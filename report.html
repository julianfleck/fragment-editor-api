<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8"/>
    <title id="head-title">report.html</title>
      <style type="text/css">body {
  font-family: Helvetica, Arial, sans-serif;
  font-size: 12px;
  /* do not increase min-width as some may use split screens */
  min-width: 800px;
  color: #999;
}

h1 {
  font-size: 24px;
  color: black;
}

h2 {
  font-size: 16px;
  color: black;
}

p {
  color: black;
}

a {
  color: #999;
}

table {
  border-collapse: collapse;
}

/******************************
 * SUMMARY INFORMATION
 ******************************/
#environment td {
  padding: 5px;
  border: 1px solid #e6e6e6;
  vertical-align: top;
}
#environment tr:nth-child(odd) {
  background-color: #f6f6f6;
}
#environment ul {
  margin: 0;
  padding: 0 20px;
}

/******************************
 * TEST RESULT COLORS
 ******************************/
span.passed,
.passed .col-result {
  color: green;
}

span.skipped,
span.xfailed,
span.rerun,
.skipped .col-result,
.xfailed .col-result,
.rerun .col-result {
  color: orange;
}

span.error,
span.failed,
span.xpassed,
.error .col-result,
.failed .col-result,
.xpassed .col-result {
  color: red;
}

.col-links__extra {
  margin-right: 3px;
}

/******************************
 * RESULTS TABLE
 *
 * 1. Table Layout
 * 2. Extra
 * 3. Sorting items
 *
 ******************************/
/*------------------
 * 1. Table Layout
 *------------------*/
#results-table {
  border: 1px solid #e6e6e6;
  color: #999;
  font-size: 12px;
  width: 100%;
}
#results-table th,
#results-table td {
  padding: 5px;
  border: 1px solid #e6e6e6;
  text-align: left;
}
#results-table th {
  font-weight: bold;
}

/*------------------
 * 2. Extra
 *------------------*/
.logwrapper {
  max-height: 230px;
  overflow-y: scroll;
  background-color: #e6e6e6;
}
.logwrapper.expanded {
  max-height: none;
}
.logwrapper.expanded .logexpander:after {
  content: "collapse [-]";
}
.logwrapper .logexpander {
  z-index: 1;
  position: sticky;
  top: 10px;
  width: max-content;
  border: 1px solid;
  border-radius: 3px;
  padding: 5px 7px;
  margin: 10px 0 10px calc(100% - 80px);
  cursor: pointer;
  background-color: #e6e6e6;
}
.logwrapper .logexpander:after {
  content: "expand [+]";
}
.logwrapper .logexpander:hover {
  color: #000;
  border-color: #000;
}
.logwrapper .log {
  min-height: 40px;
  position: relative;
  top: -50px;
  height: calc(100% + 50px);
  border: 1px solid #e6e6e6;
  color: black;
  display: block;
  font-family: "Courier New", Courier, monospace;
  padding: 5px;
  padding-right: 80px;
  white-space: pre-wrap;
}

div.media {
  border: 1px solid #e6e6e6;
  float: right;
  height: 240px;
  margin: 0 5px;
  overflow: hidden;
  width: 320px;
}

.media-container {
  display: grid;
  grid-template-columns: 25px auto 25px;
  align-items: center;
  flex: 1 1;
  overflow: hidden;
  height: 200px;
}

.media-container--fullscreen {
  grid-template-columns: 0px auto 0px;
}

.media-container__nav--right,
.media-container__nav--left {
  text-align: center;
  cursor: pointer;
}

.media-container__viewport {
  cursor: pointer;
  text-align: center;
  height: inherit;
}
.media-container__viewport img,
.media-container__viewport video {
  object-fit: cover;
  width: 100%;
  max-height: 100%;
}

.media__name,
.media__counter {
  display: flex;
  flex-direction: row;
  justify-content: space-around;
  flex: 0 0 25px;
  align-items: center;
}

.collapsible td:not(.col-links) {
  cursor: pointer;
}
.collapsible td:not(.col-links):hover::after {
  color: #bbb;
  font-style: italic;
  cursor: pointer;
}

.col-result {
  width: 130px;
}
.col-result:hover::after {
  content: " (hide details)";
}

.col-result.collapsed:hover::after {
  content: " (show details)";
}

#environment-header h2:hover::after {
  content: " (hide details)";
  color: #bbb;
  font-style: italic;
  cursor: pointer;
  font-size: 12px;
}

#environment-header.collapsed h2:hover::after {
  content: " (show details)";
  color: #bbb;
  font-style: italic;
  cursor: pointer;
  font-size: 12px;
}

/*------------------
 * 3. Sorting items
 *------------------*/
.sortable {
  cursor: pointer;
}
.sortable.desc:after {
  content: " ";
  position: relative;
  left: 5px;
  bottom: -12.5px;
  border: 10px solid #4caf50;
  border-bottom: 0;
  border-left-color: transparent;
  border-right-color: transparent;
}
.sortable.asc:after {
  content: " ";
  position: relative;
  left: 5px;
  bottom: 12.5px;
  border: 10px solid #4caf50;
  border-top: 0;
  border-left-color: transparent;
  border-right-color: transparent;
}

.hidden, .summary__reload__button.hidden {
  display: none;
}

.summary__data {
  flex: 0 0 550px;
}
.summary__reload {
  flex: 1 1;
  display: flex;
  justify-content: center;
}
.summary__reload__button {
  flex: 0 0 300px;
  display: flex;
  color: white;
  font-weight: bold;
  background-color: #4caf50;
  text-align: center;
  justify-content: center;
  align-items: center;
  border-radius: 3px;
  cursor: pointer;
}
.summary__reload__button:hover {
  background-color: #46a049;
}
.summary__spacer {
  flex: 0 0 550px;
}

.controls {
  display: flex;
  justify-content: space-between;
}

.filters,
.collapse {
  display: flex;
  align-items: center;
}
.filters button,
.collapse button {
  color: #999;
  border: none;
  background: none;
  cursor: pointer;
  text-decoration: underline;
}
.filters button:hover,
.collapse button:hover {
  color: #ccc;
}

.filter__label {
  margin-right: 10px;
}

      </style>
    
  </head>
  <body>
    <h1 id="title">report.html</h1>
    <p>Report generated on 30-Oct-2024 at 16:53:52 by <a href="https://pypi.python.org/pypi/pytest-html">pytest-html</a>
        v4.1.1</p>
    <div id="environment-header">
      <h2>Environment</h2>
    </div>
    <table id="environment"></table>
    <!-- TEMPLATES -->
      <template id="template_environment_row">
      <tr>
        <td></td>
        <td></td>
      </tr>
    </template>
    <template id="template_results-table__body--empty">
      <tbody class="results-table-row">
        <tr id="not-found-message">
          <td colspan="4">No results found. Check the filters.</th>
        </tr>
    </template>
    <template id="template_results-table__tbody">
      <tbody class="results-table-row">
        <tr class="collapsible">
        </tr>
        <tr class="extras-row">
          <td class="extra" colspan="4">
            <div class="extraHTML"></div>
            <div class="media">
              <div class="media-container">
                  <div class="media-container__nav--left"><</div>
                  <div class="media-container__viewport">
                    <img src="" />
                    <video controls>
                      <source src="" type="video/mp4">
                    </video>
                  </div>
                  <div class="media-container__nav--right">></div>
                </div>
                <div class="media__name"></div>
                <div class="media__counter"></div>
            </div>
            <div class="logwrapper">
              <div class="logexpander"></div>
              <div class="log"></div>
            </div>
          </td>
        </tr>
      </tbody>
    </template>
    <!-- END TEMPLATES -->
    <div class="summary">
      <div class="summary__data">
        <h2>Summary</h2>
        <div class="additional-summary prefix">
        </div>
        <p class="run-count">35 tests took 00:00:40.</p>
        <p class="filter">(Un)check the boxes to filter the results.</p>
        <div class="summary__reload">
          <div class="summary__reload__button hidden" onclick="location.reload()">
            <div>There are still tests running. <br />Reload this page to get the latest results!</div>
          </div>
        </div>
        <div class="summary__spacer"></div>
        <div class="controls">
          <div class="filters">
            <input checked="true" class="filter" name="filter_checkbox" type="checkbox" data-test-result="failed" />
            <span class="failed">33 Failed,</span>
            <input checked="true" class="filter" name="filter_checkbox" type="checkbox" data-test-result="passed" />
            <span class="passed">2 Passed,</span>
            <input checked="true" class="filter" name="filter_checkbox" type="checkbox" data-test-result="skipped" disabled/>
            <span class="skipped">0 Skipped,</span>
            <input checked="true" class="filter" name="filter_checkbox" type="checkbox" data-test-result="xfailed" disabled/>
            <span class="xfailed">0 Expected failures,</span>
            <input checked="true" class="filter" name="filter_checkbox" type="checkbox" data-test-result="xpassed" disabled/>
            <span class="xpassed">0 Unexpected passes,</span>
            <input checked="true" class="filter" name="filter_checkbox" type="checkbox" data-test-result="error" disabled/>
            <span class="error">0 Errors,</span>
            <input checked="true" class="filter" name="filter_checkbox" type="checkbox" data-test-result="rerun" disabled/>
            <span class="rerun">0 Reruns</span>
          </div>
          <div class="collapse">
            <button id="show_all_details">Show all details</button>&nbsp;/&nbsp;<button id="hide_all_details">Hide all details</button>
          </div>
        </div>
      </div>
      <div class="additional-summary summary">
      </div>
      <div class="additional-summary postfix">
      </div>
    </div>
    <table id="results-table">
      <thead id="results-table-head">
        <tr>
          <th class="sortable" data-column-type="result">Result</th>
          <th class="sortable" data-column-type="testId">Test</th>
          <th class="sortable" data-column-type="duration">Duration</th>
          <th>Links</th>
        </tr>
      </thead>
    </table>
  </body>
  <footer>
    <div id="data-container" data-jsonblob="{&#34;environment&#34;: {&#34;Python&#34;: &#34;3.12.5&#34;, &#34;Platform&#34;: &#34;macOS-14.5-arm64-arm-64bit&#34;, &#34;Packages&#34;: {&#34;pytest&#34;: &#34;8.0.0&#34;, &#34;pluggy&#34;: &#34;1.5.0&#34;}, &#34;Plugins&#34;: {&#34;html&#34;: &#34;4.1.1&#34;, &#34;metadata&#34;: &#34;3.1.1&#34;, &#34;cov&#34;: &#34;4.1.0&#34;, &#34;anyio&#34;: &#34;4.6.2.post1&#34;}}, &#34;tests&#34;: {&#34;tests/performance/test_compress_performance.py::TestCompressEndpoint::test_single_version_compression&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Failed&#34;, &#34;testId&#34;: &#34;tests/performance/test_compress_performance.py::TestCompressEndpoint::test_single_version_compression&#34;, &#34;duration&#34;: &#34;00:00:02&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Failed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/performance/test_compress_performance.py::TestCompressEndpoint::test_single_version_compression&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:02&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;self = &amp;lt;tests.test_compress.TestCompressEndpoint object at 0x1069529f0&amp;gt;\nclient = &amp;lt;FlaskClient &amp;lt;Flask &amp;#x27;app&amp;#x27;&amp;gt;&amp;gt;\nauth_headers = {&amp;#x27;Authorization&amp;#x27;: &amp;#x27;Bearer test_key&amp;#x27;, &amp;#x27;Content-Type&amp;#x27;: &amp;#x27;application/json&amp;#x27;}\n\n    @pytest.mark.unit\n    def test_single_version_compression(self, client, auth_headers):\n        response = client.post(self.ENDPOINTS[&amp;#x27;compress&amp;#x27;], json={\n            &amp;#x27;content&amp;#x27;: self.SAMPLE_TEXT,\n            &amp;#x27;target_percentage&amp;#x27;: 40\n        }, headers=auth_headers)\n    \n        assert response.status_code == 200\n        data = response.json\n    \n        # Test response structure\n        assert data[&amp;#x27;type&amp;#x27;] == &amp;#x27;cohesive&amp;#x27;\n        assert len(data[&amp;#x27;versions&amp;#x27;]) == 1\n    \n        version = data[&amp;#x27;versions&amp;#x27;][0]\n        assert &amp;#x27;text&amp;#x27; in version\n        assert &amp;#x27;final_percentage&amp;#x27; in version\n        assert isinstance(version[&amp;#x27;final_percentage&amp;#x27;], float)\n    \n        # Test compression quality\n        compressed_text = version[&amp;#x27;text&amp;#x27;]\n        target_percentage = 40\n&amp;gt;       assert abs(version[&amp;#x27;final_percentage&amp;#x27;] -\n                   target_percentage) &amp;lt;= 10  # 10% margin\nE       assert 42.900000000000006 &amp;lt;= 10\nE        +  where 42.900000000000006 = abs((82.9 - 40))\n\ntests/test_compress.py:52: AssertionError\n\n---------------------------- Captured stderr setup -----------------------------\nDEBUG:httpx:load_ssl_context verify=True cert=None trust_env=True http2=False\nDEBUG:httpx:load_verify_locations cafile=&amp;#x27;/Users/julian/Tresors/Privat/Code/fragment-editor-api/.venv-test/lib/python3.12/site-packages/certifi/cacert.pem&amp;#x27;\nDEBUG:app:Registering blueprints...\nDEBUG:app:Registered routes:\nDEBUG:app:static: /static/&amp;lt;path:filename&amp;gt; [GET, OPTIONS, HEAD]\nDEBUG:app:generate.create_text: /text/v1/generate/text [OPTIONS, POST]\nDEBUG:app:compress.compress_text: /text/v1/compress/ [OPTIONS, POST]\nDEBUG:app:expand.expand_text: /text/v1/expand/ [OPTIONS, POST]\n\n------------------------------ Captured log setup ------------------------------\nDEBUG    httpx:_config.py:82 load_ssl_context verify=True cert=None trust_env=True http2=False\nDEBUG    httpx:_config.py:148 load_verify_locations cafile=&amp;#x27;/Users/julian/Tresors/Privat/Code/fragment-editor-api/.venv-test/lib/python3.12/site-packages/certifi/cacert.pem&amp;#x27;\nDEBUG    app:__init__.py:106 Registering blueprints...\nDEBUG    app:__init__.py:112 Registered routes:\nDEBUG    app:__init__.py:114 static: /static/&amp;lt;path:filename&amp;gt; [GET, OPTIONS, HEAD]\nDEBUG    app:__init__.py:114 generate.create_text: /text/v1/generate/text [OPTIONS, POST]\nDEBUG    app:__init__.py:114 compress.compress_text: /text/v1/compress/ [OPTIONS, POST]\nDEBUG    app:__init__.py:114 expand.expand_text: /text/v1/expand/ [OPTIONS, POST]\n\n----------------------------- Captured stderr call -----------------------------\nDEBUG:app:Headers: {&amp;#x27;User-Agent&amp;#x27;: &amp;#x27;Werkzeug/3.0.6&amp;#x27;, &amp;#x27;Host&amp;#x27;: &amp;#x27;localhost&amp;#x27;, &amp;#x27;Content-Type&amp;#x27;: &amp;#x27;application/json&amp;#x27;, &amp;#x27;Content-Length&amp;#x27;: &amp;#x27;250&amp;#x27;, &amp;#x27;Authorization&amp;#x27;: &amp;#x27;Bearer test_key&amp;#x27;}\nDEBUG:app:Body: b&amp;#x27;{&amp;quot;content&amp;quot;: &amp;quot;The Text Transformation API offers a robust set of REST endpoints that enable developers to programmatically manipulate and transform text content. The operations include expansion, summarization, and chunking.&amp;quot;, &amp;quot;target_percentage&amp;quot;: 40}&amp;#x27;\nDEBUG:app:Query Params: {}\nDEBUG:app:Route: POST /text/v1/compress/\nDEBUG:groq._base_client:Request options: {&amp;#x27;method&amp;#x27;: &amp;#x27;post&amp;#x27;, &amp;#x27;url&amp;#x27;: &amp;#x27;/openai/v1/chat/completions&amp;#x27;, &amp;#x27;files&amp;#x27;: None, &amp;#x27;json_data&amp;#x27;: {&amp;#x27;messages&amp;#x27;: [{&amp;#x27;role&amp;#x27;: &amp;#x27;system&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate a JSON response following these rules:\\n1. Return exactly ONE compressed version:\\n   {&amp;quot;versions&amp;quot;: [{&amp;quot;text&amp;quot;: &amp;quot;compressed version&amp;quot;}]}\\n2. Target exactly the specified percentage of original length\\n3. Maintain core meaning while removing less essential details\\n4. Ensure complete sentences and proper punctuation\\n5. If task cannot be completed: {&amp;quot;error&amp;quot;: &amp;quot;specific reason&amp;quot;}&amp;#x27;}, {&amp;#x27;role&amp;#x27;: &amp;#x27;user&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate ONE compressed version at 40% length:\\n        Original length: 35 tokens\\n        Original text: The Text Transformation API offers a robust set of REST endpoints that enable developers to programmatically manipulate and transform text content. The operations include expansion, summarization, and chunking.&amp;#x27;}], &amp;#x27;model&amp;#x27;: &amp;#x27;llama3-groq-70b-8192-tool-use-preview&amp;#x27;, &amp;#x27;max_tokens&amp;#x27;: 1000, &amp;#x27;temperature&amp;#x27;: 0.7}}\nDEBUG:httpcore.connection:connect_tcp.started host=&amp;#x27;api.groq.com&amp;#x27; port=443 local_address=None timeout=5.0 socket_options=None\nDEBUG:httpcore.connection:connect_tcp.complete return_value=&amp;lt;httpcore._backends.sync.SyncStream object at 0x108436960&amp;gt;\nDEBUG:httpcore.connection:start_tls.started ssl_context=&amp;lt;ssl.SSLContext object at 0x107bb3b50&amp;gt; server_hostname=&amp;#x27;api.groq.com&amp;#x27; timeout=5.0\nDEBUG:httpcore.connection:start_tls.complete return_value=&amp;lt;httpcore._backends.sync.SyncStream object at 0x1049a6000&amp;gt;\nDEBUG:httpcore.http11:send_request_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.http11:send_request_headers.complete\nDEBUG:httpcore.http11:send_request_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.http11:send_request_body.complete\nDEBUG:httpcore.http11:receive_response_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.http11:receive_response_headers.complete return_value=(b&amp;#x27;HTTP/1.1&amp;#x27;, 200, b&amp;#x27;OK&amp;#x27;, [(b&amp;#x27;Date&amp;#x27;, b&amp;#x27;Wed, 30 Oct 2024 15:53:13 GMT&amp;#x27;), (b&amp;#x27;Content-Type&amp;#x27;, b&amp;#x27;application/json&amp;#x27;), (b&amp;#x27;Transfer-Encoding&amp;#x27;, b&amp;#x27;chunked&amp;#x27;), (b&amp;#x27;Connection&amp;#x27;, b&amp;#x27;keep-alive&amp;#x27;), (b&amp;#x27;Cache-Control&amp;#x27;, b&amp;#x27;private, max-age=0, no-store, no-cache, must-revalidate&amp;#x27;), (b&amp;#x27;vary&amp;#x27;, b&amp;#x27;Origin&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-requests&amp;#x27;, b&amp;#x27;14400&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-tokens&amp;#x27;, b&amp;#x27;15000&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-requests&amp;#x27;, b&amp;#x27;14399&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-tokens&amp;#x27;, b&amp;#x27;14818&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-requests&amp;#x27;, b&amp;#x27;6s&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-tokens&amp;#x27;, b&amp;#x27;728ms&amp;#x27;), (b&amp;#x27;x-request-id&amp;#x27;, b&amp;#x27;req_01jbf2333heaha95zz8z8cgxyw&amp;#x27;), (b&amp;#x27;via&amp;#x27;, b&amp;#x27;1.1 google&amp;#x27;), (b&amp;#x27;alt-svc&amp;#x27;, b&amp;#x27;h3=&amp;quot;:443&amp;quot;; ma=86400&amp;#x27;), (b&amp;#x27;CF-Cache-Status&amp;#x27;, b&amp;#x27;DYNAMIC&amp;#x27;), (b&amp;#x27;Set-Cookie&amp;#x27;, b&amp;#x27;__cf_bm=1wcTyWb9V1sqNVcYkWt.sOmUWVXEf74ftt6UBvYmfrE-1730303593-1.0.1.1-T5d9g5KFyy7IsXbTW7Qm1i9AjzOQI0tcIdXnHVznR8ftj326dtWVP8xsIwGNU2nZh4A3XZvD4R8rqiAtEJRtzg; path=/; expires=Wed, 30-Oct-24 16:23:13 GMT; domain=.groq.com; HttpOnly; Secure; SameSite=None&amp;#x27;), (b&amp;#x27;Server&amp;#x27;, b&amp;#x27;cloudflare&amp;#x27;), (b&amp;#x27;CF-RAY&amp;#x27;, b&amp;#x27;8dac93b35c1cca58-HAM&amp;#x27;), (b&amp;#x27;Content-Encoding&amp;#x27;, b&amp;#x27;gzip&amp;#x27;)])\nINFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;HTTP/1.1 200 OK&amp;quot;\nDEBUG:httpcore.http11:receive_response_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.http11:receive_response_body.complete\nDEBUG:httpcore.http11:response_closed.started\nDEBUG:httpcore.http11:response_closed.complete\nDEBUG:groq._base_client:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;200 OK&amp;quot;\n\n------------------------------ Captured log call -------------------------------\nDEBUG    app:__init__.py:31 Headers: {&amp;#x27;User-Agent&amp;#x27;: &amp;#x27;Werkzeug/3.0.6&amp;#x27;, &amp;#x27;Host&amp;#x27;: &amp;#x27;localhost&amp;#x27;, &amp;#x27;Content-Type&amp;#x27;: &amp;#x27;application/json&amp;#x27;, &amp;#x27;Content-Length&amp;#x27;: &amp;#x27;250&amp;#x27;, &amp;#x27;Authorization&amp;#x27;: &amp;#x27;Bearer test_key&amp;#x27;}\nDEBUG    app:__init__.py:32 Body: b&amp;#x27;{&amp;quot;content&amp;quot;: &amp;quot;The Text Transformation API offers a robust set of REST endpoints that enable developers to programmatically manipulate and transform text content. The operations include expansion, summarization, and chunking.&amp;quot;, &amp;quot;target_percentage&amp;quot;: 40}&amp;#x27;\nDEBUG    app:__init__.py:33 Query Params: {}\nDEBUG    app:__init__.py:34 Route: POST /text/v1/compress/\nDEBUG    groq._base_client:_base_client.py:441 Request options: {&amp;#x27;method&amp;#x27;: &amp;#x27;post&amp;#x27;, &amp;#x27;url&amp;#x27;: &amp;#x27;/openai/v1/chat/completions&amp;#x27;, &amp;#x27;files&amp;#x27;: None, &amp;#x27;json_data&amp;#x27;: {&amp;#x27;messages&amp;#x27;: [{&amp;#x27;role&amp;#x27;: &amp;#x27;system&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate a JSON response following these rules:\\n1. Return exactly ONE compressed version:\\n   {&amp;quot;versions&amp;quot;: [{&amp;quot;text&amp;quot;: &amp;quot;compressed version&amp;quot;}]}\\n2. Target exactly the specified percentage of original length\\n3. Maintain core meaning while removing less essential details\\n4. Ensure complete sentences and proper punctuation\\n5. If task cannot be completed: {&amp;quot;error&amp;quot;: &amp;quot;specific reason&amp;quot;}&amp;#x27;}, {&amp;#x27;role&amp;#x27;: &amp;#x27;user&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate ONE compressed version at 40% length:\\n        Original length: 35 tokens\\n        Original text: The Text Transformation API offers a robust set of REST endpoints that enable developers to programmatically manipulate and transform text content. The operations include expansion, summarization, and chunking.&amp;#x27;}], &amp;#x27;model&amp;#x27;: &amp;#x27;llama3-groq-70b-8192-tool-use-preview&amp;#x27;, &amp;#x27;max_tokens&amp;#x27;: 1000, &amp;#x27;temperature&amp;#x27;: 0.7}}\nDEBUG    httpcore.connection:_trace.py:45 connect_tcp.started host=&amp;#x27;api.groq.com&amp;#x27; port=443 local_address=None timeout=5.0 socket_options=None\nDEBUG    httpcore.connection:_trace.py:45 connect_tcp.complete return_value=&amp;lt;httpcore._backends.sync.SyncStream object at 0x108436960&amp;gt;\nDEBUG    httpcore.connection:_trace.py:45 start_tls.started ssl_context=&amp;lt;ssl.SSLContext object at 0x107bb3b50&amp;gt; server_hostname=&amp;#x27;api.groq.com&amp;#x27; timeout=5.0\nDEBUG    httpcore.connection:_trace.py:45 start_tls.complete return_value=&amp;lt;httpcore._backends.sync.SyncStream object at 0x1049a6000&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 send_request_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 send_request_headers.complete\nDEBUG    httpcore.http11:_trace.py:45 send_request_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 send_request_body.complete\nDEBUG    httpcore.http11:_trace.py:45 receive_response_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 receive_response_headers.complete return_value=(b&amp;#x27;HTTP/1.1&amp;#x27;, 200, b&amp;#x27;OK&amp;#x27;, [(b&amp;#x27;Date&amp;#x27;, b&amp;#x27;Wed, 30 Oct 2024 15:53:13 GMT&amp;#x27;), (b&amp;#x27;Content-Type&amp;#x27;, b&amp;#x27;application/json&amp;#x27;), (b&amp;#x27;Transfer-Encoding&amp;#x27;, b&amp;#x27;chunked&amp;#x27;), (b&amp;#x27;Connection&amp;#x27;, b&amp;#x27;keep-alive&amp;#x27;), (b&amp;#x27;Cache-Control&amp;#x27;, b&amp;#x27;private, max-age=0, no-store, no-cache, must-revalidate&amp;#x27;), (b&amp;#x27;vary&amp;#x27;, b&amp;#x27;Origin&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-requests&amp;#x27;, b&amp;#x27;14400&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-tokens&amp;#x27;, b&amp;#x27;15000&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-requests&amp;#x27;, b&amp;#x27;14399&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-tokens&amp;#x27;, b&amp;#x27;14818&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-requests&amp;#x27;, b&amp;#x27;6s&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-tokens&amp;#x27;, b&amp;#x27;728ms&amp;#x27;), (b&amp;#x27;x-request-id&amp;#x27;, b&amp;#x27;req_01jbf2333heaha95zz8z8cgxyw&amp;#x27;), (b&amp;#x27;via&amp;#x27;, b&amp;#x27;1.1 google&amp;#x27;), (b&amp;#x27;alt-svc&amp;#x27;, b&amp;#x27;h3=&amp;quot;:443&amp;quot;; ma=86400&amp;#x27;), (b&amp;#x27;CF-Cache-Status&amp;#x27;, b&amp;#x27;DYNAMIC&amp;#x27;), (b&amp;#x27;Set-Cookie&amp;#x27;, b&amp;#x27;__cf_bm=1wcTyWb9V1sqNVcYkWt.sOmUWVXEf74ftt6UBvYmfrE-1730303593-1.0.1.1-T5d9g5KFyy7IsXbTW7Qm1i9AjzOQI0tcIdXnHVznR8ftj326dtWVP8xsIwGNU2nZh4A3XZvD4R8rqiAtEJRtzg; path=/; expires=Wed, 30-Oct-24 16:23:13 GMT; domain=.groq.com; HttpOnly; Secure; SameSite=None&amp;#x27;), (b&amp;#x27;Server&amp;#x27;, b&amp;#x27;cloudflare&amp;#x27;), (b&amp;#x27;CF-RAY&amp;#x27;, b&amp;#x27;8dac93b35c1cca58-HAM&amp;#x27;), (b&amp;#x27;Content-Encoding&amp;#x27;, b&amp;#x27;gzip&amp;#x27;)])\nINFO     httpx:_client.py:1038 HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;HTTP/1.1 200 OK&amp;quot;\nDEBUG    httpcore.http11:_trace.py:45 receive_response_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 receive_response_body.complete\nDEBUG    httpcore.http11:_trace.py:45 response_closed.started\nDEBUG    httpcore.http11:_trace.py:45 response_closed.complete\nDEBUG    groq._base_client:_base_client.py:956 HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;200 OK&amp;quot;\n\n&#34;}], &#34;tests/performance/test_compress_performance.py::TestCompressEndpoint::test_fixed_multiple_versions&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Failed&#34;, &#34;testId&#34;: &#34;tests/performance/test_compress_performance.py::TestCompressEndpoint::test_fixed_multiple_versions&#34;, &#34;duration&#34;: &#34;00:00:01&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Failed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/performance/test_compress_performance.py::TestCompressEndpoint::test_fixed_multiple_versions&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:01&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;self = &amp;lt;tests.test_compress.TestCompressEndpoint object at 0x106952bd0&amp;gt;\nclient = &amp;lt;FlaskClient &amp;lt;Flask &amp;#x27;app&amp;#x27;&amp;gt;&amp;gt;\nauth_headers = {&amp;#x27;Authorization&amp;#x27;: &amp;#x27;Bearer test_key&amp;#x27;, &amp;#x27;Content-Type&amp;#x27;: &amp;#x27;application/json&amp;#x27;}\n\n    @pytest.mark.unit\n    def test_fixed_multiple_versions(self, client, auth_headers):\n        response = client.post(self.ENDPOINTS[&amp;#x27;compress&amp;#x27;], json={\n            &amp;#x27;content&amp;#x27;: self.SAMPLE_TEXT,\n            &amp;#x27;target_percentage&amp;#x27;: 50,\n            &amp;#x27;versions&amp;#x27;: 3\n        }, headers=auth_headers)\n    \n        assert response.status_code == 200\n        data = response.json\n        assert len(data[&amp;#x27;versions&amp;#x27;]) == 3\n        # All versions same length\n&amp;gt;       assert len(set(len(v[&amp;#x27;text&amp;#x27;]) for v in data[&amp;#x27;versions&amp;#x27;])) == 1\nE       assert 3 == 1\nE        +  where 3 = len({200, 203, 204})\nE        +    where {200, 203, 204} = set(&amp;lt;generator object TestCompressEndpoint.test_fixed_multiple_versions.&amp;lt;locals&amp;gt;.&amp;lt;genexpr&amp;gt; at 0x108914f20&amp;gt;)\n\ntests/test_compress.py:72: AssertionError\n\n---------------------------- Captured stderr setup -----------------------------\nDEBUG:app:Registering blueprints...\nDEBUG:app:Registered routes:\nDEBUG:app:static: /static/&amp;lt;path:filename&amp;gt; [GET, OPTIONS, HEAD]\nDEBUG:app:generate.create_text: /text/v1/generate/text [OPTIONS, POST]\nDEBUG:app:compress.compress_text: /text/v1/compress/ [OPTIONS, POST]\nDEBUG:app:expand.expand_text: /text/v1/expand/ [OPTIONS, POST]\n\n------------------------------ Captured log setup ------------------------------\nDEBUG    app:__init__.py:106 Registering blueprints...\nDEBUG    app:__init__.py:112 Registered routes:\nDEBUG    app:__init__.py:114 static: /static/&amp;lt;path:filename&amp;gt; [GET, OPTIONS, HEAD]\nDEBUG    app:__init__.py:114 generate.create_text: /text/v1/generate/text [OPTIONS, POST]\nDEBUG    app:__init__.py:114 compress.compress_text: /text/v1/compress/ [OPTIONS, POST]\nDEBUG    app:__init__.py:114 expand.expand_text: /text/v1/expand/ [OPTIONS, POST]\n\n----------------------------- Captured stderr call -----------------------------\nDEBUG:app:Headers: {&amp;#x27;User-Agent&amp;#x27;: &amp;#x27;Werkzeug/3.0.6&amp;#x27;, &amp;#x27;Host&amp;#x27;: &amp;#x27;localhost&amp;#x27;, &amp;#x27;Content-Type&amp;#x27;: &amp;#x27;application/json&amp;#x27;, &amp;#x27;Content-Length&amp;#x27;: &amp;#x27;265&amp;#x27;, &amp;#x27;Authorization&amp;#x27;: &amp;#x27;Bearer test_key&amp;#x27;}\nDEBUG:app:Body: b&amp;#x27;{&amp;quot;content&amp;quot;: &amp;quot;The Text Transformation API offers a robust set of REST endpoints that enable developers to programmatically manipulate and transform text content. The operations include expansion, summarization, and chunking.&amp;quot;, &amp;quot;target_percentage&amp;quot;: 50, &amp;quot;versions&amp;quot;: 3}&amp;#x27;\nDEBUG:app:Query Params: {}\nDEBUG:app:Route: POST /text/v1/compress/\nDEBUG:groq._base_client:Request options: {&amp;#x27;method&amp;#x27;: &amp;#x27;post&amp;#x27;, &amp;#x27;url&amp;#x27;: &amp;#x27;/openai/v1/chat/completions&amp;#x27;, &amp;#x27;files&amp;#x27;: None, &amp;#x27;json_data&amp;#x27;: {&amp;#x27;messages&amp;#x27;: [{&amp;#x27;role&amp;#x27;: &amp;#x27;system&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate a JSON response following these rules:\\n1. Return multiple UNIQUE versions at the SAME length:\\n   {&amp;quot;versions&amp;quot;: [{&amp;quot;text&amp;quot;: &amp;quot;version1&amp;quot;}, {&amp;quot;text&amp;quot;: &amp;quot;version2&amp;quot;}]}\\n2. Each version must:\\n   - Target exactly the specified percentage\\n   - Use different sentence structures\\n   - Vary word choices while keeping technical terms\\n   - Maintain the same meaning\\n3. If task cannot be completed: {&amp;quot;error&amp;quot;: &amp;quot;specific reason&amp;quot;}&amp;#x27;}, {&amp;#x27;role&amp;#x27;: &amp;#x27;user&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate 3 UNIQUE versions at 50% length:\\n        - Each must be exactly the same length\\n        - Use different phrasings\\n        Original length: 35 tokens\\n        Original text: The Text Transformation API offers a robust set of REST endpoints that enable developers to programmatically manipulate and transform text content. The operations include expansion, summarization, and chunking.&amp;#x27;}], &amp;#x27;model&amp;#x27;: &amp;#x27;llama3-groq-70b-8192-tool-use-preview&amp;#x27;, &amp;#x27;max_tokens&amp;#x27;: 1000, &amp;#x27;temperature&amp;#x27;: 0.7}}\nDEBUG:httpcore.http11:send_request_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.http11:send_request_headers.complete\nDEBUG:httpcore.http11:send_request_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.http11:send_request_body.complete\nDEBUG:httpcore.http11:receive_response_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.http11:receive_response_headers.complete return_value=(b&amp;#x27;HTTP/1.1&amp;#x27;, 200, b&amp;#x27;OK&amp;#x27;, [(b&amp;#x27;Date&amp;#x27;, b&amp;#x27;Wed, 30 Oct 2024 15:53:15 GMT&amp;#x27;), (b&amp;#x27;Content-Type&amp;#x27;, b&amp;#x27;application/json&amp;#x27;), (b&amp;#x27;Transfer-Encoding&amp;#x27;, b&amp;#x27;chunked&amp;#x27;), (b&amp;#x27;Connection&amp;#x27;, b&amp;#x27;keep-alive&amp;#x27;), (b&amp;#x27;Cache-Control&amp;#x27;, b&amp;#x27;private, max-age=0, no-store, no-cache, must-revalidate&amp;#x27;), (b&amp;#x27;vary&amp;#x27;, b&amp;#x27;Origin&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-requests&amp;#x27;, b&amp;#x27;14400&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-tokens&amp;#x27;, b&amp;#x27;15000&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-requests&amp;#x27;, b&amp;#x27;14398&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-tokens&amp;#x27;, b&amp;#x27;14790&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-requests&amp;#x27;, b&amp;#x27;11.036s&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-tokens&amp;#x27;, b&amp;#x27;840ms&amp;#x27;), (b&amp;#x27;x-request-id&amp;#x27;, b&amp;#x27;req_01jbf2341pf9ray7h93ze424vv&amp;#x27;), (b&amp;#x27;via&amp;#x27;, b&amp;#x27;1.1 google&amp;#x27;), (b&amp;#x27;alt-svc&amp;#x27;, b&amp;#x27;h3=&amp;quot;:443&amp;quot;; ma=86400&amp;#x27;), (b&amp;#x27;CF-Cache-Status&amp;#x27;, b&amp;#x27;DYNAMIC&amp;#x27;), (b&amp;#x27;Server&amp;#x27;, b&amp;#x27;cloudflare&amp;#x27;), (b&amp;#x27;CF-RAY&amp;#x27;, b&amp;#x27;8dac93b95bf6ca58-HAM&amp;#x27;), (b&amp;#x27;Content-Encoding&amp;#x27;, b&amp;#x27;gzip&amp;#x27;)])\nINFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;HTTP/1.1 200 OK&amp;quot;\nDEBUG:httpcore.http11:receive_response_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.http11:receive_response_body.complete\nDEBUG:httpcore.http11:response_closed.started\nDEBUG:httpcore.http11:response_closed.complete\nDEBUG:groq._base_client:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;200 OK&amp;quot;\n\n------------------------------ Captured log call -------------------------------\nDEBUG    app:__init__.py:31 Headers: {&amp;#x27;User-Agent&amp;#x27;: &amp;#x27;Werkzeug/3.0.6&amp;#x27;, &amp;#x27;Host&amp;#x27;: &amp;#x27;localhost&amp;#x27;, &amp;#x27;Content-Type&amp;#x27;: &amp;#x27;application/json&amp;#x27;, &amp;#x27;Content-Length&amp;#x27;: &amp;#x27;265&amp;#x27;, &amp;#x27;Authorization&amp;#x27;: &amp;#x27;Bearer test_key&amp;#x27;}\nDEBUG    app:__init__.py:32 Body: b&amp;#x27;{&amp;quot;content&amp;quot;: &amp;quot;The Text Transformation API offers a robust set of REST endpoints that enable developers to programmatically manipulate and transform text content. The operations include expansion, summarization, and chunking.&amp;quot;, &amp;quot;target_percentage&amp;quot;: 50, &amp;quot;versions&amp;quot;: 3}&amp;#x27;\nDEBUG    app:__init__.py:33 Query Params: {}\nDEBUG    app:__init__.py:34 Route: POST /text/v1/compress/\nDEBUG    groq._base_client:_base_client.py:441 Request options: {&amp;#x27;method&amp;#x27;: &amp;#x27;post&amp;#x27;, &amp;#x27;url&amp;#x27;: &amp;#x27;/openai/v1/chat/completions&amp;#x27;, &amp;#x27;files&amp;#x27;: None, &amp;#x27;json_data&amp;#x27;: {&amp;#x27;messages&amp;#x27;: [{&amp;#x27;role&amp;#x27;: &amp;#x27;system&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate a JSON response following these rules:\\n1. Return multiple UNIQUE versions at the SAME length:\\n   {&amp;quot;versions&amp;quot;: [{&amp;quot;text&amp;quot;: &amp;quot;version1&amp;quot;}, {&amp;quot;text&amp;quot;: &amp;quot;version2&amp;quot;}]}\\n2. Each version must:\\n   - Target exactly the specified percentage\\n   - Use different sentence structures\\n   - Vary word choices while keeping technical terms\\n   - Maintain the same meaning\\n3. If task cannot be completed: {&amp;quot;error&amp;quot;: &amp;quot;specific reason&amp;quot;}&amp;#x27;}, {&amp;#x27;role&amp;#x27;: &amp;#x27;user&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate 3 UNIQUE versions at 50% length:\\n        - Each must be exactly the same length\\n        - Use different phrasings\\n        Original length: 35 tokens\\n        Original text: The Text Transformation API offers a robust set of REST endpoints that enable developers to programmatically manipulate and transform text content. The operations include expansion, summarization, and chunking.&amp;#x27;}], &amp;#x27;model&amp;#x27;: &amp;#x27;llama3-groq-70b-8192-tool-use-preview&amp;#x27;, &amp;#x27;max_tokens&amp;#x27;: 1000, &amp;#x27;temperature&amp;#x27;: 0.7}}\nDEBUG    httpcore.http11:_trace.py:45 send_request_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 send_request_headers.complete\nDEBUG    httpcore.http11:_trace.py:45 send_request_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 send_request_body.complete\nDEBUG    httpcore.http11:_trace.py:45 receive_response_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 receive_response_headers.complete return_value=(b&amp;#x27;HTTP/1.1&amp;#x27;, 200, b&amp;#x27;OK&amp;#x27;, [(b&amp;#x27;Date&amp;#x27;, b&amp;#x27;Wed, 30 Oct 2024 15:53:15 GMT&amp;#x27;), (b&amp;#x27;Content-Type&amp;#x27;, b&amp;#x27;application/json&amp;#x27;), (b&amp;#x27;Transfer-Encoding&amp;#x27;, b&amp;#x27;chunked&amp;#x27;), (b&amp;#x27;Connection&amp;#x27;, b&amp;#x27;keep-alive&amp;#x27;), (b&amp;#x27;Cache-Control&amp;#x27;, b&amp;#x27;private, max-age=0, no-store, no-cache, must-revalidate&amp;#x27;), (b&amp;#x27;vary&amp;#x27;, b&amp;#x27;Origin&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-requests&amp;#x27;, b&amp;#x27;14400&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-tokens&amp;#x27;, b&amp;#x27;15000&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-requests&amp;#x27;, b&amp;#x27;14398&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-tokens&amp;#x27;, b&amp;#x27;14790&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-requests&amp;#x27;, b&amp;#x27;11.036s&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-tokens&amp;#x27;, b&amp;#x27;840ms&amp;#x27;), (b&amp;#x27;x-request-id&amp;#x27;, b&amp;#x27;req_01jbf2341pf9ray7h93ze424vv&amp;#x27;), (b&amp;#x27;via&amp;#x27;, b&amp;#x27;1.1 google&amp;#x27;), (b&amp;#x27;alt-svc&amp;#x27;, b&amp;#x27;h3=&amp;quot;:443&amp;quot;; ma=86400&amp;#x27;), (b&amp;#x27;CF-Cache-Status&amp;#x27;, b&amp;#x27;DYNAMIC&amp;#x27;), (b&amp;#x27;Server&amp;#x27;, b&amp;#x27;cloudflare&amp;#x27;), (b&amp;#x27;CF-RAY&amp;#x27;, b&amp;#x27;8dac93b95bf6ca58-HAM&amp;#x27;), (b&amp;#x27;Content-Encoding&amp;#x27;, b&amp;#x27;gzip&amp;#x27;)])\nINFO     httpx:_client.py:1038 HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;HTTP/1.1 200 OK&amp;quot;\nDEBUG    httpcore.http11:_trace.py:45 receive_response_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 receive_response_body.complete\nDEBUG    httpcore.http11:_trace.py:45 response_closed.started\nDEBUG    httpcore.http11:_trace.py:45 response_closed.complete\nDEBUG    groq._base_client:_base_client.py:956 HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;200 OK&amp;quot;\n\n&#34;}], &#34;tests/performance/test_compress_performance.py::TestCompressEndpoint::test_staggered_with_steps&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/performance/test_compress_performance.py::TestCompressEndpoint::test_staggered_with_steps&#34;, &#34;duration&#34;: &#34;00:00:01&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/performance/test_compress_performance.py::TestCompressEndpoint::test_staggered_with_steps&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:01&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;---------------------------- Captured stderr setup -----------------------------\nDEBUG:app:Registering blueprints...\nDEBUG:app:Registered routes:\nDEBUG:app:static: /static/&amp;lt;path:filename&amp;gt; [GET, OPTIONS, HEAD]\nDEBUG:app:generate.create_text: /text/v1/generate/text [OPTIONS, POST]\nDEBUG:app:compress.compress_text: /text/v1/compress/ [OPTIONS, POST]\nDEBUG:app:expand.expand_text: /text/v1/expand/ [OPTIONS, POST]\n\n------------------------------ Captured log setup ------------------------------\nDEBUG    app:__init__.py:106 Registering blueprints...\nDEBUG    app:__init__.py:112 Registered routes:\nDEBUG    app:__init__.py:114 static: /static/&amp;lt;path:filename&amp;gt; [GET, OPTIONS, HEAD]\nDEBUG    app:__init__.py:114 generate.create_text: /text/v1/generate/text [OPTIONS, POST]\nDEBUG    app:__init__.py:114 compress.compress_text: /text/v1/compress/ [OPTIONS, POST]\nDEBUG    app:__init__.py:114 expand.expand_text: /text/v1/expand/ [OPTIONS, POST]\n\n----------------------------- Captured stderr call -----------------------------\nDEBUG:app:Headers: {&amp;#x27;User-Agent&amp;#x27;: &amp;#x27;Werkzeug/3.0.6&amp;#x27;, &amp;#x27;Host&amp;#x27;: &amp;#x27;localhost&amp;#x27;, &amp;#x27;Content-Type&amp;#x27;: &amp;#x27;application/json&amp;#x27;, &amp;#x27;Content-Length&amp;#x27;: &amp;#x27;274&amp;#x27;, &amp;#x27;Authorization&amp;#x27;: &amp;#x27;Bearer test_key&amp;#x27;}\nDEBUG:app:Body: b&amp;#x27;{&amp;quot;content&amp;quot;: &amp;quot;The Text Transformation API offers a robust set of REST endpoints that enable developers to programmatically manipulate and transform text content. The operations include expansion, summarization, and chunking.&amp;quot;, &amp;quot;steps_percentage&amp;quot;: 10, &amp;quot;target_percentage&amp;quot;: 40}&amp;#x27;\nDEBUG:app:Query Params: {}\nDEBUG:app:Route: POST /text/v1/compress/\nDEBUG:groq._base_client:Request options: {&amp;#x27;method&amp;#x27;: &amp;#x27;post&amp;#x27;, &amp;#x27;url&amp;#x27;: &amp;#x27;/openai/v1/chat/completions&amp;#x27;, &amp;#x27;files&amp;#x27;: None, &amp;#x27;json_data&amp;#x27;: {&amp;#x27;messages&amp;#x27;: [{&amp;#x27;role&amp;#x27;: &amp;#x27;system&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate a JSON response following these rules:\\n1. Return multiple versions with DECREASING length:\\n   {&amp;quot;versions&amp;quot;: [{&amp;quot;text&amp;quot;: &amp;quot;longest&amp;quot;}, {&amp;quot;text&amp;quot;: &amp;quot;shorter&amp;quot;}, {&amp;quot;text&amp;quot;: &amp;quot;shortest&amp;quot;}]}\\n2. Each version must:\\n   - Match its target percentage exactly\\n   - Remove less important information gradually\\n   - Keep core technical terms\\n   - Maintain readability\\n3. Sort versions from longest to shortest\\n4. If task cannot be completed: {&amp;quot;error&amp;quot;: &amp;quot;specific reason&amp;quot;}&amp;#x27;}, {&amp;#x27;role&amp;#x27;: &amp;#x27;user&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate 5 versions with decreasing length:\\n        Target percentages: 100%, 85%, 70%, 55%, 40%\\n        Original length: 35 tokens\\n        Original text: The Text Transformation API offers a robust set of REST endpoints that enable developers to programmatically manipulate and transform text content. The operations include expansion, summarization, and chunking.&amp;#x27;}], &amp;#x27;model&amp;#x27;: &amp;#x27;llama3-groq-70b-8192-tool-use-preview&amp;#x27;, &amp;#x27;max_tokens&amp;#x27;: 1000, &amp;#x27;temperature&amp;#x27;: 0.7}}\nDEBUG:httpcore.http11:send_request_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.http11:send_request_headers.complete\nDEBUG:httpcore.http11:send_request_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.http11:send_request_body.complete\nDEBUG:httpcore.http11:receive_response_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.http11:receive_response_headers.complete return_value=(b&amp;#x27;HTTP/1.1&amp;#x27;, 200, b&amp;#x27;OK&amp;#x27;, [(b&amp;#x27;Date&amp;#x27;, b&amp;#x27;Wed, 30 Oct 2024 15:53:16 GMT&amp;#x27;), (b&amp;#x27;Content-Type&amp;#x27;, b&amp;#x27;application/json&amp;#x27;), (b&amp;#x27;Transfer-Encoding&amp;#x27;, b&amp;#x27;chunked&amp;#x27;), (b&amp;#x27;Connection&amp;#x27;, b&amp;#x27;keep-alive&amp;#x27;), (b&amp;#x27;Cache-Control&amp;#x27;, b&amp;#x27;private, max-age=0, no-store, no-cache, must-revalidate&amp;#x27;), (b&amp;#x27;vary&amp;#x27;, b&amp;#x27;Origin&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-requests&amp;#x27;, b&amp;#x27;14400&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-tokens&amp;#x27;, b&amp;#x27;15000&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-requests&amp;#x27;, b&amp;#x27;14397&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-tokens&amp;#x27;, b&amp;#x27;14658&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-requests&amp;#x27;, b&amp;#x27;16.819999999s&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-tokens&amp;#x27;, b&amp;#x27;1.367s&amp;#x27;), (b&amp;#x27;x-request-id&amp;#x27;, b&amp;#x27;req_01jbf2356mfb0vf6gnx1qw56vy&amp;#x27;), (b&amp;#x27;via&amp;#x27;, b&amp;#x27;1.1 google&amp;#x27;), (b&amp;#x27;alt-svc&amp;#x27;, b&amp;#x27;h3=&amp;quot;:443&amp;quot;; ma=86400&amp;#x27;), (b&amp;#x27;CF-Cache-Status&amp;#x27;, b&amp;#x27;DYNAMIC&amp;#x27;), (b&amp;#x27;Server&amp;#x27;, b&amp;#x27;cloudflare&amp;#x27;), (b&amp;#x27;CF-RAY&amp;#x27;, b&amp;#x27;8dac93c0bde6ca58-HAM&amp;#x27;), (b&amp;#x27;Content-Encoding&amp;#x27;, b&amp;#x27;gzip&amp;#x27;)])\nINFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;HTTP/1.1 200 OK&amp;quot;\nDEBUG:httpcore.http11:receive_response_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.http11:receive_response_body.complete\nDEBUG:httpcore.http11:response_closed.started\nDEBUG:httpcore.http11:response_closed.complete\nDEBUG:groq._base_client:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;200 OK&amp;quot;\n\n------------------------------ Captured log call -------------------------------\nDEBUG    app:__init__.py:31 Headers: {&amp;#x27;User-Agent&amp;#x27;: &amp;#x27;Werkzeug/3.0.6&amp;#x27;, &amp;#x27;Host&amp;#x27;: &amp;#x27;localhost&amp;#x27;, &amp;#x27;Content-Type&amp;#x27;: &amp;#x27;application/json&amp;#x27;, &amp;#x27;Content-Length&amp;#x27;: &amp;#x27;274&amp;#x27;, &amp;#x27;Authorization&amp;#x27;: &amp;#x27;Bearer test_key&amp;#x27;}\nDEBUG    app:__init__.py:32 Body: b&amp;#x27;{&amp;quot;content&amp;quot;: &amp;quot;The Text Transformation API offers a robust set of REST endpoints that enable developers to programmatically manipulate and transform text content. The operations include expansion, summarization, and chunking.&amp;quot;, &amp;quot;steps_percentage&amp;quot;: 10, &amp;quot;target_percentage&amp;quot;: 40}&amp;#x27;\nDEBUG    app:__init__.py:33 Query Params: {}\nDEBUG    app:__init__.py:34 Route: POST /text/v1/compress/\nDEBUG    groq._base_client:_base_client.py:441 Request options: {&amp;#x27;method&amp;#x27;: &amp;#x27;post&amp;#x27;, &amp;#x27;url&amp;#x27;: &amp;#x27;/openai/v1/chat/completions&amp;#x27;, &amp;#x27;files&amp;#x27;: None, &amp;#x27;json_data&amp;#x27;: {&amp;#x27;messages&amp;#x27;: [{&amp;#x27;role&amp;#x27;: &amp;#x27;system&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate a JSON response following these rules:\\n1. Return multiple versions with DECREASING length:\\n   {&amp;quot;versions&amp;quot;: [{&amp;quot;text&amp;quot;: &amp;quot;longest&amp;quot;}, {&amp;quot;text&amp;quot;: &amp;quot;shorter&amp;quot;}, {&amp;quot;text&amp;quot;: &amp;quot;shortest&amp;quot;}]}\\n2. Each version must:\\n   - Match its target percentage exactly\\n   - Remove less important information gradually\\n   - Keep core technical terms\\n   - Maintain readability\\n3. Sort versions from longest to shortest\\n4. If task cannot be completed: {&amp;quot;error&amp;quot;: &amp;quot;specific reason&amp;quot;}&amp;#x27;}, {&amp;#x27;role&amp;#x27;: &amp;#x27;user&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate 5 versions with decreasing length:\\n        Target percentages: 100%, 85%, 70%, 55%, 40%\\n        Original length: 35 tokens\\n        Original text: The Text Transformation API offers a robust set of REST endpoints that enable developers to programmatically manipulate and transform text content. The operations include expansion, summarization, and chunking.&amp;#x27;}], &amp;#x27;model&amp;#x27;: &amp;#x27;llama3-groq-70b-8192-tool-use-preview&amp;#x27;, &amp;#x27;max_tokens&amp;#x27;: 1000, &amp;#x27;temperature&amp;#x27;: 0.7}}\nDEBUG    httpcore.http11:_trace.py:45 send_request_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 send_request_headers.complete\nDEBUG    httpcore.http11:_trace.py:45 send_request_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 send_request_body.complete\nDEBUG    httpcore.http11:_trace.py:45 receive_response_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 receive_response_headers.complete return_value=(b&amp;#x27;HTTP/1.1&amp;#x27;, 200, b&amp;#x27;OK&amp;#x27;, [(b&amp;#x27;Date&amp;#x27;, b&amp;#x27;Wed, 30 Oct 2024 15:53:16 GMT&amp;#x27;), (b&amp;#x27;Content-Type&amp;#x27;, b&amp;#x27;application/json&amp;#x27;), (b&amp;#x27;Transfer-Encoding&amp;#x27;, b&amp;#x27;chunked&amp;#x27;), (b&amp;#x27;Connection&amp;#x27;, b&amp;#x27;keep-alive&amp;#x27;), (b&amp;#x27;Cache-Control&amp;#x27;, b&amp;#x27;private, max-age=0, no-store, no-cache, must-revalidate&amp;#x27;), (b&amp;#x27;vary&amp;#x27;, b&amp;#x27;Origin&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-requests&amp;#x27;, b&amp;#x27;14400&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-tokens&amp;#x27;, b&amp;#x27;15000&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-requests&amp;#x27;, b&amp;#x27;14397&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-tokens&amp;#x27;, b&amp;#x27;14658&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-requests&amp;#x27;, b&amp;#x27;16.819999999s&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-tokens&amp;#x27;, b&amp;#x27;1.367s&amp;#x27;), (b&amp;#x27;x-request-id&amp;#x27;, b&amp;#x27;req_01jbf2356mfb0vf6gnx1qw56vy&amp;#x27;), (b&amp;#x27;via&amp;#x27;, b&amp;#x27;1.1 google&amp;#x27;), (b&amp;#x27;alt-svc&amp;#x27;, b&amp;#x27;h3=&amp;quot;:443&amp;quot;; ma=86400&amp;#x27;), (b&amp;#x27;CF-Cache-Status&amp;#x27;, b&amp;#x27;DYNAMIC&amp;#x27;), (b&amp;#x27;Server&amp;#x27;, b&amp;#x27;cloudflare&amp;#x27;), (b&amp;#x27;CF-RAY&amp;#x27;, b&amp;#x27;8dac93c0bde6ca58-HAM&amp;#x27;), (b&amp;#x27;Content-Encoding&amp;#x27;, b&amp;#x27;gzip&amp;#x27;)])\nINFO     httpx:_client.py:1038 HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;HTTP/1.1 200 OK&amp;quot;\nDEBUG    httpcore.http11:_trace.py:45 receive_response_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 receive_response_body.complete\nDEBUG    httpcore.http11:_trace.py:45 response_closed.started\nDEBUG    httpcore.http11:_trace.py:45 response_closed.complete\nDEBUG    groq._base_client:_base_client.py:956 HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;200 OK&amp;quot;\n\n&#34;}], &#34;tests/performance/test_compress_performance.py::TestCompressEndpoint::test_staggered_custom_range&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Failed&#34;, &#34;testId&#34;: &#34;tests/performance/test_compress_performance.py::TestCompressEndpoint::test_staggered_custom_range&#34;, &#34;duration&#34;: &#34;00:00:01&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Failed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/performance/test_compress_performance.py::TestCompressEndpoint::test_staggered_custom_range&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:01&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;self = &amp;lt;tests.test_compress.TestCompressEndpoint object at 0x106952f90&amp;gt;\nclient = &amp;lt;FlaskClient &amp;lt;Flask &amp;#x27;app&amp;#x27;&amp;gt;&amp;gt;\nauth_headers = {&amp;#x27;Authorization&amp;#x27;: &amp;#x27;Bearer test_key&amp;#x27;, &amp;#x27;Content-Type&amp;#x27;: &amp;#x27;application/json&amp;#x27;}\n\n    @pytest.mark.unit\n    def test_staggered_custom_range(self, client, auth_headers):\n        response = client.post(self.ENDPOINTS[&amp;#x27;compress&amp;#x27;], json={\n            &amp;#x27;content&amp;#x27;: self.SAMPLE_TEXT,\n            &amp;#x27;start_percentage&amp;#x27;: 60,\n            &amp;#x27;target_percentage&amp;#x27;: 40,\n            &amp;#x27;versions&amp;#x27;: 5\n        }, headers=auth_headers)\n    \n        data = response.json\n        percentages = data[&amp;#x27;metadata&amp;#x27;][&amp;#x27;target_percentages&amp;#x27;]\n&amp;gt;       assert percentages == [60, 55, 50, 45, 40]\nE       AssertionError: assert [40, 40, 40, 40, 40] == [60, 55, 50, 45, 40]\nE         \nE         At index 0 diff: 40 != 60\nE         \nE         Full diff:\nE           [\nE         -     60,\nE         ?     ^...\nE         \nE         ...Full output truncated (14 lines hidden), use &amp;#x27;-vv&amp;#x27; to show\n\ntests/test_compress.py:101: AssertionError\n\n---------------------------- Captured stderr setup -----------------------------\nDEBUG:app:Registering blueprints...\nDEBUG:app:Registered routes:\nDEBUG:app:static: /static/&amp;lt;path:filename&amp;gt; [GET, OPTIONS, HEAD]\nDEBUG:app:generate.create_text: /text/v1/generate/text [OPTIONS, POST]\nDEBUG:app:compress.compress_text: /text/v1/compress/ [OPTIONS, POST]\nDEBUG:app:expand.expand_text: /text/v1/expand/ [OPTIONS, POST]\n\n------------------------------ Captured log setup ------------------------------\nDEBUG    app:__init__.py:106 Registering blueprints...\nDEBUG    app:__init__.py:112 Registered routes:\nDEBUG    app:__init__.py:114 static: /static/&amp;lt;path:filename&amp;gt; [GET, OPTIONS, HEAD]\nDEBUG    app:__init__.py:114 generate.create_text: /text/v1/generate/text [OPTIONS, POST]\nDEBUG    app:__init__.py:114 compress.compress_text: /text/v1/compress/ [OPTIONS, POST]\nDEBUG    app:__init__.py:114 expand.expand_text: /text/v1/expand/ [OPTIONS, POST]\n\n----------------------------- Captured stderr call -----------------------------\nDEBUG:app:Headers: {&amp;#x27;User-Agent&amp;#x27;: &amp;#x27;Werkzeug/3.0.6&amp;#x27;, &amp;#x27;Host&amp;#x27;: &amp;#x27;localhost&amp;#x27;, &amp;#x27;Content-Type&amp;#x27;: &amp;#x27;application/json&amp;#x27;, &amp;#x27;Content-Length&amp;#x27;: &amp;#x27;289&amp;#x27;, &amp;#x27;Authorization&amp;#x27;: &amp;#x27;Bearer test_key&amp;#x27;}\nDEBUG:app:Body: b&amp;#x27;{&amp;quot;content&amp;quot;: &amp;quot;The Text Transformation API offers a robust set of REST endpoints that enable developers to programmatically manipulate and transform text content. The operations include expansion, summarization, and chunking.&amp;quot;, &amp;quot;start_percentage&amp;quot;: 60, &amp;quot;target_percentage&amp;quot;: 40, &amp;quot;versions&amp;quot;: 5}&amp;#x27;\nDEBUG:app:Query Params: {}\nDEBUG:app:Route: POST /text/v1/compress/\nDEBUG:groq._base_client:Request options: {&amp;#x27;method&amp;#x27;: &amp;#x27;post&amp;#x27;, &amp;#x27;url&amp;#x27;: &amp;#x27;/openai/v1/chat/completions&amp;#x27;, &amp;#x27;files&amp;#x27;: None, &amp;#x27;json_data&amp;#x27;: {&amp;#x27;messages&amp;#x27;: [{&amp;#x27;role&amp;#x27;: &amp;#x27;system&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate a JSON response following these rules:\\n1. Return multiple UNIQUE versions at the SAME length:\\n   {&amp;quot;versions&amp;quot;: [{&amp;quot;text&amp;quot;: &amp;quot;version1&amp;quot;}, {&amp;quot;text&amp;quot;: &amp;quot;version2&amp;quot;}]}\\n2. Each version must:\\n   - Target exactly the specified percentage\\n   - Use different sentence structures\\n   - Vary word choices while keeping technical terms\\n   - Maintain the same meaning\\n3. If task cannot be completed: {&amp;quot;error&amp;quot;: &amp;quot;specific reason&amp;quot;}&amp;#x27;}, {&amp;#x27;role&amp;#x27;: &amp;#x27;user&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate 5 UNIQUE versions at 40% length:\\n        - Each must be exactly the same length\\n        - Use different phrasings\\n        Original length: 35 tokens\\n        Original text: The Text Transformation API offers a robust set of REST endpoints that enable developers to programmatically manipulate and transform text content. The operations include expansion, summarization, and chunking.&amp;#x27;}], &amp;#x27;model&amp;#x27;: &amp;#x27;llama3-groq-70b-8192-tool-use-preview&amp;#x27;, &amp;#x27;max_tokens&amp;#x27;: 1000, &amp;#x27;temperature&amp;#x27;: 0.7}}\nDEBUG:httpcore.http11:send_request_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.http11:send_request_headers.complete\nDEBUG:httpcore.http11:send_request_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.http11:send_request_body.complete\nDEBUG:httpcore.http11:receive_response_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.http11:receive_response_headers.complete return_value=(b&amp;#x27;HTTP/1.1&amp;#x27;, 200, b&amp;#x27;OK&amp;#x27;, [(b&amp;#x27;Date&amp;#x27;, b&amp;#x27;Wed, 30 Oct 2024 15:53:17 GMT&amp;#x27;), (b&amp;#x27;Content-Type&amp;#x27;, b&amp;#x27;application/json&amp;#x27;), (b&amp;#x27;Transfer-Encoding&amp;#x27;, b&amp;#x27;chunked&amp;#x27;), (b&amp;#x27;Connection&amp;#x27;, b&amp;#x27;keep-alive&amp;#x27;), (b&amp;#x27;Cache-Control&amp;#x27;, b&amp;#x27;private, max-age=0, no-store, no-cache, must-revalidate&amp;#x27;), (b&amp;#x27;vary&amp;#x27;, b&amp;#x27;Origin&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-requests&amp;#x27;, b&amp;#x27;14400&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-tokens&amp;#x27;, b&amp;#x27;15000&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-requests&amp;#x27;, b&amp;#x27;14396&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-tokens&amp;#x27;, b&amp;#x27;14589&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-requests&amp;#x27;, b&amp;#x27;22.618s&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-tokens&amp;#x27;, b&amp;#x27;1.641s&amp;#x27;), (b&amp;#x27;x-request-id&amp;#x27;, b&amp;#x27;req_01jbf236hteasrj09bpnp5cy3y&amp;#x27;), (b&amp;#x27;via&amp;#x27;, b&amp;#x27;1.1 google&amp;#x27;), (b&amp;#x27;alt-svc&amp;#x27;, b&amp;#x27;h3=&amp;quot;:443&amp;quot;; ma=86400&amp;#x27;), (b&amp;#x27;CF-Cache-Status&amp;#x27;, b&amp;#x27;DYNAMIC&amp;#x27;), (b&amp;#x27;Server&amp;#x27;, b&amp;#x27;cloudflare&amp;#x27;), (b&amp;#x27;CF-RAY&amp;#x27;, b&amp;#x27;8dac93c968b4ca58-HAM&amp;#x27;), (b&amp;#x27;Content-Encoding&amp;#x27;, b&amp;#x27;gzip&amp;#x27;)])\nINFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;HTTP/1.1 200 OK&amp;quot;\nDEBUG:httpcore.http11:receive_response_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.http11:receive_response_body.complete\nDEBUG:httpcore.http11:response_closed.started\nDEBUG:httpcore.http11:response_closed.complete\nDEBUG:groq._base_client:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;200 OK&amp;quot;\n\n------------------------------ Captured log call -------------------------------\nDEBUG    app:__init__.py:31 Headers: {&amp;#x27;User-Agent&amp;#x27;: &amp;#x27;Werkzeug/3.0.6&amp;#x27;, &amp;#x27;Host&amp;#x27;: &amp;#x27;localhost&amp;#x27;, &amp;#x27;Content-Type&amp;#x27;: &amp;#x27;application/json&amp;#x27;, &amp;#x27;Content-Length&amp;#x27;: &amp;#x27;289&amp;#x27;, &amp;#x27;Authorization&amp;#x27;: &amp;#x27;Bearer test_key&amp;#x27;}\nDEBUG    app:__init__.py:32 Body: b&amp;#x27;{&amp;quot;content&amp;quot;: &amp;quot;The Text Transformation API offers a robust set of REST endpoints that enable developers to programmatically manipulate and transform text content. The operations include expansion, summarization, and chunking.&amp;quot;, &amp;quot;start_percentage&amp;quot;: 60, &amp;quot;target_percentage&amp;quot;: 40, &amp;quot;versions&amp;quot;: 5}&amp;#x27;\nDEBUG    app:__init__.py:33 Query Params: {}\nDEBUG    app:__init__.py:34 Route: POST /text/v1/compress/\nDEBUG    groq._base_client:_base_client.py:441 Request options: {&amp;#x27;method&amp;#x27;: &amp;#x27;post&amp;#x27;, &amp;#x27;url&amp;#x27;: &amp;#x27;/openai/v1/chat/completions&amp;#x27;, &amp;#x27;files&amp;#x27;: None, &amp;#x27;json_data&amp;#x27;: {&amp;#x27;messages&amp;#x27;: [{&amp;#x27;role&amp;#x27;: &amp;#x27;system&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate a JSON response following these rules:\\n1. Return multiple UNIQUE versions at the SAME length:\\n   {&amp;quot;versions&amp;quot;: [{&amp;quot;text&amp;quot;: &amp;quot;version1&amp;quot;}, {&amp;quot;text&amp;quot;: &amp;quot;version2&amp;quot;}]}\\n2. Each version must:\\n   - Target exactly the specified percentage\\n   - Use different sentence structures\\n   - Vary word choices while keeping technical terms\\n   - Maintain the same meaning\\n3. If task cannot be completed: {&amp;quot;error&amp;quot;: &amp;quot;specific reason&amp;quot;}&amp;#x27;}, {&amp;#x27;role&amp;#x27;: &amp;#x27;user&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate 5 UNIQUE versions at 40% length:\\n        - Each must be exactly the same length\\n        - Use different phrasings\\n        Original length: 35 tokens\\n        Original text: The Text Transformation API offers a robust set of REST endpoints that enable developers to programmatically manipulate and transform text content. The operations include expansion, summarization, and chunking.&amp;#x27;}], &amp;#x27;model&amp;#x27;: &amp;#x27;llama3-groq-70b-8192-tool-use-preview&amp;#x27;, &amp;#x27;max_tokens&amp;#x27;: 1000, &amp;#x27;temperature&amp;#x27;: 0.7}}\nDEBUG    httpcore.http11:_trace.py:45 send_request_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 send_request_headers.complete\nDEBUG    httpcore.http11:_trace.py:45 send_request_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 send_request_body.complete\nDEBUG    httpcore.http11:_trace.py:45 receive_response_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 receive_response_headers.complete return_value=(b&amp;#x27;HTTP/1.1&amp;#x27;, 200, b&amp;#x27;OK&amp;#x27;, [(b&amp;#x27;Date&amp;#x27;, b&amp;#x27;Wed, 30 Oct 2024 15:53:17 GMT&amp;#x27;), (b&amp;#x27;Content-Type&amp;#x27;, b&amp;#x27;application/json&amp;#x27;), (b&amp;#x27;Transfer-Encoding&amp;#x27;, b&amp;#x27;chunked&amp;#x27;), (b&amp;#x27;Connection&amp;#x27;, b&amp;#x27;keep-alive&amp;#x27;), (b&amp;#x27;Cache-Control&amp;#x27;, b&amp;#x27;private, max-age=0, no-store, no-cache, must-revalidate&amp;#x27;), (b&amp;#x27;vary&amp;#x27;, b&amp;#x27;Origin&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-requests&amp;#x27;, b&amp;#x27;14400&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-tokens&amp;#x27;, b&amp;#x27;15000&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-requests&amp;#x27;, b&amp;#x27;14396&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-tokens&amp;#x27;, b&amp;#x27;14589&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-requests&amp;#x27;, b&amp;#x27;22.618s&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-tokens&amp;#x27;, b&amp;#x27;1.641s&amp;#x27;), (b&amp;#x27;x-request-id&amp;#x27;, b&amp;#x27;req_01jbf236hteasrj09bpnp5cy3y&amp;#x27;), (b&amp;#x27;via&amp;#x27;, b&amp;#x27;1.1 google&amp;#x27;), (b&amp;#x27;alt-svc&amp;#x27;, b&amp;#x27;h3=&amp;quot;:443&amp;quot;; ma=86400&amp;#x27;), (b&amp;#x27;CF-Cache-Status&amp;#x27;, b&amp;#x27;DYNAMIC&amp;#x27;), (b&amp;#x27;Server&amp;#x27;, b&amp;#x27;cloudflare&amp;#x27;), (b&amp;#x27;CF-RAY&amp;#x27;, b&amp;#x27;8dac93c968b4ca58-HAM&amp;#x27;), (b&amp;#x27;Content-Encoding&amp;#x27;, b&amp;#x27;gzip&amp;#x27;)])\nINFO     httpx:_client.py:1038 HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;HTTP/1.1 200 OK&amp;quot;\nDEBUG    httpcore.http11:_trace.py:45 receive_response_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 receive_response_body.complete\nDEBUG    httpcore.http11:_trace.py:45 response_closed.started\nDEBUG    httpcore.http11:_trace.py:45 response_closed.complete\nDEBUG    groq._base_client:_base_client.py:956 HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;200 OK&amp;quot;\n\n&#34;}], &#34;tests/performance/test_compress_performance.py::TestCompressEndpoint::test_array_input&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Failed&#34;, &#34;testId&#34;: &#34;tests/performance/test_compress_performance.py::TestCompressEndpoint::test_array_input&#34;, &#34;duration&#34;: &#34;00:00:02&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Failed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/performance/test_compress_performance.py::TestCompressEndpoint::test_array_input&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:02&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;self = &amp;lt;tests.test_compress.TestCompressEndpoint object at 0x106953170&amp;gt;\nclient = &amp;lt;FlaskClient &amp;lt;Flask &amp;#x27;app&amp;#x27;&amp;gt;&amp;gt;\nauth_headers = {&amp;#x27;Authorization&amp;#x27;: &amp;#x27;Bearer test_key&amp;#x27;, &amp;#x27;Content-Type&amp;#x27;: &amp;#x27;application/json&amp;#x27;}\n\n    @pytest.mark.unit\n    def test_array_input(self, client, auth_headers):\n        response = client.post(self.ENDPOINTS[&amp;#x27;compress&amp;#x27;], json={\n            &amp;#x27;content&amp;#x27;: [\n                &amp;quot;The Text Transformation API offers REST endpoints&amp;quot;,\n                &amp;quot;These endpoints enable text manipulation&amp;quot;,\n                &amp;quot;Operations include various transformations&amp;quot;\n            ],\n            &amp;#x27;target_percentage&amp;#x27;: 50,\n            &amp;#x27;versions&amp;#x27;: 2\n        }, headers=auth_headers)\n    \n        data = response.json\n        assert data[&amp;#x27;type&amp;#x27;] == &amp;#x27;fragments&amp;#x27;\n        assert len(data[&amp;#x27;fragments&amp;#x27;]) == 3\n    \n        for fragment in data[&amp;#x27;fragments&amp;#x27;]:\n            assert len(fragment[&amp;#x27;versions&amp;#x27;]) == 2\n            for version in fragment[&amp;#x27;versions&amp;#x27;]:\n                assert &amp;#x27;text&amp;#x27; in version\n                assert &amp;#x27;final_percentage&amp;#x27; in version\n                assert isinstance(version[&amp;#x27;final_percentage&amp;#x27;], float)\n                # Check if compression is roughly within target\n&amp;gt;               assert abs(version[&amp;#x27;final_percentage&amp;#x27;] - 50) &amp;lt;= 10\nE               assert 54.099999999999994 &amp;lt;= 10\nE                +  where 54.099999999999994 = abs((104.1 - 50))\n\ntests/test_compress.py:126: AssertionError\n\n---------------------------- Captured stderr setup -----------------------------\nDEBUG:app:Registering blueprints...\nDEBUG:app:Registered routes:\nDEBUG:app:static: /static/&amp;lt;path:filename&amp;gt; [GET, OPTIONS, HEAD]\nDEBUG:app:generate.create_text: /text/v1/generate/text [OPTIONS, POST]\nDEBUG:app:compress.compress_text: /text/v1/compress/ [OPTIONS, POST]\nDEBUG:app:expand.expand_text: /text/v1/expand/ [OPTIONS, POST]\n\n------------------------------ Captured log setup ------------------------------\nDEBUG    app:__init__.py:106 Registering blueprints...\nDEBUG    app:__init__.py:112 Registered routes:\nDEBUG    app:__init__.py:114 static: /static/&amp;lt;path:filename&amp;gt; [GET, OPTIONS, HEAD]\nDEBUG    app:__init__.py:114 generate.create_text: /text/v1/generate/text [OPTIONS, POST]\nDEBUG    app:__init__.py:114 compress.compress_text: /text/v1/compress/ [OPTIONS, POST]\nDEBUG    app:__init__.py:114 expand.expand_text: /text/v1/expand/ [OPTIONS, POST]\n\n----------------------------- Captured stderr call -----------------------------\nDEBUG:app:Headers: {&amp;#x27;User-Agent&amp;#x27;: &amp;#x27;Werkzeug/3.0.6&amp;#x27;, &amp;#x27;Host&amp;#x27;: &amp;#x27;localhost&amp;#x27;, &amp;#x27;Content-Type&amp;#x27;: &amp;#x27;application/json&amp;#x27;, &amp;#x27;Content-Length&amp;#x27;: &amp;#x27;196&amp;#x27;, &amp;#x27;Authorization&amp;#x27;: &amp;#x27;Bearer test_key&amp;#x27;}\nDEBUG:app:Body: b&amp;#x27;{&amp;quot;content&amp;quot;: [&amp;quot;The Text Transformation API offers REST endpoints&amp;quot;, &amp;quot;These endpoints enable text manipulation&amp;quot;, &amp;quot;Operations include various transformations&amp;quot;], &amp;quot;target_percentage&amp;quot;: 50, &amp;quot;versions&amp;quot;: 2}&amp;#x27;\nDEBUG:app:Query Params: {}\nDEBUG:app:Route: POST /text/v1/compress/\nDEBUG:groq._base_client:Request options: {&amp;#x27;method&amp;#x27;: &amp;#x27;post&amp;#x27;, &amp;#x27;url&amp;#x27;: &amp;#x27;/openai/v1/chat/completions&amp;#x27;, &amp;#x27;files&amp;#x27;: None, &amp;#x27;json_data&amp;#x27;: {&amp;#x27;messages&amp;#x27;: [{&amp;#x27;role&amp;#x27;: &amp;#x27;system&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate a JSON response following these rules:\\n1. Return multiple UNIQUE versions at the SAME length:\\n   {&amp;quot;versions&amp;quot;: [{&amp;quot;text&amp;quot;: &amp;quot;version1&amp;quot;}, {&amp;quot;text&amp;quot;: &amp;quot;version2&amp;quot;}]}\\n2. Each version must:\\n   - Target exactly the specified percentage\\n   - Use different sentence structures\\n   - Vary word choices while keeping technical terms\\n   - Maintain the same meaning\\n3. If task cannot be completed: {&amp;quot;error&amp;quot;: &amp;quot;specific reason&amp;quot;}&amp;#x27;}, {&amp;#x27;role&amp;#x27;: &amp;#x27;user&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate 2 UNIQUE versions at 50% length:\\n        - Each must be exactly the same length\\n        - Use different phrasings\\n        Original length: 7 tokens\\n        Original text: The Text Transformation API offers REST endpoints&amp;#x27;}], &amp;#x27;model&amp;#x27;: &amp;#x27;llama3-groq-70b-8192-tool-use-preview&amp;#x27;, &amp;#x27;max_tokens&amp;#x27;: 1000, &amp;#x27;temperature&amp;#x27;: 0.7}}\nDEBUG:httpcore.http11:send_request_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.http11:send_request_headers.complete\nDEBUG:httpcore.http11:send_request_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.http11:send_request_body.complete\nDEBUG:httpcore.http11:receive_response_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.http11:receive_response_headers.complete return_value=(b&amp;#x27;HTTP/1.1&amp;#x27;, 200, b&amp;#x27;OK&amp;#x27;, [(b&amp;#x27;Date&amp;#x27;, b&amp;#x27;Wed, 30 Oct 2024 15:53:18 GMT&amp;#x27;), (b&amp;#x27;Content-Type&amp;#x27;, b&amp;#x27;application/json&amp;#x27;), (b&amp;#x27;Transfer-Encoding&amp;#x27;, b&amp;#x27;chunked&amp;#x27;), (b&amp;#x27;Connection&amp;#x27;, b&amp;#x27;keep-alive&amp;#x27;), (b&amp;#x27;Cache-Control&amp;#x27;, b&amp;#x27;private, max-age=0, no-store, no-cache, must-revalidate&amp;#x27;), (b&amp;#x27;vary&amp;#x27;, b&amp;#x27;Origin&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-requests&amp;#x27;, b&amp;#x27;14400&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-tokens&amp;#x27;, b&amp;#x27;15000&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-requests&amp;#x27;, b&amp;#x27;14395&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-tokens&amp;#x27;, b&amp;#x27;14617&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-requests&amp;#x27;, b&amp;#x27;28.512s&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-tokens&amp;#x27;, b&amp;#x27;1.532s&amp;#x27;), (b&amp;#x27;x-request-id&amp;#x27;, b&amp;#x27;req_01jbf2380dfvtbahqckbsj0gpm&amp;#x27;), (b&amp;#x27;via&amp;#x27;, b&amp;#x27;1.1 google&amp;#x27;), (b&amp;#x27;alt-svc&amp;#x27;, b&amp;#x27;h3=&amp;quot;:443&amp;quot;; ma=86400&amp;#x27;), (b&amp;#x27;CF-Cache-Status&amp;#x27;, b&amp;#x27;DYNAMIC&amp;#x27;), (b&amp;#x27;Server&amp;#x27;, b&amp;#x27;cloudflare&amp;#x27;), (b&amp;#x27;CF-RAY&amp;#x27;, b&amp;#x27;8dac93d2bc6bca58-HAM&amp;#x27;), (b&amp;#x27;Content-Encoding&amp;#x27;, b&amp;#x27;gzip&amp;#x27;)])\nINFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;HTTP/1.1 200 OK&amp;quot;\nDEBUG:httpcore.http11:receive_response_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.http11:receive_response_body.complete\nDEBUG:httpcore.http11:response_closed.started\nDEBUG:httpcore.http11:response_closed.complete\nDEBUG:groq._base_client:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;200 OK&amp;quot;\nDEBUG:groq._base_client:Request options: {&amp;#x27;method&amp;#x27;: &amp;#x27;post&amp;#x27;, &amp;#x27;url&amp;#x27;: &amp;#x27;/openai/v1/chat/completions&amp;#x27;, &amp;#x27;files&amp;#x27;: None, &amp;#x27;json_data&amp;#x27;: {&amp;#x27;messages&amp;#x27;: [{&amp;#x27;role&amp;#x27;: &amp;#x27;system&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate a JSON response following these rules:\\n1. Return multiple UNIQUE versions at the SAME length:\\n   {&amp;quot;versions&amp;quot;: [{&amp;quot;text&amp;quot;: &amp;quot;version1&amp;quot;}, {&amp;quot;text&amp;quot;: &amp;quot;version2&amp;quot;}]}\\n2. Each version must:\\n   - Target exactly the specified percentage\\n   - Use different sentence structures\\n   - Vary word choices while keeping technical terms\\n   - Maintain the same meaning\\n3. If task cannot be completed: {&amp;quot;error&amp;quot;: &amp;quot;specific reason&amp;quot;}&amp;#x27;}, {&amp;#x27;role&amp;#x27;: &amp;#x27;user&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate 2 UNIQUE versions at 50% length:\\n        - Each must be exactly the same length\\n        - Use different phrasings\\n        Original length: 5 tokens\\n        Original text: These endpoints enable text manipulation&amp;#x27;}], &amp;#x27;model&amp;#x27;: &amp;#x27;llama3-groq-70b-8192-tool-use-preview&amp;#x27;, &amp;#x27;max_tokens&amp;#x27;: 1000, &amp;#x27;temperature&amp;#x27;: 0.7}}\nDEBUG:httpcore.http11:send_request_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.http11:send_request_headers.complete\nDEBUG:httpcore.http11:send_request_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.http11:send_request_body.complete\nDEBUG:httpcore.http11:receive_response_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.http11:receive_response_headers.complete return_value=(b&amp;#x27;HTTP/1.1&amp;#x27;, 200, b&amp;#x27;OK&amp;#x27;, [(b&amp;#x27;Date&amp;#x27;, b&amp;#x27;Wed, 30 Oct 2024 15:53:19 GMT&amp;#x27;), (b&amp;#x27;Content-Type&amp;#x27;, b&amp;#x27;application/json&amp;#x27;), (b&amp;#x27;Transfer-Encoding&amp;#x27;, b&amp;#x27;chunked&amp;#x27;), (b&amp;#x27;Connection&amp;#x27;, b&amp;#x27;keep-alive&amp;#x27;), (b&amp;#x27;Cache-Control&amp;#x27;, b&amp;#x27;private, max-age=0, no-store, no-cache, must-revalidate&amp;#x27;), (b&amp;#x27;vary&amp;#x27;, b&amp;#x27;Origin&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-requests&amp;#x27;, b&amp;#x27;14400&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-tokens&amp;#x27;, b&amp;#x27;15000&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-requests&amp;#x27;, b&amp;#x27;14394&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-tokens&amp;#x27;, b&amp;#x27;14522&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-requests&amp;#x27;, b&amp;#x27;35.641s&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-tokens&amp;#x27;, b&amp;#x27;1.911s&amp;#x27;), (b&amp;#x27;x-request-id&amp;#x27;, b&amp;#x27;req_01jbf238bjfskrn6cj4g9r1hw3&amp;#x27;), (b&amp;#x27;via&amp;#x27;, b&amp;#x27;1.1 google&amp;#x27;), (b&amp;#x27;alt-svc&amp;#x27;, b&amp;#x27;h3=&amp;quot;:443&amp;quot;; ma=86400&amp;#x27;), (b&amp;#x27;CF-Cache-Status&amp;#x27;, b&amp;#x27;DYNAMIC&amp;#x27;), (b&amp;#x27;Server&amp;#x27;, b&amp;#x27;cloudflare&amp;#x27;), (b&amp;#x27;CF-RAY&amp;#x27;, b&amp;#x27;8dac93d4fee2ca58-HAM&amp;#x27;), (b&amp;#x27;Content-Encoding&amp;#x27;, b&amp;#x27;gzip&amp;#x27;)])\nINFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;HTTP/1.1 200 OK&amp;quot;\nDEBUG:httpcore.http11:receive_response_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.http11:receive_response_body.complete\nDEBUG:httpcore.http11:response_closed.started\nDEBUG:httpcore.http11:response_closed.complete\nDEBUG:groq._base_client:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;200 OK&amp;quot;\nDEBUG:groq._base_client:Request options: {&amp;#x27;method&amp;#x27;: &amp;#x27;post&amp;#x27;, &amp;#x27;url&amp;#x27;: &amp;#x27;/openai/v1/chat/completions&amp;#x27;, &amp;#x27;files&amp;#x27;: None, &amp;#x27;json_data&amp;#x27;: {&amp;#x27;messages&amp;#x27;: [{&amp;#x27;role&amp;#x27;: &amp;#x27;system&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate a JSON response following these rules:\\n1. Return multiple UNIQUE versions at the SAME length:\\n   {&amp;quot;versions&amp;quot;: [{&amp;quot;text&amp;quot;: &amp;quot;version1&amp;quot;}, {&amp;quot;text&amp;quot;: &amp;quot;version2&amp;quot;}]}\\n2. Each version must:\\n   - Target exactly the specified percentage\\n   - Use different sentence structures\\n   - Vary word choices while keeping technical terms\\n   - Maintain the same meaning\\n3. If task cannot be completed: {&amp;quot;error&amp;quot;: &amp;quot;specific reason&amp;quot;}&amp;#x27;}, {&amp;#x27;role&amp;#x27;: &amp;#x27;user&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate 2 UNIQUE versions at 50% length:\\n        - Each must be exactly the same length\\n        - Use different phrasings\\n        Original length: 4 tokens\\n        Original text: Operations include various transformations&amp;#x27;}], &amp;#x27;model&amp;#x27;: &amp;#x27;llama3-groq-70b-8192-tool-use-preview&amp;#x27;, &amp;#x27;max_tokens&amp;#x27;: 1000, &amp;#x27;temperature&amp;#x27;: 0.7}}\nDEBUG:httpcore.http11:send_request_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.http11:send_request_headers.complete\nDEBUG:httpcore.http11:send_request_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.http11:send_request_body.complete\nDEBUG:httpcore.http11:receive_response_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.http11:receive_response_headers.complete return_value=(b&amp;#x27;HTTP/1.1&amp;#x27;, 200, b&amp;#x27;OK&amp;#x27;, [(b&amp;#x27;Date&amp;#x27;, b&amp;#x27;Wed, 30 Oct 2024 15:53:19 GMT&amp;#x27;), (b&amp;#x27;Content-Type&amp;#x27;, b&amp;#x27;application/json&amp;#x27;), (b&amp;#x27;Transfer-Encoding&amp;#x27;, b&amp;#x27;chunked&amp;#x27;), (b&amp;#x27;Connection&amp;#x27;, b&amp;#x27;keep-alive&amp;#x27;), (b&amp;#x27;Cache-Control&amp;#x27;, b&amp;#x27;private, max-age=0, no-store, no-cache, must-revalidate&amp;#x27;), (b&amp;#x27;vary&amp;#x27;, b&amp;#x27;Origin&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-requests&amp;#x27;, b&amp;#x27;14400&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-tokens&amp;#x27;, b&amp;#x27;15000&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-requests&amp;#x27;, b&amp;#x27;14393&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-tokens&amp;#x27;, b&amp;#x27;14427&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-requests&amp;#x27;, b&amp;#x27;41.668999999s&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-tokens&amp;#x27;, b&amp;#x27;2.292s&amp;#x27;), (b&amp;#x27;x-request-id&amp;#x27;, b&amp;#x27;req_01jbf238nzf498er0syr08j4n7&amp;#x27;), (b&amp;#x27;via&amp;#x27;, b&amp;#x27;1.1 google&amp;#x27;), (b&amp;#x27;alt-svc&amp;#x27;, b&amp;#x27;h3=&amp;quot;:443&amp;quot;; ma=86400&amp;#x27;), (b&amp;#x27;CF-Cache-Status&amp;#x27;, b&amp;#x27;DYNAMIC&amp;#x27;), (b&amp;#x27;Server&amp;#x27;, b&amp;#x27;cloudflare&amp;#x27;), (b&amp;#x27;CF-RAY&amp;#x27;, b&amp;#x27;8dac93d6f9a9ca58-HAM&amp;#x27;), (b&amp;#x27;Content-Encoding&amp;#x27;, b&amp;#x27;gzip&amp;#x27;)])\nINFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;HTTP/1.1 200 OK&amp;quot;\nDEBUG:httpcore.http11:receive_response_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.http11:receive_response_body.complete\nDEBUG:httpcore.http11:response_closed.started\nDEBUG:httpcore.http11:response_closed.complete\nDEBUG:groq._base_client:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;200 OK&amp;quot;\n\n------------------------------ Captured log call -------------------------------\nDEBUG    app:__init__.py:31 Headers: {&amp;#x27;User-Agent&amp;#x27;: &amp;#x27;Werkzeug/3.0.6&amp;#x27;, &amp;#x27;Host&amp;#x27;: &amp;#x27;localhost&amp;#x27;, &amp;#x27;Content-Type&amp;#x27;: &amp;#x27;application/json&amp;#x27;, &amp;#x27;Content-Length&amp;#x27;: &amp;#x27;196&amp;#x27;, &amp;#x27;Authorization&amp;#x27;: &amp;#x27;Bearer test_key&amp;#x27;}\nDEBUG    app:__init__.py:32 Body: b&amp;#x27;{&amp;quot;content&amp;quot;: [&amp;quot;The Text Transformation API offers REST endpoints&amp;quot;, &amp;quot;These endpoints enable text manipulation&amp;quot;, &amp;quot;Operations include various transformations&amp;quot;], &amp;quot;target_percentage&amp;quot;: 50, &amp;quot;versions&amp;quot;: 2}&amp;#x27;\nDEBUG    app:__init__.py:33 Query Params: {}\nDEBUG    app:__init__.py:34 Route: POST /text/v1/compress/\nDEBUG    groq._base_client:_base_client.py:441 Request options: {&amp;#x27;method&amp;#x27;: &amp;#x27;post&amp;#x27;, &amp;#x27;url&amp;#x27;: &amp;#x27;/openai/v1/chat/completions&amp;#x27;, &amp;#x27;files&amp;#x27;: None, &amp;#x27;json_data&amp;#x27;: {&amp;#x27;messages&amp;#x27;: [{&amp;#x27;role&amp;#x27;: &amp;#x27;system&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate a JSON response following these rules:\\n1. Return multiple UNIQUE versions at the SAME length:\\n   {&amp;quot;versions&amp;quot;: [{&amp;quot;text&amp;quot;: &amp;quot;version1&amp;quot;}, {&amp;quot;text&amp;quot;: &amp;quot;version2&amp;quot;}]}\\n2. Each version must:\\n   - Target exactly the specified percentage\\n   - Use different sentence structures\\n   - Vary word choices while keeping technical terms\\n   - Maintain the same meaning\\n3. If task cannot be completed: {&amp;quot;error&amp;quot;: &amp;quot;specific reason&amp;quot;}&amp;#x27;}, {&amp;#x27;role&amp;#x27;: &amp;#x27;user&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate 2 UNIQUE versions at 50% length:\\n        - Each must be exactly the same length\\n        - Use different phrasings\\n        Original length: 7 tokens\\n        Original text: The Text Transformation API offers REST endpoints&amp;#x27;}], &amp;#x27;model&amp;#x27;: &amp;#x27;llama3-groq-70b-8192-tool-use-preview&amp;#x27;, &amp;#x27;max_tokens&amp;#x27;: 1000, &amp;#x27;temperature&amp;#x27;: 0.7}}\nDEBUG    httpcore.http11:_trace.py:45 send_request_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 send_request_headers.complete\nDEBUG    httpcore.http11:_trace.py:45 send_request_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 send_request_body.complete\nDEBUG    httpcore.http11:_trace.py:45 receive_response_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 receive_response_headers.complete return_value=(b&amp;#x27;HTTP/1.1&amp;#x27;, 200, b&amp;#x27;OK&amp;#x27;, [(b&amp;#x27;Date&amp;#x27;, b&amp;#x27;Wed, 30 Oct 2024 15:53:18 GMT&amp;#x27;), (b&amp;#x27;Content-Type&amp;#x27;, b&amp;#x27;application/json&amp;#x27;), (b&amp;#x27;Transfer-Encoding&amp;#x27;, b&amp;#x27;chunked&amp;#x27;), (b&amp;#x27;Connection&amp;#x27;, b&amp;#x27;keep-alive&amp;#x27;), (b&amp;#x27;Cache-Control&amp;#x27;, b&amp;#x27;private, max-age=0, no-store, no-cache, must-revalidate&amp;#x27;), (b&amp;#x27;vary&amp;#x27;, b&amp;#x27;Origin&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-requests&amp;#x27;, b&amp;#x27;14400&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-tokens&amp;#x27;, b&amp;#x27;15000&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-requests&amp;#x27;, b&amp;#x27;14395&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-tokens&amp;#x27;, b&amp;#x27;14617&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-requests&amp;#x27;, b&amp;#x27;28.512s&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-tokens&amp;#x27;, b&amp;#x27;1.532s&amp;#x27;), (b&amp;#x27;x-request-id&amp;#x27;, b&amp;#x27;req_01jbf2380dfvtbahqckbsj0gpm&amp;#x27;), (b&amp;#x27;via&amp;#x27;, b&amp;#x27;1.1 google&amp;#x27;), (b&amp;#x27;alt-svc&amp;#x27;, b&amp;#x27;h3=&amp;quot;:443&amp;quot;; ma=86400&amp;#x27;), (b&amp;#x27;CF-Cache-Status&amp;#x27;, b&amp;#x27;DYNAMIC&amp;#x27;), (b&amp;#x27;Server&amp;#x27;, b&amp;#x27;cloudflare&amp;#x27;), (b&amp;#x27;CF-RAY&amp;#x27;, b&amp;#x27;8dac93d2bc6bca58-HAM&amp;#x27;), (b&amp;#x27;Content-Encoding&amp;#x27;, b&amp;#x27;gzip&amp;#x27;)])\nINFO     httpx:_client.py:1038 HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;HTTP/1.1 200 OK&amp;quot;\nDEBUG    httpcore.http11:_trace.py:45 receive_response_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 receive_response_body.complete\nDEBUG    httpcore.http11:_trace.py:45 response_closed.started\nDEBUG    httpcore.http11:_trace.py:45 response_closed.complete\nDEBUG    groq._base_client:_base_client.py:956 HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;200 OK&amp;quot;\nDEBUG    groq._base_client:_base_client.py:441 Request options: {&amp;#x27;method&amp;#x27;: &amp;#x27;post&amp;#x27;, &amp;#x27;url&amp;#x27;: &amp;#x27;/openai/v1/chat/completions&amp;#x27;, &amp;#x27;files&amp;#x27;: None, &amp;#x27;json_data&amp;#x27;: {&amp;#x27;messages&amp;#x27;: [{&amp;#x27;role&amp;#x27;: &amp;#x27;system&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate a JSON response following these rules:\\n1. Return multiple UNIQUE versions at the SAME length:\\n   {&amp;quot;versions&amp;quot;: [{&amp;quot;text&amp;quot;: &amp;quot;version1&amp;quot;}, {&amp;quot;text&amp;quot;: &amp;quot;version2&amp;quot;}]}\\n2. Each version must:\\n   - Target exactly the specified percentage\\n   - Use different sentence structures\\n   - Vary word choices while keeping technical terms\\n   - Maintain the same meaning\\n3. If task cannot be completed: {&amp;quot;error&amp;quot;: &amp;quot;specific reason&amp;quot;}&amp;#x27;}, {&amp;#x27;role&amp;#x27;: &amp;#x27;user&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate 2 UNIQUE versions at 50% length:\\n        - Each must be exactly the same length\\n        - Use different phrasings\\n        Original length: 5 tokens\\n        Original text: These endpoints enable text manipulation&amp;#x27;}], &amp;#x27;model&amp;#x27;: &amp;#x27;llama3-groq-70b-8192-tool-use-preview&amp;#x27;, &amp;#x27;max_tokens&amp;#x27;: 1000, &amp;#x27;temperature&amp;#x27;: 0.7}}\nDEBUG    httpcore.http11:_trace.py:45 send_request_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 send_request_headers.complete\nDEBUG    httpcore.http11:_trace.py:45 send_request_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 send_request_body.complete\nDEBUG    httpcore.http11:_trace.py:45 receive_response_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 receive_response_headers.complete return_value=(b&amp;#x27;HTTP/1.1&amp;#x27;, 200, b&amp;#x27;OK&amp;#x27;, [(b&amp;#x27;Date&amp;#x27;, b&amp;#x27;Wed, 30 Oct 2024 15:53:19 GMT&amp;#x27;), (b&amp;#x27;Content-Type&amp;#x27;, b&amp;#x27;application/json&amp;#x27;), (b&amp;#x27;Transfer-Encoding&amp;#x27;, b&amp;#x27;chunked&amp;#x27;), (b&amp;#x27;Connection&amp;#x27;, b&amp;#x27;keep-alive&amp;#x27;), (b&amp;#x27;Cache-Control&amp;#x27;, b&amp;#x27;private, max-age=0, no-store, no-cache, must-revalidate&amp;#x27;), (b&amp;#x27;vary&amp;#x27;, b&amp;#x27;Origin&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-requests&amp;#x27;, b&amp;#x27;14400&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-tokens&amp;#x27;, b&amp;#x27;15000&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-requests&amp;#x27;, b&amp;#x27;14394&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-tokens&amp;#x27;, b&amp;#x27;14522&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-requests&amp;#x27;, b&amp;#x27;35.641s&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-tokens&amp;#x27;, b&amp;#x27;1.911s&amp;#x27;), (b&amp;#x27;x-request-id&amp;#x27;, b&amp;#x27;req_01jbf238bjfskrn6cj4g9r1hw3&amp;#x27;), (b&amp;#x27;via&amp;#x27;, b&amp;#x27;1.1 google&amp;#x27;), (b&amp;#x27;alt-svc&amp;#x27;, b&amp;#x27;h3=&amp;quot;:443&amp;quot;; ma=86400&amp;#x27;), (b&amp;#x27;CF-Cache-Status&amp;#x27;, b&amp;#x27;DYNAMIC&amp;#x27;), (b&amp;#x27;Server&amp;#x27;, b&amp;#x27;cloudflare&amp;#x27;), (b&amp;#x27;CF-RAY&amp;#x27;, b&amp;#x27;8dac93d4fee2ca58-HAM&amp;#x27;), (b&amp;#x27;Content-Encoding&amp;#x27;, b&amp;#x27;gzip&amp;#x27;)])\nINFO     httpx:_client.py:1038 HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;HTTP/1.1 200 OK&amp;quot;\nDEBUG    httpcore.http11:_trace.py:45 receive_response_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 receive_response_body.complete\nDEBUG    httpcore.http11:_trace.py:45 response_closed.started\nDEBUG    httpcore.http11:_trace.py:45 response_closed.complete\nDEBUG    groq._base_client:_base_client.py:956 HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;200 OK&amp;quot;\nDEBUG    groq._base_client:_base_client.py:441 Request options: {&amp;#x27;method&amp;#x27;: &amp;#x27;post&amp;#x27;, &amp;#x27;url&amp;#x27;: &amp;#x27;/openai/v1/chat/completions&amp;#x27;, &amp;#x27;files&amp;#x27;: None, &amp;#x27;json_data&amp;#x27;: {&amp;#x27;messages&amp;#x27;: [{&amp;#x27;role&amp;#x27;: &amp;#x27;system&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate a JSON response following these rules:\\n1. Return multiple UNIQUE versions at the SAME length:\\n   {&amp;quot;versions&amp;quot;: [{&amp;quot;text&amp;quot;: &amp;quot;version1&amp;quot;}, {&amp;quot;text&amp;quot;: &amp;quot;version2&amp;quot;}]}\\n2. Each version must:\\n   - Target exactly the specified percentage\\n   - Use different sentence structures\\n   - Vary word choices while keeping technical terms\\n   - Maintain the same meaning\\n3. If task cannot be completed: {&amp;quot;error&amp;quot;: &amp;quot;specific reason&amp;quot;}&amp;#x27;}, {&amp;#x27;role&amp;#x27;: &amp;#x27;user&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate 2 UNIQUE versions at 50% length:\\n        - Each must be exactly the same length\\n        - Use different phrasings\\n        Original length: 4 tokens\\n        Original text: Operations include various transformations&amp;#x27;}], &amp;#x27;model&amp;#x27;: &amp;#x27;llama3-groq-70b-8192-tool-use-preview&amp;#x27;, &amp;#x27;max_tokens&amp;#x27;: 1000, &amp;#x27;temperature&amp;#x27;: 0.7}}\nDEBUG    httpcore.http11:_trace.py:45 send_request_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 send_request_headers.complete\nDEBUG    httpcore.http11:_trace.py:45 send_request_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 send_request_body.complete\nDEBUG    httpcore.http11:_trace.py:45 receive_response_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 receive_response_headers.complete return_value=(b&amp;#x27;HTTP/1.1&amp;#x27;, 200, b&amp;#x27;OK&amp;#x27;, [(b&amp;#x27;Date&amp;#x27;, b&amp;#x27;Wed, 30 Oct 2024 15:53:19 GMT&amp;#x27;), (b&amp;#x27;Content-Type&amp;#x27;, b&amp;#x27;application/json&amp;#x27;), (b&amp;#x27;Transfer-Encoding&amp;#x27;, b&amp;#x27;chunked&amp;#x27;), (b&amp;#x27;Connection&amp;#x27;, b&amp;#x27;keep-alive&amp;#x27;), (b&amp;#x27;Cache-Control&amp;#x27;, b&amp;#x27;private, max-age=0, no-store, no-cache, must-revalidate&amp;#x27;), (b&amp;#x27;vary&amp;#x27;, b&amp;#x27;Origin&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-requests&amp;#x27;, b&amp;#x27;14400&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-tokens&amp;#x27;, b&amp;#x27;15000&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-requests&amp;#x27;, b&amp;#x27;14393&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-tokens&amp;#x27;, b&amp;#x27;14427&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-requests&amp;#x27;, b&amp;#x27;41.668999999s&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-tokens&amp;#x27;, b&amp;#x27;2.292s&amp;#x27;), (b&amp;#x27;x-request-id&amp;#x27;, b&amp;#x27;req_01jbf238nzf498er0syr08j4n7&amp;#x27;), (b&amp;#x27;via&amp;#x27;, b&amp;#x27;1.1 google&amp;#x27;), (b&amp;#x27;alt-svc&amp;#x27;, b&amp;#x27;h3=&amp;quot;:443&amp;quot;; ma=86400&amp;#x27;), (b&amp;#x27;CF-Cache-Status&amp;#x27;, b&amp;#x27;DYNAMIC&amp;#x27;), (b&amp;#x27;Server&amp;#x27;, b&amp;#x27;cloudflare&amp;#x27;), (b&amp;#x27;CF-RAY&amp;#x27;, b&amp;#x27;8dac93d6f9a9ca58-HAM&amp;#x27;), (b&amp;#x27;Content-Encoding&amp;#x27;, b&amp;#x27;gzip&amp;#x27;)])\nINFO     httpx:_client.py:1038 HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;HTTP/1.1 200 OK&amp;quot;\nDEBUG    httpcore.http11:_trace.py:45 receive_response_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 receive_response_body.complete\nDEBUG    httpcore.http11:_trace.py:45 response_closed.started\nDEBUG    httpcore.http11:_trace.py:45 response_closed.complete\nDEBUG    groq._base_client:_base_client.py:956 HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;200 OK&amp;quot;\n\n&#34;}], &#34;tests/performance/test_compress_performance.py::TestCompressEndpoint::test_invalid_inputs[invalid_input0]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Failed&#34;, &#34;testId&#34;: &#34;tests/performance/test_compress_performance.py::TestCompressEndpoint::test_invalid_inputs[invalid_input0]&#34;, &#34;duration&#34;: &#34;816 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Failed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/performance/test_compress_performance.py::TestCompressEndpoint::test_invalid_inputs[invalid_input0]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;816 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;self = &amp;lt;tests.test_compress.TestCompressEndpoint object at 0x106953410&amp;gt;\nclient = &amp;lt;FlaskClient &amp;lt;Flask &amp;#x27;app&amp;#x27;&amp;gt;&amp;gt;\nauth_headers = {&amp;#x27;Authorization&amp;#x27;: &amp;#x27;Bearer test_key&amp;#x27;, &amp;#x27;Content-Type&amp;#x27;: &amp;#x27;application/json&amp;#x27;}\ninvalid_input = {&amp;#x27;content&amp;#x27;: &amp;#x27;text&amp;#x27;, &amp;#x27;target_percentage&amp;#x27;: 150}\n\n    @pytest.mark.unit\n    @pytest.mark.parametrize(&amp;#x27;invalid_input&amp;#x27;, [\n        {&amp;#x27;content&amp;#x27;: &amp;quot;text&amp;quot;, &amp;#x27;target_percentage&amp;#x27;: 150},  # Invalid percentage\n        {&amp;#x27;content&amp;#x27;: &amp;quot;text&amp;quot;, &amp;#x27;steps_percentage&amp;#x27;: -10},   # Negative steps\n        {&amp;#x27;content&amp;#x27;: &amp;quot;text&amp;quot;, &amp;#x27;versions&amp;#x27;: 10},            # Too many versions\n        {&amp;#x27;content&amp;#x27;: &amp;quot;&amp;quot;, &amp;#x27;target_percentage&amp;#x27;: 50},       # Empty content\n        {&amp;#x27;target_percentage&amp;#x27;: 50},                      # Missing content\n    ])\n    def test_invalid_inputs(self, client, auth_headers, invalid_input):\n        response = client.post(\n            self.ENDPOINTS[&amp;#x27;compress&amp;#x27;], json=invalid_input, headers=auth_headers)\n&amp;gt;       assert response.status_code == 400\nE       assert 200 == 400\nE        +  where 200 = &amp;lt;WrapperTestResponse streamed [200 OK]&amp;gt;.status_code\n\ntests/test_compress.py:139: AssertionError\n\n---------------------------- Captured stderr setup -----------------------------\nDEBUG:app:Registering blueprints...\nDEBUG:app:Registered routes:\nDEBUG:app:static: /static/&amp;lt;path:filename&amp;gt; [GET, OPTIONS, HEAD]\nDEBUG:app:generate.create_text: /text/v1/generate/text [OPTIONS, POST]\nDEBUG:app:compress.compress_text: /text/v1/compress/ [OPTIONS, POST]\nDEBUG:app:expand.expand_text: /text/v1/expand/ [OPTIONS, POST]\n\n------------------------------ Captured log setup ------------------------------\nDEBUG    app:__init__.py:106 Registering blueprints...\nDEBUG    app:__init__.py:112 Registered routes:\nDEBUG    app:__init__.py:114 static: /static/&amp;lt;path:filename&amp;gt; [GET, OPTIONS, HEAD]\nDEBUG    app:__init__.py:114 generate.create_text: /text/v1/generate/text [OPTIONS, POST]\nDEBUG    app:__init__.py:114 compress.compress_text: /text/v1/compress/ [OPTIONS, POST]\nDEBUG    app:__init__.py:114 expand.expand_text: /text/v1/expand/ [OPTIONS, POST]\n\n----------------------------- Captured stderr call -----------------------------\nDEBUG:app:Headers: {&amp;#x27;User-Agent&amp;#x27;: &amp;#x27;Werkzeug/3.0.6&amp;#x27;, &amp;#x27;Host&amp;#x27;: &amp;#x27;localhost&amp;#x27;, &amp;#x27;Content-Type&amp;#x27;: &amp;#x27;application/json&amp;#x27;, &amp;#x27;Content-Length&amp;#x27;: &amp;#x27;45&amp;#x27;, &amp;#x27;Authorization&amp;#x27;: &amp;#x27;Bearer test_key&amp;#x27;}\nDEBUG:app:Body: b&amp;#x27;{&amp;quot;content&amp;quot;: &amp;quot;text&amp;quot;, &amp;quot;target_percentage&amp;quot;: 150}&amp;#x27;\nDEBUG:app:Query Params: {}\nDEBUG:app:Route: POST /text/v1/compress/\nDEBUG:groq._base_client:Request options: {&amp;#x27;method&amp;#x27;: &amp;#x27;post&amp;#x27;, &amp;#x27;url&amp;#x27;: &amp;#x27;/openai/v1/chat/completions&amp;#x27;, &amp;#x27;files&amp;#x27;: None, &amp;#x27;json_data&amp;#x27;: {&amp;#x27;messages&amp;#x27;: [{&amp;#x27;role&amp;#x27;: &amp;#x27;system&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate a JSON response following these rules:\\n1. Return exactly ONE compressed version:\\n   {&amp;quot;versions&amp;quot;: [{&amp;quot;text&amp;quot;: &amp;quot;compressed version&amp;quot;}]}\\n2. Target exactly the specified percentage of original length\\n3. Maintain core meaning while removing less essential details\\n4. Ensure complete sentences and proper punctuation\\n5. If task cannot be completed: {&amp;quot;error&amp;quot;: &amp;quot;specific reason&amp;quot;}&amp;#x27;}, {&amp;#x27;role&amp;#x27;: &amp;#x27;user&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate ONE compressed version at 150% length:\\n        Original length: 1 tokens\\n        Original text: text&amp;#x27;}], &amp;#x27;model&amp;#x27;: &amp;#x27;llama3-groq-70b-8192-tool-use-preview&amp;#x27;, &amp;#x27;max_tokens&amp;#x27;: 1000, &amp;#x27;temperature&amp;#x27;: 0.7}}\nDEBUG:httpcore.http11:send_request_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.http11:send_request_headers.complete\nDEBUG:httpcore.http11:send_request_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.http11:send_request_body.complete\nDEBUG:httpcore.http11:receive_response_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.http11:receive_response_headers.complete return_value=(b&amp;#x27;HTTP/1.1&amp;#x27;, 200, b&amp;#x27;OK&amp;#x27;, [(b&amp;#x27;Date&amp;#x27;, b&amp;#x27;Wed, 30 Oct 2024 15:53:20 GMT&amp;#x27;), (b&amp;#x27;Content-Type&amp;#x27;, b&amp;#x27;application/json&amp;#x27;), (b&amp;#x27;Transfer-Encoding&amp;#x27;, b&amp;#x27;chunked&amp;#x27;), (b&amp;#x27;Connection&amp;#x27;, b&amp;#x27;keep-alive&amp;#x27;), (b&amp;#x27;Cache-Control&amp;#x27;, b&amp;#x27;private, max-age=0, no-store, no-cache, must-revalidate&amp;#x27;), (b&amp;#x27;vary&amp;#x27;, b&amp;#x27;Origin&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-requests&amp;#x27;, b&amp;#x27;14400&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-tokens&amp;#x27;, b&amp;#x27;15000&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-requests&amp;#x27;, b&amp;#x27;14392&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-tokens&amp;#x27;, b&amp;#x27;14501&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-requests&amp;#x27;, b&amp;#x27;47.152s&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-tokens&amp;#x27;, b&amp;#x27;1.995s&amp;#x27;), (b&amp;#x27;x-request-id&amp;#x27;, b&amp;#x27;req_01jbf239ggebkt2dmhe4s5xx21&amp;#x27;), (b&amp;#x27;via&amp;#x27;, b&amp;#x27;1.1 google&amp;#x27;), (b&amp;#x27;alt-svc&amp;#x27;, b&amp;#x27;h3=&amp;quot;:443&amp;quot;; ma=86400&amp;#x27;), (b&amp;#x27;CF-Cache-Status&amp;#x27;, b&amp;#x27;DYNAMIC&amp;#x27;), (b&amp;#x27;Server&amp;#x27;, b&amp;#x27;cloudflare&amp;#x27;), (b&amp;#x27;CF-RAY&amp;#x27;, b&amp;#x27;8dac93dc580dca58-HAM&amp;#x27;), (b&amp;#x27;Content-Encoding&amp;#x27;, b&amp;#x27;gzip&amp;#x27;)])\nINFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;HTTP/1.1 200 OK&amp;quot;\nDEBUG:httpcore.http11:receive_response_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.http11:receive_response_body.complete\nDEBUG:httpcore.http11:response_closed.started\nDEBUG:httpcore.http11:response_closed.complete\nDEBUG:groq._base_client:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;200 OK&amp;quot;\n\n------------------------------ Captured log call -------------------------------\nDEBUG    app:__init__.py:31 Headers: {&amp;#x27;User-Agent&amp;#x27;: &amp;#x27;Werkzeug/3.0.6&amp;#x27;, &amp;#x27;Host&amp;#x27;: &amp;#x27;localhost&amp;#x27;, &amp;#x27;Content-Type&amp;#x27;: &amp;#x27;application/json&amp;#x27;, &amp;#x27;Content-Length&amp;#x27;: &amp;#x27;45&amp;#x27;, &amp;#x27;Authorization&amp;#x27;: &amp;#x27;Bearer test_key&amp;#x27;}\nDEBUG    app:__init__.py:32 Body: b&amp;#x27;{&amp;quot;content&amp;quot;: &amp;quot;text&amp;quot;, &amp;quot;target_percentage&amp;quot;: 150}&amp;#x27;\nDEBUG    app:__init__.py:33 Query Params: {}\nDEBUG    app:__init__.py:34 Route: POST /text/v1/compress/\nDEBUG    groq._base_client:_base_client.py:441 Request options: {&amp;#x27;method&amp;#x27;: &amp;#x27;post&amp;#x27;, &amp;#x27;url&amp;#x27;: &amp;#x27;/openai/v1/chat/completions&amp;#x27;, &amp;#x27;files&amp;#x27;: None, &amp;#x27;json_data&amp;#x27;: {&amp;#x27;messages&amp;#x27;: [{&amp;#x27;role&amp;#x27;: &amp;#x27;system&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate a JSON response following these rules:\\n1. Return exactly ONE compressed version:\\n   {&amp;quot;versions&amp;quot;: [{&amp;quot;text&amp;quot;: &amp;quot;compressed version&amp;quot;}]}\\n2. Target exactly the specified percentage of original length\\n3. Maintain core meaning while removing less essential details\\n4. Ensure complete sentences and proper punctuation\\n5. If task cannot be completed: {&amp;quot;error&amp;quot;: &amp;quot;specific reason&amp;quot;}&amp;#x27;}, {&amp;#x27;role&amp;#x27;: &amp;#x27;user&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate ONE compressed version at 150% length:\\n        Original length: 1 tokens\\n        Original text: text&amp;#x27;}], &amp;#x27;model&amp;#x27;: &amp;#x27;llama3-groq-70b-8192-tool-use-preview&amp;#x27;, &amp;#x27;max_tokens&amp;#x27;: 1000, &amp;#x27;temperature&amp;#x27;: 0.7}}\nDEBUG    httpcore.http11:_trace.py:45 send_request_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 send_request_headers.complete\nDEBUG    httpcore.http11:_trace.py:45 send_request_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 send_request_body.complete\nDEBUG    httpcore.http11:_trace.py:45 receive_response_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 receive_response_headers.complete return_value=(b&amp;#x27;HTTP/1.1&amp;#x27;, 200, b&amp;#x27;OK&amp;#x27;, [(b&amp;#x27;Date&amp;#x27;, b&amp;#x27;Wed, 30 Oct 2024 15:53:20 GMT&amp;#x27;), (b&amp;#x27;Content-Type&amp;#x27;, b&amp;#x27;application/json&amp;#x27;), (b&amp;#x27;Transfer-Encoding&amp;#x27;, b&amp;#x27;chunked&amp;#x27;), (b&amp;#x27;Connection&amp;#x27;, b&amp;#x27;keep-alive&amp;#x27;), (b&amp;#x27;Cache-Control&amp;#x27;, b&amp;#x27;private, max-age=0, no-store, no-cache, must-revalidate&amp;#x27;), (b&amp;#x27;vary&amp;#x27;, b&amp;#x27;Origin&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-requests&amp;#x27;, b&amp;#x27;14400&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-tokens&amp;#x27;, b&amp;#x27;15000&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-requests&amp;#x27;, b&amp;#x27;14392&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-tokens&amp;#x27;, b&amp;#x27;14501&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-requests&amp;#x27;, b&amp;#x27;47.152s&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-tokens&amp;#x27;, b&amp;#x27;1.995s&amp;#x27;), (b&amp;#x27;x-request-id&amp;#x27;, b&amp;#x27;req_01jbf239ggebkt2dmhe4s5xx21&amp;#x27;), (b&amp;#x27;via&amp;#x27;, b&amp;#x27;1.1 google&amp;#x27;), (b&amp;#x27;alt-svc&amp;#x27;, b&amp;#x27;h3=&amp;quot;:443&amp;quot;; ma=86400&amp;#x27;), (b&amp;#x27;CF-Cache-Status&amp;#x27;, b&amp;#x27;DYNAMIC&amp;#x27;), (b&amp;#x27;Server&amp;#x27;, b&amp;#x27;cloudflare&amp;#x27;), (b&amp;#x27;CF-RAY&amp;#x27;, b&amp;#x27;8dac93dc580dca58-HAM&amp;#x27;), (b&amp;#x27;Content-Encoding&amp;#x27;, b&amp;#x27;gzip&amp;#x27;)])\nINFO     httpx:_client.py:1038 HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;HTTP/1.1 200 OK&amp;quot;\nDEBUG    httpcore.http11:_trace.py:45 receive_response_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 receive_response_body.complete\nDEBUG    httpcore.http11:_trace.py:45 response_closed.started\nDEBUG    httpcore.http11:_trace.py:45 response_closed.complete\nDEBUG    groq._base_client:_base_client.py:956 HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;200 OK&amp;quot;\n\n&#34;}], &#34;tests/performance/test_compress_performance.py::TestCompressEndpoint::test_invalid_inputs[invalid_input1]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Failed&#34;, &#34;testId&#34;: &#34;tests/performance/test_compress_performance.py::TestCompressEndpoint::test_invalid_inputs[invalid_input1]&#34;, &#34;duration&#34;: &#34;813 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Failed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/performance/test_compress_performance.py::TestCompressEndpoint::test_invalid_inputs[invalid_input1]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;813 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;self = &amp;lt;tests.test_compress.TestCompressEndpoint object at 0x106953650&amp;gt;\nclient = &amp;lt;FlaskClient &amp;lt;Flask &amp;#x27;app&amp;#x27;&amp;gt;&amp;gt;\nauth_headers = {&amp;#x27;Authorization&amp;#x27;: &amp;#x27;Bearer test_key&amp;#x27;, &amp;#x27;Content-Type&amp;#x27;: &amp;#x27;application/json&amp;#x27;}\ninvalid_input = {&amp;#x27;content&amp;#x27;: &amp;#x27;text&amp;#x27;, &amp;#x27;steps_percentage&amp;#x27;: -10}\n\n    @pytest.mark.unit\n    @pytest.mark.parametrize(&amp;#x27;invalid_input&amp;#x27;, [\n        {&amp;#x27;content&amp;#x27;: &amp;quot;text&amp;quot;, &amp;#x27;target_percentage&amp;#x27;: 150},  # Invalid percentage\n        {&amp;#x27;content&amp;#x27;: &amp;quot;text&amp;quot;, &amp;#x27;steps_percentage&amp;#x27;: -10},   # Negative steps\n        {&amp;#x27;content&amp;#x27;: &amp;quot;text&amp;quot;, &amp;#x27;versions&amp;#x27;: 10},            # Too many versions\n        {&amp;#x27;content&amp;#x27;: &amp;quot;&amp;quot;, &amp;#x27;target_percentage&amp;#x27;: 50},       # Empty content\n        {&amp;#x27;target_percentage&amp;#x27;: 50},                      # Missing content\n    ])\n    def test_invalid_inputs(self, client, auth_headers, invalid_input):\n        response = client.post(\n            self.ENDPOINTS[&amp;#x27;compress&amp;#x27;], json=invalid_input, headers=auth_headers)\n&amp;gt;       assert response.status_code == 400\nE       assert 200 == 400\nE        +  where 200 = &amp;lt;WrapperTestResponse streamed [200 OK]&amp;gt;.status_code\n\ntests/test_compress.py:139: AssertionError\n\n---------------------------- Captured stderr setup -----------------------------\nDEBUG:app:Registering blueprints...\nDEBUG:app:Registered routes:\nDEBUG:app:static: /static/&amp;lt;path:filename&amp;gt; [GET, OPTIONS, HEAD]\nDEBUG:app:generate.create_text: /text/v1/generate/text [OPTIONS, POST]\nDEBUG:app:compress.compress_text: /text/v1/compress/ [OPTIONS, POST]\nDEBUG:app:expand.expand_text: /text/v1/expand/ [OPTIONS, POST]\n\n------------------------------ Captured log setup ------------------------------\nDEBUG    app:__init__.py:106 Registering blueprints...\nDEBUG    app:__init__.py:112 Registered routes:\nDEBUG    app:__init__.py:114 static: /static/&amp;lt;path:filename&amp;gt; [GET, OPTIONS, HEAD]\nDEBUG    app:__init__.py:114 generate.create_text: /text/v1/generate/text [OPTIONS, POST]\nDEBUG    app:__init__.py:114 compress.compress_text: /text/v1/compress/ [OPTIONS, POST]\nDEBUG    app:__init__.py:114 expand.expand_text: /text/v1/expand/ [OPTIONS, POST]\n\n----------------------------- Captured stderr call -----------------------------\nDEBUG:app:Headers: {&amp;#x27;User-Agent&amp;#x27;: &amp;#x27;Werkzeug/3.0.6&amp;#x27;, &amp;#x27;Host&amp;#x27;: &amp;#x27;localhost&amp;#x27;, &amp;#x27;Content-Type&amp;#x27;: &amp;#x27;application/json&amp;#x27;, &amp;#x27;Content-Length&amp;#x27;: &amp;#x27;44&amp;#x27;, &amp;#x27;Authorization&amp;#x27;: &amp;#x27;Bearer test_key&amp;#x27;}\nDEBUG:app:Body: b&amp;#x27;{&amp;quot;content&amp;quot;: &amp;quot;text&amp;quot;, &amp;quot;steps_percentage&amp;quot;: -10}&amp;#x27;\nDEBUG:app:Query Params: {}\nDEBUG:app:Route: POST /text/v1/compress/\nDEBUG:groq._base_client:Request options: {&amp;#x27;method&amp;#x27;: &amp;#x27;post&amp;#x27;, &amp;#x27;url&amp;#x27;: &amp;#x27;/openai/v1/chat/completions&amp;#x27;, &amp;#x27;files&amp;#x27;: None, &amp;#x27;json_data&amp;#x27;: {&amp;#x27;messages&amp;#x27;: [{&amp;#x27;role&amp;#x27;: &amp;#x27;system&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate a JSON response following these rules:\\n1. Return exactly ONE compressed version:\\n   {&amp;quot;versions&amp;quot;: [{&amp;quot;text&amp;quot;: &amp;quot;compressed version&amp;quot;}]}\\n2. Target exactly the specified percentage of original length\\n3. Maintain core meaning while removing less essential details\\n4. Ensure complete sentences and proper punctuation\\n5. If task cannot be completed: {&amp;quot;error&amp;quot;: &amp;quot;specific reason&amp;quot;}&amp;#x27;}, {&amp;#x27;role&amp;#x27;: &amp;#x27;user&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate ONE compressed version at 20% length:\\n        Original length: 1 tokens\\n        Original text: text&amp;#x27;}], &amp;#x27;model&amp;#x27;: &amp;#x27;llama3-groq-70b-8192-tool-use-preview&amp;#x27;, &amp;#x27;max_tokens&amp;#x27;: 1000, &amp;#x27;temperature&amp;#x27;: 0.7}}\nDEBUG:httpcore.http11:send_request_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.http11:send_request_headers.complete\nDEBUG:httpcore.http11:send_request_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.http11:send_request_body.complete\nDEBUG:httpcore.http11:receive_response_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.http11:receive_response_headers.complete return_value=(b&amp;#x27;HTTP/1.1&amp;#x27;, 200, b&amp;#x27;OK&amp;#x27;, [(b&amp;#x27;Date&amp;#x27;, b&amp;#x27;Wed, 30 Oct 2024 15:53:21 GMT&amp;#x27;), (b&amp;#x27;Content-Type&amp;#x27;, b&amp;#x27;application/json&amp;#x27;), (b&amp;#x27;Transfer-Encoding&amp;#x27;, b&amp;#x27;chunked&amp;#x27;), (b&amp;#x27;Connection&amp;#x27;, b&amp;#x27;keep-alive&amp;#x27;), (b&amp;#x27;Cache-Control&amp;#x27;, b&amp;#x27;private, max-age=0, no-store, no-cache, must-revalidate&amp;#x27;), (b&amp;#x27;vary&amp;#x27;, b&amp;#x27;Origin&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-requests&amp;#x27;, b&amp;#x27;14400&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-tokens&amp;#x27;, b&amp;#x27;15000&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-requests&amp;#x27;, b&amp;#x27;14391&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-tokens&amp;#x27;, b&amp;#x27;14582&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-requests&amp;#x27;, b&amp;#x27;53.177999999s&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-tokens&amp;#x27;, b&amp;#x27;1.669s&amp;#x27;), (b&amp;#x27;x-request-id&amp;#x27;, b&amp;#x27;req_01jbf23a9xerxrf4jncgtg0j59&amp;#x27;), (b&amp;#x27;via&amp;#x27;, b&amp;#x27;1.1 google&amp;#x27;), (b&amp;#x27;alt-svc&amp;#x27;, b&amp;#x27;h3=&amp;quot;:443&amp;quot;; ma=86400&amp;#x27;), (b&amp;#x27;CF-Cache-Status&amp;#x27;, b&amp;#x27;DYNAMIC&amp;#x27;), (b&amp;#x27;Server&amp;#x27;, b&amp;#x27;cloudflare&amp;#x27;), (b&amp;#x27;CF-RAY&amp;#x27;, b&amp;#x27;8dac93e16e90ca58-HAM&amp;#x27;), (b&amp;#x27;Content-Encoding&amp;#x27;, b&amp;#x27;gzip&amp;#x27;)])\nINFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;HTTP/1.1 200 OK&amp;quot;\nDEBUG:httpcore.http11:receive_response_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.http11:receive_response_body.complete\nDEBUG:httpcore.http11:response_closed.started\nDEBUG:httpcore.http11:response_closed.complete\nDEBUG:groq._base_client:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;200 OK&amp;quot;\n\n------------------------------ Captured log call -------------------------------\nDEBUG    app:__init__.py:31 Headers: {&amp;#x27;User-Agent&amp;#x27;: &amp;#x27;Werkzeug/3.0.6&amp;#x27;, &amp;#x27;Host&amp;#x27;: &amp;#x27;localhost&amp;#x27;, &amp;#x27;Content-Type&amp;#x27;: &amp;#x27;application/json&amp;#x27;, &amp;#x27;Content-Length&amp;#x27;: &amp;#x27;44&amp;#x27;, &amp;#x27;Authorization&amp;#x27;: &amp;#x27;Bearer test_key&amp;#x27;}\nDEBUG    app:__init__.py:32 Body: b&amp;#x27;{&amp;quot;content&amp;quot;: &amp;quot;text&amp;quot;, &amp;quot;steps_percentage&amp;quot;: -10}&amp;#x27;\nDEBUG    app:__init__.py:33 Query Params: {}\nDEBUG    app:__init__.py:34 Route: POST /text/v1/compress/\nDEBUG    groq._base_client:_base_client.py:441 Request options: {&amp;#x27;method&amp;#x27;: &amp;#x27;post&amp;#x27;, &amp;#x27;url&amp;#x27;: &amp;#x27;/openai/v1/chat/completions&amp;#x27;, &amp;#x27;files&amp;#x27;: None, &amp;#x27;json_data&amp;#x27;: {&amp;#x27;messages&amp;#x27;: [{&amp;#x27;role&amp;#x27;: &amp;#x27;system&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate a JSON response following these rules:\\n1. Return exactly ONE compressed version:\\n   {&amp;quot;versions&amp;quot;: [{&amp;quot;text&amp;quot;: &amp;quot;compressed version&amp;quot;}]}\\n2. Target exactly the specified percentage of original length\\n3. Maintain core meaning while removing less essential details\\n4. Ensure complete sentences and proper punctuation\\n5. If task cannot be completed: {&amp;quot;error&amp;quot;: &amp;quot;specific reason&amp;quot;}&amp;#x27;}, {&amp;#x27;role&amp;#x27;: &amp;#x27;user&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate ONE compressed version at 20% length:\\n        Original length: 1 tokens\\n        Original text: text&amp;#x27;}], &amp;#x27;model&amp;#x27;: &amp;#x27;llama3-groq-70b-8192-tool-use-preview&amp;#x27;, &amp;#x27;max_tokens&amp;#x27;: 1000, &amp;#x27;temperature&amp;#x27;: 0.7}}\nDEBUG    httpcore.http11:_trace.py:45 send_request_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 send_request_headers.complete\nDEBUG    httpcore.http11:_trace.py:45 send_request_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 send_request_body.complete\nDEBUG    httpcore.http11:_trace.py:45 receive_response_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 receive_response_headers.complete return_value=(b&amp;#x27;HTTP/1.1&amp;#x27;, 200, b&amp;#x27;OK&amp;#x27;, [(b&amp;#x27;Date&amp;#x27;, b&amp;#x27;Wed, 30 Oct 2024 15:53:21 GMT&amp;#x27;), (b&amp;#x27;Content-Type&amp;#x27;, b&amp;#x27;application/json&amp;#x27;), (b&amp;#x27;Transfer-Encoding&amp;#x27;, b&amp;#x27;chunked&amp;#x27;), (b&amp;#x27;Connection&amp;#x27;, b&amp;#x27;keep-alive&amp;#x27;), (b&amp;#x27;Cache-Control&amp;#x27;, b&amp;#x27;private, max-age=0, no-store, no-cache, must-revalidate&amp;#x27;), (b&amp;#x27;vary&amp;#x27;, b&amp;#x27;Origin&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-requests&amp;#x27;, b&amp;#x27;14400&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-tokens&amp;#x27;, b&amp;#x27;15000&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-requests&amp;#x27;, b&amp;#x27;14391&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-tokens&amp;#x27;, b&amp;#x27;14582&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-requests&amp;#x27;, b&amp;#x27;53.177999999s&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-tokens&amp;#x27;, b&amp;#x27;1.669s&amp;#x27;), (b&amp;#x27;x-request-id&amp;#x27;, b&amp;#x27;req_01jbf23a9xerxrf4jncgtg0j59&amp;#x27;), (b&amp;#x27;via&amp;#x27;, b&amp;#x27;1.1 google&amp;#x27;), (b&amp;#x27;alt-svc&amp;#x27;, b&amp;#x27;h3=&amp;quot;:443&amp;quot;; ma=86400&amp;#x27;), (b&amp;#x27;CF-Cache-Status&amp;#x27;, b&amp;#x27;DYNAMIC&amp;#x27;), (b&amp;#x27;Server&amp;#x27;, b&amp;#x27;cloudflare&amp;#x27;), (b&amp;#x27;CF-RAY&amp;#x27;, b&amp;#x27;8dac93e16e90ca58-HAM&amp;#x27;), (b&amp;#x27;Content-Encoding&amp;#x27;, b&amp;#x27;gzip&amp;#x27;)])\nINFO     httpx:_client.py:1038 HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;HTTP/1.1 200 OK&amp;quot;\nDEBUG    httpcore.http11:_trace.py:45 receive_response_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 receive_response_body.complete\nDEBUG    httpcore.http11:_trace.py:45 response_closed.started\nDEBUG    httpcore.http11:_trace.py:45 response_closed.complete\nDEBUG    groq._base_client:_base_client.py:956 HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;200 OK&amp;quot;\n\n&#34;}], &#34;tests/performance/test_compress_performance.py::TestCompressEndpoint::test_invalid_inputs[invalid_input2]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Failed&#34;, &#34;testId&#34;: &#34;tests/performance/test_compress_performance.py::TestCompressEndpoint::test_invalid_inputs[invalid_input2]&#34;, &#34;duration&#34;: &#34;865 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Failed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/performance/test_compress_performance.py::TestCompressEndpoint::test_invalid_inputs[invalid_input2]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;865 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;self = &amp;lt;tests.test_compress.TestCompressEndpoint object at 0x106953800&amp;gt;\nclient = &amp;lt;FlaskClient &amp;lt;Flask &amp;#x27;app&amp;#x27;&amp;gt;&amp;gt;\nauth_headers = {&amp;#x27;Authorization&amp;#x27;: &amp;#x27;Bearer test_key&amp;#x27;, &amp;#x27;Content-Type&amp;#x27;: &amp;#x27;application/json&amp;#x27;}\ninvalid_input = {&amp;#x27;content&amp;#x27;: &amp;#x27;text&amp;#x27;, &amp;#x27;versions&amp;#x27;: 10}\n\n    @pytest.mark.unit\n    @pytest.mark.parametrize(&amp;#x27;invalid_input&amp;#x27;, [\n        {&amp;#x27;content&amp;#x27;: &amp;quot;text&amp;quot;, &amp;#x27;target_percentage&amp;#x27;: 150},  # Invalid percentage\n        {&amp;#x27;content&amp;#x27;: &amp;quot;text&amp;quot;, &amp;#x27;steps_percentage&amp;#x27;: -10},   # Negative steps\n        {&amp;#x27;content&amp;#x27;: &amp;quot;text&amp;quot;, &amp;#x27;versions&amp;#x27;: 10},            # Too many versions\n        {&amp;#x27;content&amp;#x27;: &amp;quot;&amp;quot;, &amp;#x27;target_percentage&amp;#x27;: 50},       # Empty content\n        {&amp;#x27;target_percentage&amp;#x27;: 50},                      # Missing content\n    ])\n    def test_invalid_inputs(self, client, auth_headers, invalid_input):\n        response = client.post(\n            self.ENDPOINTS[&amp;#x27;compress&amp;#x27;], json=invalid_input, headers=auth_headers)\n&amp;gt;       assert response.status_code == 400\nE       assert 200 == 400\nE        +  where 200 = &amp;lt;WrapperTestResponse streamed [200 OK]&amp;gt;.status_code\n\ntests/test_compress.py:139: AssertionError\n\n---------------------------- Captured stderr setup -----------------------------\nDEBUG:app:Registering blueprints...\nDEBUG:app:Registered routes:\nDEBUG:app:static: /static/&amp;lt;path:filename&amp;gt; [GET, OPTIONS, HEAD]\nDEBUG:app:generate.create_text: /text/v1/generate/text [OPTIONS, POST]\nDEBUG:app:compress.compress_text: /text/v1/compress/ [OPTIONS, POST]\nDEBUG:app:expand.expand_text: /text/v1/expand/ [OPTIONS, POST]\n\n------------------------------ Captured log setup ------------------------------\nDEBUG    app:__init__.py:106 Registering blueprints...\nDEBUG    app:__init__.py:112 Registered routes:\nDEBUG    app:__init__.py:114 static: /static/&amp;lt;path:filename&amp;gt; [GET, OPTIONS, HEAD]\nDEBUG    app:__init__.py:114 generate.create_text: /text/v1/generate/text [OPTIONS, POST]\nDEBUG    app:__init__.py:114 compress.compress_text: /text/v1/compress/ [OPTIONS, POST]\nDEBUG    app:__init__.py:114 expand.expand_text: /text/v1/expand/ [OPTIONS, POST]\n\n----------------------------- Captured stderr call -----------------------------\nDEBUG:app:Headers: {&amp;#x27;User-Agent&amp;#x27;: &amp;#x27;Werkzeug/3.0.6&amp;#x27;, &amp;#x27;Host&amp;#x27;: &amp;#x27;localhost&amp;#x27;, &amp;#x27;Content-Type&amp;#x27;: &amp;#x27;application/json&amp;#x27;, &amp;#x27;Content-Length&amp;#x27;: &amp;#x27;35&amp;#x27;, &amp;#x27;Authorization&amp;#x27;: &amp;#x27;Bearer test_key&amp;#x27;}\nDEBUG:app:Body: b&amp;#x27;{&amp;quot;content&amp;quot;: &amp;quot;text&amp;quot;, &amp;quot;versions&amp;quot;: 10}&amp;#x27;\nDEBUG:app:Query Params: {}\nDEBUG:app:Route: POST /text/v1/compress/\nDEBUG:groq._base_client:Request options: {&amp;#x27;method&amp;#x27;: &amp;#x27;post&amp;#x27;, &amp;#x27;url&amp;#x27;: &amp;#x27;/openai/v1/chat/completions&amp;#x27;, &amp;#x27;files&amp;#x27;: None, &amp;#x27;json_data&amp;#x27;: {&amp;#x27;messages&amp;#x27;: [{&amp;#x27;role&amp;#x27;: &amp;#x27;system&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate a JSON response following these rules:\\n1. Return multiple UNIQUE versions at the SAME length:\\n   {&amp;quot;versions&amp;quot;: [{&amp;quot;text&amp;quot;: &amp;quot;version1&amp;quot;}, {&amp;quot;text&amp;quot;: &amp;quot;version2&amp;quot;}]}\\n2. Each version must:\\n   - Target exactly the specified percentage\\n   - Use different sentence structures\\n   - Vary word choices while keeping technical terms\\n   - Maintain the same meaning\\n3. If task cannot be completed: {&amp;quot;error&amp;quot;: &amp;quot;specific reason&amp;quot;}&amp;#x27;}, {&amp;#x27;role&amp;#x27;: &amp;#x27;user&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate 5 UNIQUE versions at 20% length:\\n        - Each must be exactly the same length\\n        - Use different phrasings\\n        Original length: 1 tokens\\n        Original text: text&amp;#x27;}], &amp;#x27;model&amp;#x27;: &amp;#x27;llama3-groq-70b-8192-tool-use-preview&amp;#x27;, &amp;#x27;max_tokens&amp;#x27;: 1000, &amp;#x27;temperature&amp;#x27;: 0.7}}\nDEBUG:httpcore.http11:send_request_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.http11:send_request_headers.complete\nDEBUG:httpcore.http11:send_request_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.http11:send_request_body.complete\nDEBUG:httpcore.http11:receive_response_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.http11:receive_response_headers.complete return_value=(b&amp;#x27;HTTP/1.1&amp;#x27;, 200, b&amp;#x27;OK&amp;#x27;, [(b&amp;#x27;Date&amp;#x27;, b&amp;#x27;Wed, 30 Oct 2024 15:53:22 GMT&amp;#x27;), (b&amp;#x27;Content-Type&amp;#x27;, b&amp;#x27;application/json&amp;#x27;), (b&amp;#x27;Transfer-Encoding&amp;#x27;, b&amp;#x27;chunked&amp;#x27;), (b&amp;#x27;Connection&amp;#x27;, b&amp;#x27;keep-alive&amp;#x27;), (b&amp;#x27;Cache-Control&amp;#x27;, b&amp;#x27;private, max-age=0, no-store, no-cache, must-revalidate&amp;#x27;), (b&amp;#x27;vary&amp;#x27;, b&amp;#x27;Origin&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-requests&amp;#x27;, b&amp;#x27;14400&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-tokens&amp;#x27;, b&amp;#x27;15000&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-requests&amp;#x27;, b&amp;#x27;14390&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-tokens&amp;#x27;, b&amp;#x27;14632&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-requests&amp;#x27;, b&amp;#x27;59.194999999s&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-tokens&amp;#x27;, b&amp;#x27;1.47s&amp;#x27;), (b&amp;#x27;x-request-id&amp;#x27;, b&amp;#x27;req_01jbf23b3ef9rt6vsy5zk67zh8&amp;#x27;), (b&amp;#x27;via&amp;#x27;, b&amp;#x27;1.1 google&amp;#x27;), (b&amp;#x27;alt-svc&amp;#x27;, b&amp;#x27;h3=&amp;quot;:443&amp;quot;; ma=86400&amp;#x27;), (b&amp;#x27;CF-Cache-Status&amp;#x27;, b&amp;#x27;DYNAMIC&amp;#x27;), (b&amp;#x27;Server&amp;#x27;, b&amp;#x27;cloudflare&amp;#x27;), (b&amp;#x27;CF-RAY&amp;#x27;, b&amp;#x27;8dac93e68d1bca58-HAM&amp;#x27;), (b&amp;#x27;Content-Encoding&amp;#x27;, b&amp;#x27;gzip&amp;#x27;)])\nINFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;HTTP/1.1 200 OK&amp;quot;\nDEBUG:httpcore.http11:receive_response_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.http11:receive_response_body.complete\nDEBUG:httpcore.http11:response_closed.started\nDEBUG:httpcore.http11:response_closed.complete\nDEBUG:groq._base_client:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;200 OK&amp;quot;\n\n------------------------------ Captured log call -------------------------------\nDEBUG    app:__init__.py:31 Headers: {&amp;#x27;User-Agent&amp;#x27;: &amp;#x27;Werkzeug/3.0.6&amp;#x27;, &amp;#x27;Host&amp;#x27;: &amp;#x27;localhost&amp;#x27;, &amp;#x27;Content-Type&amp;#x27;: &amp;#x27;application/json&amp;#x27;, &amp;#x27;Content-Length&amp;#x27;: &amp;#x27;35&amp;#x27;, &amp;#x27;Authorization&amp;#x27;: &amp;#x27;Bearer test_key&amp;#x27;}\nDEBUG    app:__init__.py:32 Body: b&amp;#x27;{&amp;quot;content&amp;quot;: &amp;quot;text&amp;quot;, &amp;quot;versions&amp;quot;: 10}&amp;#x27;\nDEBUG    app:__init__.py:33 Query Params: {}\nDEBUG    app:__init__.py:34 Route: POST /text/v1/compress/\nDEBUG    groq._base_client:_base_client.py:441 Request options: {&amp;#x27;method&amp;#x27;: &amp;#x27;post&amp;#x27;, &amp;#x27;url&amp;#x27;: &amp;#x27;/openai/v1/chat/completions&amp;#x27;, &amp;#x27;files&amp;#x27;: None, &amp;#x27;json_data&amp;#x27;: {&amp;#x27;messages&amp;#x27;: [{&amp;#x27;role&amp;#x27;: &amp;#x27;system&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate a JSON response following these rules:\\n1. Return multiple UNIQUE versions at the SAME length:\\n   {&amp;quot;versions&amp;quot;: [{&amp;quot;text&amp;quot;: &amp;quot;version1&amp;quot;}, {&amp;quot;text&amp;quot;: &amp;quot;version2&amp;quot;}]}\\n2. Each version must:\\n   - Target exactly the specified percentage\\n   - Use different sentence structures\\n   - Vary word choices while keeping technical terms\\n   - Maintain the same meaning\\n3. If task cannot be completed: {&amp;quot;error&amp;quot;: &amp;quot;specific reason&amp;quot;}&amp;#x27;}, {&amp;#x27;role&amp;#x27;: &amp;#x27;user&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate 5 UNIQUE versions at 20% length:\\n        - Each must be exactly the same length\\n        - Use different phrasings\\n        Original length: 1 tokens\\n        Original text: text&amp;#x27;}], &amp;#x27;model&amp;#x27;: &amp;#x27;llama3-groq-70b-8192-tool-use-preview&amp;#x27;, &amp;#x27;max_tokens&amp;#x27;: 1000, &amp;#x27;temperature&amp;#x27;: 0.7}}\nDEBUG    httpcore.http11:_trace.py:45 send_request_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 send_request_headers.complete\nDEBUG    httpcore.http11:_trace.py:45 send_request_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 send_request_body.complete\nDEBUG    httpcore.http11:_trace.py:45 receive_response_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 receive_response_headers.complete return_value=(b&amp;#x27;HTTP/1.1&amp;#x27;, 200, b&amp;#x27;OK&amp;#x27;, [(b&amp;#x27;Date&amp;#x27;, b&amp;#x27;Wed, 30 Oct 2024 15:53:22 GMT&amp;#x27;), (b&amp;#x27;Content-Type&amp;#x27;, b&amp;#x27;application/json&amp;#x27;), (b&amp;#x27;Transfer-Encoding&amp;#x27;, b&amp;#x27;chunked&amp;#x27;), (b&amp;#x27;Connection&amp;#x27;, b&amp;#x27;keep-alive&amp;#x27;), (b&amp;#x27;Cache-Control&amp;#x27;, b&amp;#x27;private, max-age=0, no-store, no-cache, must-revalidate&amp;#x27;), (b&amp;#x27;vary&amp;#x27;, b&amp;#x27;Origin&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-requests&amp;#x27;, b&amp;#x27;14400&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-tokens&amp;#x27;, b&amp;#x27;15000&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-requests&amp;#x27;, b&amp;#x27;14390&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-tokens&amp;#x27;, b&amp;#x27;14632&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-requests&amp;#x27;, b&amp;#x27;59.194999999s&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-tokens&amp;#x27;, b&amp;#x27;1.47s&amp;#x27;), (b&amp;#x27;x-request-id&amp;#x27;, b&amp;#x27;req_01jbf23b3ef9rt6vsy5zk67zh8&amp;#x27;), (b&amp;#x27;via&amp;#x27;, b&amp;#x27;1.1 google&amp;#x27;), (b&amp;#x27;alt-svc&amp;#x27;, b&amp;#x27;h3=&amp;quot;:443&amp;quot;; ma=86400&amp;#x27;), (b&amp;#x27;CF-Cache-Status&amp;#x27;, b&amp;#x27;DYNAMIC&amp;#x27;), (b&amp;#x27;Server&amp;#x27;, b&amp;#x27;cloudflare&amp;#x27;), (b&amp;#x27;CF-RAY&amp;#x27;, b&amp;#x27;8dac93e68d1bca58-HAM&amp;#x27;), (b&amp;#x27;Content-Encoding&amp;#x27;, b&amp;#x27;gzip&amp;#x27;)])\nINFO     httpx:_client.py:1038 HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;HTTP/1.1 200 OK&amp;quot;\nDEBUG    httpcore.http11:_trace.py:45 receive_response_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 receive_response_body.complete\nDEBUG    httpcore.http11:_trace.py:45 response_closed.started\nDEBUG    httpcore.http11:_trace.py:45 response_closed.complete\nDEBUG    groq._base_client:_base_client.py:956 HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;200 OK&amp;quot;\n\n&#34;}], &#34;tests/performance/test_compress_performance.py::TestCompressEndpoint::test_invalid_inputs[invalid_input3]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Failed&#34;, &#34;testId&#34;: &#34;tests/performance/test_compress_performance.py::TestCompressEndpoint::test_invalid_inputs[invalid_input3]&#34;, &#34;duration&#34;: &#34;817 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Failed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/performance/test_compress_performance.py::TestCompressEndpoint::test_invalid_inputs[invalid_input3]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;817 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;self = &amp;lt;tests.test_compress.TestCompressEndpoint object at 0x106953890&amp;gt;\nclient = &amp;lt;FlaskClient &amp;lt;Flask &amp;#x27;app&amp;#x27;&amp;gt;&amp;gt;\nauth_headers = {&amp;#x27;Authorization&amp;#x27;: &amp;#x27;Bearer test_key&amp;#x27;, &amp;#x27;Content-Type&amp;#x27;: &amp;#x27;application/json&amp;#x27;}\ninvalid_input = {&amp;#x27;content&amp;#x27;: &amp;#x27;&amp;#x27;, &amp;#x27;target_percentage&amp;#x27;: 50}\n\n    @pytest.mark.unit\n    @pytest.mark.parametrize(&amp;#x27;invalid_input&amp;#x27;, [\n        {&amp;#x27;content&amp;#x27;: &amp;quot;text&amp;quot;, &amp;#x27;target_percentage&amp;#x27;: 150},  # Invalid percentage\n        {&amp;#x27;content&amp;#x27;: &amp;quot;text&amp;quot;, &amp;#x27;steps_percentage&amp;#x27;: -10},   # Negative steps\n        {&amp;#x27;content&amp;#x27;: &amp;quot;text&amp;quot;, &amp;#x27;versions&amp;#x27;: 10},            # Too many versions\n        {&amp;#x27;content&amp;#x27;: &amp;quot;&amp;quot;, &amp;#x27;target_percentage&amp;#x27;: 50},       # Empty content\n        {&amp;#x27;target_percentage&amp;#x27;: 50},                      # Missing content\n    ])\n    def test_invalid_inputs(self, client, auth_headers, invalid_input):\n        response = client.post(\n            self.ENDPOINTS[&amp;#x27;compress&amp;#x27;], json=invalid_input, headers=auth_headers)\n&amp;gt;       assert response.status_code == 400\nE       assert 500 == 400\nE        +  where 500 = &amp;lt;WrapperTestResponse streamed [500 INTERNAL SERVER ERROR]&amp;gt;.status_code\n\ntests/test_compress.py:139: AssertionError\n\n---------------------------- Captured stderr setup -----------------------------\nDEBUG:app:Registering blueprints...\nDEBUG:app:Registered routes:\nDEBUG:app:static: /static/&amp;lt;path:filename&amp;gt; [GET, OPTIONS, HEAD]\nDEBUG:app:generate.create_text: /text/v1/generate/text [OPTIONS, POST]\nDEBUG:app:compress.compress_text: /text/v1/compress/ [OPTIONS, POST]\nDEBUG:app:expand.expand_text: /text/v1/expand/ [OPTIONS, POST]\n\n------------------------------ Captured log setup ------------------------------\nDEBUG    app:__init__.py:106 Registering blueprints...\nDEBUG    app:__init__.py:112 Registered routes:\nDEBUG    app:__init__.py:114 static: /static/&amp;lt;path:filename&amp;gt; [GET, OPTIONS, HEAD]\nDEBUG    app:__init__.py:114 generate.create_text: /text/v1/generate/text [OPTIONS, POST]\nDEBUG    app:__init__.py:114 compress.compress_text: /text/v1/compress/ [OPTIONS, POST]\nDEBUG    app:__init__.py:114 expand.expand_text: /text/v1/expand/ [OPTIONS, POST]\n\n----------------------------- Captured stderr call -----------------------------\nDEBUG:app:Headers: {&amp;#x27;User-Agent&amp;#x27;: &amp;#x27;Werkzeug/3.0.6&amp;#x27;, &amp;#x27;Host&amp;#x27;: &amp;#x27;localhost&amp;#x27;, &amp;#x27;Content-Type&amp;#x27;: &amp;#x27;application/json&amp;#x27;, &amp;#x27;Content-Length&amp;#x27;: &amp;#x27;40&amp;#x27;, &amp;#x27;Authorization&amp;#x27;: &amp;#x27;Bearer test_key&amp;#x27;}\nDEBUG:app:Body: b&amp;#x27;{&amp;quot;content&amp;quot;: &amp;quot;&amp;quot;, &amp;quot;target_percentage&amp;quot;: 50}&amp;#x27;\nDEBUG:app:Query Params: {}\nDEBUG:app:Route: POST /text/v1/compress/\nDEBUG:groq._base_client:Request options: {&amp;#x27;method&amp;#x27;: &amp;#x27;post&amp;#x27;, &amp;#x27;url&amp;#x27;: &amp;#x27;/openai/v1/chat/completions&amp;#x27;, &amp;#x27;files&amp;#x27;: None, &amp;#x27;json_data&amp;#x27;: {&amp;#x27;messages&amp;#x27;: [{&amp;#x27;role&amp;#x27;: &amp;#x27;system&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate a JSON response following these rules:\\n1. Return exactly ONE compressed version:\\n   {&amp;quot;versions&amp;quot;: [{&amp;quot;text&amp;quot;: &amp;quot;compressed version&amp;quot;}]}\\n2. Target exactly the specified percentage of original length\\n3. Maintain core meaning while removing less essential details\\n4. Ensure complete sentences and proper punctuation\\n5. If task cannot be completed: {&amp;quot;error&amp;quot;: &amp;quot;specific reason&amp;quot;}&amp;#x27;}, {&amp;#x27;role&amp;#x27;: &amp;#x27;user&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate ONE compressed version at 50% length:\\n        Original length: 0 tokens\\n        Original text: &amp;#x27;}], &amp;#x27;model&amp;#x27;: &amp;#x27;llama3-groq-70b-8192-tool-use-preview&amp;#x27;, &amp;#x27;max_tokens&amp;#x27;: 1000, &amp;#x27;temperature&amp;#x27;: 0.7}}\nDEBUG:httpcore.http11:send_request_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.http11:send_request_headers.complete\nDEBUG:httpcore.http11:send_request_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.http11:send_request_body.complete\nDEBUG:httpcore.http11:receive_response_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.http11:receive_response_headers.complete return_value=(b&amp;#x27;HTTP/1.1&amp;#x27;, 200, b&amp;#x27;OK&amp;#x27;, [(b&amp;#x27;Date&amp;#x27;, b&amp;#x27;Wed, 30 Oct 2024 15:53:22 GMT&amp;#x27;), (b&amp;#x27;Content-Type&amp;#x27;, b&amp;#x27;application/json&amp;#x27;), (b&amp;#x27;Transfer-Encoding&amp;#x27;, b&amp;#x27;chunked&amp;#x27;), (b&amp;#x27;Connection&amp;#x27;, b&amp;#x27;keep-alive&amp;#x27;), (b&amp;#x27;Cache-Control&amp;#x27;, b&amp;#x27;private, max-age=0, no-store, no-cache, must-revalidate&amp;#x27;), (b&amp;#x27;vary&amp;#x27;, b&amp;#x27;Origin&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-requests&amp;#x27;, b&amp;#x27;14400&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-tokens&amp;#x27;, b&amp;#x27;15000&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-requests&amp;#x27;, b&amp;#x27;14389&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-tokens&amp;#x27;, b&amp;#x27;14698&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-requests&amp;#x27;, b&amp;#x27;1m5.116s&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-tokens&amp;#x27;, b&amp;#x27;1.205s&amp;#x27;), (b&amp;#x27;x-request-id&amp;#x27;, b&amp;#x27;req_01jbf23bz2ej7r2v1q4akpsx8z&amp;#x27;), (b&amp;#x27;via&amp;#x27;, b&amp;#x27;1.1 google&amp;#x27;), (b&amp;#x27;alt-svc&amp;#x27;, b&amp;#x27;h3=&amp;quot;:443&amp;quot;; ma=86400&amp;#x27;), (b&amp;#x27;CF-Cache-Status&amp;#x27;, b&amp;#x27;DYNAMIC&amp;#x27;), (b&amp;#x27;Server&amp;#x27;, b&amp;#x27;cloudflare&amp;#x27;), (b&amp;#x27;CF-RAY&amp;#x27;, b&amp;#x27;8dac93ec1b1dca58-HAM&amp;#x27;), (b&amp;#x27;Content-Encoding&amp;#x27;, b&amp;#x27;gzip&amp;#x27;)])\nINFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;HTTP/1.1 200 OK&amp;quot;\nDEBUG:httpcore.http11:receive_response_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.http11:receive_response_body.complete\nDEBUG:httpcore.http11:response_closed.started\nDEBUG:httpcore.http11:response_closed.complete\nDEBUG:groq._base_client:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;200 OK&amp;quot;\n\n------------------------------ Captured log call -------------------------------\nDEBUG    app:__init__.py:31 Headers: {&amp;#x27;User-Agent&amp;#x27;: &amp;#x27;Werkzeug/3.0.6&amp;#x27;, &amp;#x27;Host&amp;#x27;: &amp;#x27;localhost&amp;#x27;, &amp;#x27;Content-Type&amp;#x27;: &amp;#x27;application/json&amp;#x27;, &amp;#x27;Content-Length&amp;#x27;: &amp;#x27;40&amp;#x27;, &amp;#x27;Authorization&amp;#x27;: &amp;#x27;Bearer test_key&amp;#x27;}\nDEBUG    app:__init__.py:32 Body: b&amp;#x27;{&amp;quot;content&amp;quot;: &amp;quot;&amp;quot;, &amp;quot;target_percentage&amp;quot;: 50}&amp;#x27;\nDEBUG    app:__init__.py:33 Query Params: {}\nDEBUG    app:__init__.py:34 Route: POST /text/v1/compress/\nDEBUG    groq._base_client:_base_client.py:441 Request options: {&amp;#x27;method&amp;#x27;: &amp;#x27;post&amp;#x27;, &amp;#x27;url&amp;#x27;: &amp;#x27;/openai/v1/chat/completions&amp;#x27;, &amp;#x27;files&amp;#x27;: None, &amp;#x27;json_data&amp;#x27;: {&amp;#x27;messages&amp;#x27;: [{&amp;#x27;role&amp;#x27;: &amp;#x27;system&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate a JSON response following these rules:\\n1. Return exactly ONE compressed version:\\n   {&amp;quot;versions&amp;quot;: [{&amp;quot;text&amp;quot;: &amp;quot;compressed version&amp;quot;}]}\\n2. Target exactly the specified percentage of original length\\n3. Maintain core meaning while removing less essential details\\n4. Ensure complete sentences and proper punctuation\\n5. If task cannot be completed: {&amp;quot;error&amp;quot;: &amp;quot;specific reason&amp;quot;}&amp;#x27;}, {&amp;#x27;role&amp;#x27;: &amp;#x27;user&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate ONE compressed version at 50% length:\\n        Original length: 0 tokens\\n        Original text: &amp;#x27;}], &amp;#x27;model&amp;#x27;: &amp;#x27;llama3-groq-70b-8192-tool-use-preview&amp;#x27;, &amp;#x27;max_tokens&amp;#x27;: 1000, &amp;#x27;temperature&amp;#x27;: 0.7}}\nDEBUG    httpcore.http11:_trace.py:45 send_request_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 send_request_headers.complete\nDEBUG    httpcore.http11:_trace.py:45 send_request_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 send_request_body.complete\nDEBUG    httpcore.http11:_trace.py:45 receive_response_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 receive_response_headers.complete return_value=(b&amp;#x27;HTTP/1.1&amp;#x27;, 200, b&amp;#x27;OK&amp;#x27;, [(b&amp;#x27;Date&amp;#x27;, b&amp;#x27;Wed, 30 Oct 2024 15:53:22 GMT&amp;#x27;), (b&amp;#x27;Content-Type&amp;#x27;, b&amp;#x27;application/json&amp;#x27;), (b&amp;#x27;Transfer-Encoding&amp;#x27;, b&amp;#x27;chunked&amp;#x27;), (b&amp;#x27;Connection&amp;#x27;, b&amp;#x27;keep-alive&amp;#x27;), (b&amp;#x27;Cache-Control&amp;#x27;, b&amp;#x27;private, max-age=0, no-store, no-cache, must-revalidate&amp;#x27;), (b&amp;#x27;vary&amp;#x27;, b&amp;#x27;Origin&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-requests&amp;#x27;, b&amp;#x27;14400&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-tokens&amp;#x27;, b&amp;#x27;15000&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-requests&amp;#x27;, b&amp;#x27;14389&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-tokens&amp;#x27;, b&amp;#x27;14698&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-requests&amp;#x27;, b&amp;#x27;1m5.116s&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-tokens&amp;#x27;, b&amp;#x27;1.205s&amp;#x27;), (b&amp;#x27;x-request-id&amp;#x27;, b&amp;#x27;req_01jbf23bz2ej7r2v1q4akpsx8z&amp;#x27;), (b&amp;#x27;via&amp;#x27;, b&amp;#x27;1.1 google&amp;#x27;), (b&amp;#x27;alt-svc&amp;#x27;, b&amp;#x27;h3=&amp;quot;:443&amp;quot;; ma=86400&amp;#x27;), (b&amp;#x27;CF-Cache-Status&amp;#x27;, b&amp;#x27;DYNAMIC&amp;#x27;), (b&amp;#x27;Server&amp;#x27;, b&amp;#x27;cloudflare&amp;#x27;), (b&amp;#x27;CF-RAY&amp;#x27;, b&amp;#x27;8dac93ec1b1dca58-HAM&amp;#x27;), (b&amp;#x27;Content-Encoding&amp;#x27;, b&amp;#x27;gzip&amp;#x27;)])\nINFO     httpx:_client.py:1038 HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;HTTP/1.1 200 OK&amp;quot;\nDEBUG    httpcore.http11:_trace.py:45 receive_response_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 receive_response_body.complete\nDEBUG    httpcore.http11:_trace.py:45 response_closed.started\nDEBUG    httpcore.http11:_trace.py:45 response_closed.complete\nDEBUG    groq._base_client:_base_client.py:956 HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;200 OK&amp;quot;\n\n&#34;}], &#34;tests/performance/test_compress_performance.py::TestCompressEndpoint::test_invalid_inputs[invalid_input4]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Failed&#34;, &#34;testId&#34;: &#34;tests/performance/test_compress_performance.py::TestCompressEndpoint::test_invalid_inputs[invalid_input4]&#34;, &#34;duration&#34;: &#34;509 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Failed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/performance/test_compress_performance.py::TestCompressEndpoint::test_invalid_inputs[invalid_input4]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;509 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;self = &amp;lt;tests.test_compress.TestCompressEndpoint object at 0x106953920&amp;gt;\nclient = &amp;lt;FlaskClient &amp;lt;Flask &amp;#x27;app&amp;#x27;&amp;gt;&amp;gt;\nauth_headers = {&amp;#x27;Authorization&amp;#x27;: &amp;#x27;Bearer test_key&amp;#x27;, &amp;#x27;Content-Type&amp;#x27;: &amp;#x27;application/json&amp;#x27;}\ninvalid_input = {&amp;#x27;target_percentage&amp;#x27;: 50}\n\n    @pytest.mark.unit\n    @pytest.mark.parametrize(&amp;#x27;invalid_input&amp;#x27;, [\n        {&amp;#x27;content&amp;#x27;: &amp;quot;text&amp;quot;, &amp;#x27;target_percentage&amp;#x27;: 150},  # Invalid percentage\n        {&amp;#x27;content&amp;#x27;: &amp;quot;text&amp;quot;, &amp;#x27;steps_percentage&amp;#x27;: -10},   # Negative steps\n        {&amp;#x27;content&amp;#x27;: &amp;quot;text&amp;quot;, &amp;#x27;versions&amp;#x27;: 10},            # Too many versions\n        {&amp;#x27;content&amp;#x27;: &amp;quot;&amp;quot;, &amp;#x27;target_percentage&amp;#x27;: 50},       # Empty content\n        {&amp;#x27;target_percentage&amp;#x27;: 50},                      # Missing content\n    ])\n    def test_invalid_inputs(self, client, auth_headers, invalid_input):\n        response = client.post(\n            self.ENDPOINTS[&amp;#x27;compress&amp;#x27;], json=invalid_input, headers=auth_headers)\n&amp;gt;       assert response.status_code == 400\nE       assert 500 == 400\nE        +  where 500 = &amp;lt;WrapperTestResponse streamed [500 INTERNAL SERVER ERROR]&amp;gt;.status_code\n\ntests/test_compress.py:139: AssertionError\n\n---------------------------- Captured stderr setup -----------------------------\nDEBUG:app:Registering blueprints...\nDEBUG:app:Registered routes:\nDEBUG:app:static: /static/&amp;lt;path:filename&amp;gt; [GET, OPTIONS, HEAD]\nDEBUG:app:generate.create_text: /text/v1/generate/text [OPTIONS, POST]\nDEBUG:app:compress.compress_text: /text/v1/compress/ [OPTIONS, POST]\nDEBUG:app:expand.expand_text: /text/v1/expand/ [OPTIONS, POST]\n\n------------------------------ Captured log setup ------------------------------\nDEBUG    app:__init__.py:106 Registering blueprints...\nDEBUG    app:__init__.py:112 Registered routes:\nDEBUG    app:__init__.py:114 static: /static/&amp;lt;path:filename&amp;gt; [GET, OPTIONS, HEAD]\nDEBUG    app:__init__.py:114 generate.create_text: /text/v1/generate/text [OPTIONS, POST]\nDEBUG    app:__init__.py:114 compress.compress_text: /text/v1/compress/ [OPTIONS, POST]\nDEBUG    app:__init__.py:114 expand.expand_text: /text/v1/expand/ [OPTIONS, POST]\n\n----------------------------- Captured stderr call -----------------------------\nDEBUG:app:Headers: {&amp;#x27;User-Agent&amp;#x27;: &amp;#x27;Werkzeug/3.0.6&amp;#x27;, &amp;#x27;Host&amp;#x27;: &amp;#x27;localhost&amp;#x27;, &amp;#x27;Content-Type&amp;#x27;: &amp;#x27;application/json&amp;#x27;, &amp;#x27;Content-Length&amp;#x27;: &amp;#x27;25&amp;#x27;, &amp;#x27;Authorization&amp;#x27;: &amp;#x27;Bearer test_key&amp;#x27;}\nDEBUG:app:Body: b&amp;#x27;{&amp;quot;target_percentage&amp;quot;: 50}&amp;#x27;\nDEBUG:app:Query Params: {}\nDEBUG:app:Route: POST /text/v1/compress/\n\n------------------------------ Captured log call -------------------------------\nDEBUG    app:__init__.py:31 Headers: {&amp;#x27;User-Agent&amp;#x27;: &amp;#x27;Werkzeug/3.0.6&amp;#x27;, &amp;#x27;Host&amp;#x27;: &amp;#x27;localhost&amp;#x27;, &amp;#x27;Content-Type&amp;#x27;: &amp;#x27;application/json&amp;#x27;, &amp;#x27;Content-Length&amp;#x27;: &amp;#x27;25&amp;#x27;, &amp;#x27;Authorization&amp;#x27;: &amp;#x27;Bearer test_key&amp;#x27;}\nDEBUG    app:__init__.py:32 Body: b&amp;#x27;{&amp;quot;target_percentage&amp;quot;: 50}&amp;#x27;\nDEBUG    app:__init__.py:33 Query Params: {}\nDEBUG    app:__init__.py:34 Route: POST /text/v1/compress/\n\n&#34;}], &#34;tests/performance/test_compress_performance.py::TestCompressEndpoint::test_length_validation&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Failed&#34;, &#34;testId&#34;: &#34;tests/performance/test_compress_performance.py::TestCompressEndpoint::test_length_validation&#34;, &#34;duration&#34;: &#34;899 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Failed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/performance/test_compress_performance.py::TestCompressEndpoint::test_length_validation&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;899 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;self = &amp;lt;tests.test_compress.TestCompressEndpoint object at 0x106953560&amp;gt;\nclient = &amp;lt;FlaskClient &amp;lt;Flask &amp;#x27;app&amp;#x27;&amp;gt;&amp;gt;\nauth_headers = {&amp;#x27;Authorization&amp;#x27;: &amp;#x27;Bearer test_key&amp;#x27;, &amp;#x27;Content-Type&amp;#x27;: &amp;#x27;application/json&amp;#x27;}\n\n    @pytest.mark.unit\n    def test_length_validation(self, client, auth_headers):\n        &amp;quot;&amp;quot;&amp;quot;Test if compressed versions roughly match target percentages&amp;quot;&amp;quot;&amp;quot;\n        response = client.post(self.ENDPOINTS[&amp;#x27;compress&amp;#x27;], json={\n            &amp;#x27;content&amp;#x27;: self.SAMPLE_TEXT,\n            &amp;#x27;target_percentage&amp;#x27;: 50,\n            &amp;#x27;versions&amp;#x27;: 1\n        }, headers=auth_headers)\n    \n        data = response.json\n        original_length = len(self.SAMPLE_TEXT)\n        compressed_length = len(data[&amp;#x27;versions&amp;#x27;][0][&amp;#x27;text&amp;#x27;])\n        # Allow 10% margin of error\n&amp;gt;       assert abs(compressed_length/original_length - 0.5) &amp;lt;= 0.1\nE       assert 0.30000000000000004 &amp;lt;= 0.1\nE        +  where 0.30000000000000004 = abs(((168 / 210) - 0.5))\n\ntests/test_compress.py:155: AssertionError\n\n---------------------------- Captured stderr setup -----------------------------\nDEBUG:app:Registering blueprints...\nDEBUG:app:Registered routes:\nDEBUG:app:static: /static/&amp;lt;path:filename&amp;gt; [GET, OPTIONS, HEAD]\nDEBUG:app:generate.create_text: /text/v1/generate/text [OPTIONS, POST]\nDEBUG:app:compress.compress_text: /text/v1/compress/ [OPTIONS, POST]\nDEBUG:app:expand.expand_text: /text/v1/expand/ [OPTIONS, POST]\n\n------------------------------ Captured log setup ------------------------------\nDEBUG    app:__init__.py:106 Registering blueprints...\nDEBUG    app:__init__.py:112 Registered routes:\nDEBUG    app:__init__.py:114 static: /static/&amp;lt;path:filename&amp;gt; [GET, OPTIONS, HEAD]\nDEBUG    app:__init__.py:114 generate.create_text: /text/v1/generate/text [OPTIONS, POST]\nDEBUG    app:__init__.py:114 compress.compress_text: /text/v1/compress/ [OPTIONS, POST]\nDEBUG    app:__init__.py:114 expand.expand_text: /text/v1/expand/ [OPTIONS, POST]\n\n----------------------------- Captured stderr call -----------------------------\nDEBUG:app:Headers: {&amp;#x27;User-Agent&amp;#x27;: &amp;#x27;Werkzeug/3.0.6&amp;#x27;, &amp;#x27;Host&amp;#x27;: &amp;#x27;localhost&amp;#x27;, &amp;#x27;Content-Type&amp;#x27;: &amp;#x27;application/json&amp;#x27;, &amp;#x27;Content-Length&amp;#x27;: &amp;#x27;265&amp;#x27;, &amp;#x27;Authorization&amp;#x27;: &amp;#x27;Bearer test_key&amp;#x27;}\nDEBUG:app:Body: b&amp;#x27;{&amp;quot;content&amp;quot;: &amp;quot;The Text Transformation API offers a robust set of REST endpoints that enable developers to programmatically manipulate and transform text content. The operations include expansion, summarization, and chunking.&amp;quot;, &amp;quot;target_percentage&amp;quot;: 50, &amp;quot;versions&amp;quot;: 1}&amp;#x27;\nDEBUG:app:Query Params: {}\nDEBUG:app:Route: POST /text/v1/compress/\nDEBUG:groq._base_client:Request options: {&amp;#x27;method&amp;#x27;: &amp;#x27;post&amp;#x27;, &amp;#x27;url&amp;#x27;: &amp;#x27;/openai/v1/chat/completions&amp;#x27;, &amp;#x27;files&amp;#x27;: None, &amp;#x27;json_data&amp;#x27;: {&amp;#x27;messages&amp;#x27;: [{&amp;#x27;role&amp;#x27;: &amp;#x27;system&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate a JSON response following these rules:\\n1. Return exactly ONE compressed version:\\n   {&amp;quot;versions&amp;quot;: [{&amp;quot;text&amp;quot;: &amp;quot;compressed version&amp;quot;}]}\\n2. Target exactly the specified percentage of original length\\n3. Maintain core meaning while removing less essential details\\n4. Ensure complete sentences and proper punctuation\\n5. If task cannot be completed: {&amp;quot;error&amp;quot;: &amp;quot;specific reason&amp;quot;}&amp;#x27;}, {&amp;#x27;role&amp;#x27;: &amp;#x27;user&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate ONE compressed version at 50% length:\\n        Original length: 35 tokens\\n        Original text: The Text Transformation API offers a robust set of REST endpoints that enable developers to programmatically manipulate and transform text content. The operations include expansion, summarization, and chunking.&amp;#x27;}], &amp;#x27;model&amp;#x27;: &amp;#x27;llama3-groq-70b-8192-tool-use-preview&amp;#x27;, &amp;#x27;max_tokens&amp;#x27;: 1000, &amp;#x27;temperature&amp;#x27;: 0.7}}\nDEBUG:httpcore.http11:send_request_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.http11:send_request_headers.complete\nDEBUG:httpcore.http11:send_request_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.http11:send_request_body.complete\nDEBUG:httpcore.http11:receive_response_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.http11:receive_response_headers.complete return_value=(b&amp;#x27;HTTP/1.1&amp;#x27;, 200, b&amp;#x27;OK&amp;#x27;, [(b&amp;#x27;Date&amp;#x27;, b&amp;#x27;Wed, 30 Oct 2024 15:53:24 GMT&amp;#x27;), (b&amp;#x27;Content-Type&amp;#x27;, b&amp;#x27;application/json&amp;#x27;), (b&amp;#x27;Transfer-Encoding&amp;#x27;, b&amp;#x27;chunked&amp;#x27;), (b&amp;#x27;Connection&amp;#x27;, b&amp;#x27;keep-alive&amp;#x27;), (b&amp;#x27;Cache-Control&amp;#x27;, b&amp;#x27;private, max-age=0, no-store, no-cache, must-revalidate&amp;#x27;), (b&amp;#x27;vary&amp;#x27;, b&amp;#x27;Origin&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-requests&amp;#x27;, b&amp;#x27;14400&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-tokens&amp;#x27;, b&amp;#x27;15000&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-requests&amp;#x27;, b&amp;#x27;14388&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-tokens&amp;#x27;, b&amp;#x27;14818&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-requests&amp;#x27;, b&amp;#x27;1m10.674s&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-tokens&amp;#x27;, b&amp;#x27;728ms&amp;#x27;), (b&amp;#x27;x-request-id&amp;#x27;, b&amp;#x27;req_01jbf23d8hf9rrn8m57x8svtvb&amp;#x27;), (b&amp;#x27;via&amp;#x27;, b&amp;#x27;1.1 google&amp;#x27;), (b&amp;#x27;alt-svc&amp;#x27;, b&amp;#x27;h3=&amp;quot;:443&amp;quot;; ma=86400&amp;#x27;), (b&amp;#x27;CF-Cache-Status&amp;#x27;, b&amp;#x27;DYNAMIC&amp;#x27;), (b&amp;#x27;Server&amp;#x27;, b&amp;#x27;cloudflare&amp;#x27;), (b&amp;#x27;CF-RAY&amp;#x27;, b&amp;#x27;8dac93f45d0cca58-HAM&amp;#x27;), (b&amp;#x27;Content-Encoding&amp;#x27;, b&amp;#x27;gzip&amp;#x27;)])\nINFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;HTTP/1.1 200 OK&amp;quot;\nDEBUG:httpcore.http11:receive_response_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.http11:receive_response_body.complete\nDEBUG:httpcore.http11:response_closed.started\nDEBUG:httpcore.http11:response_closed.complete\nDEBUG:groq._base_client:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;200 OK&amp;quot;\n\n------------------------------ Captured log call -------------------------------\nDEBUG    app:__init__.py:31 Headers: {&amp;#x27;User-Agent&amp;#x27;: &amp;#x27;Werkzeug/3.0.6&amp;#x27;, &amp;#x27;Host&amp;#x27;: &amp;#x27;localhost&amp;#x27;, &amp;#x27;Content-Type&amp;#x27;: &amp;#x27;application/json&amp;#x27;, &amp;#x27;Content-Length&amp;#x27;: &amp;#x27;265&amp;#x27;, &amp;#x27;Authorization&amp;#x27;: &amp;#x27;Bearer test_key&amp;#x27;}\nDEBUG    app:__init__.py:32 Body: b&amp;#x27;{&amp;quot;content&amp;quot;: &amp;quot;The Text Transformation API offers a robust set of REST endpoints that enable developers to programmatically manipulate and transform text content. The operations include expansion, summarization, and chunking.&amp;quot;, &amp;quot;target_percentage&amp;quot;: 50, &amp;quot;versions&amp;quot;: 1}&amp;#x27;\nDEBUG    app:__init__.py:33 Query Params: {}\nDEBUG    app:__init__.py:34 Route: POST /text/v1/compress/\nDEBUG    groq._base_client:_base_client.py:441 Request options: {&amp;#x27;method&amp;#x27;: &amp;#x27;post&amp;#x27;, &amp;#x27;url&amp;#x27;: &amp;#x27;/openai/v1/chat/completions&amp;#x27;, &amp;#x27;files&amp;#x27;: None, &amp;#x27;json_data&amp;#x27;: {&amp;#x27;messages&amp;#x27;: [{&amp;#x27;role&amp;#x27;: &amp;#x27;system&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate a JSON response following these rules:\\n1. Return exactly ONE compressed version:\\n   {&amp;quot;versions&amp;quot;: [{&amp;quot;text&amp;quot;: &amp;quot;compressed version&amp;quot;}]}\\n2. Target exactly the specified percentage of original length\\n3. Maintain core meaning while removing less essential details\\n4. Ensure complete sentences and proper punctuation\\n5. If task cannot be completed: {&amp;quot;error&amp;quot;: &amp;quot;specific reason&amp;quot;}&amp;#x27;}, {&amp;#x27;role&amp;#x27;: &amp;#x27;user&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate ONE compressed version at 50% length:\\n        Original length: 35 tokens\\n        Original text: The Text Transformation API offers a robust set of REST endpoints that enable developers to programmatically manipulate and transform text content. The operations include expansion, summarization, and chunking.&amp;#x27;}], &amp;#x27;model&amp;#x27;: &amp;#x27;llama3-groq-70b-8192-tool-use-preview&amp;#x27;, &amp;#x27;max_tokens&amp;#x27;: 1000, &amp;#x27;temperature&amp;#x27;: 0.7}}\nDEBUG    httpcore.http11:_trace.py:45 send_request_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 send_request_headers.complete\nDEBUG    httpcore.http11:_trace.py:45 send_request_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 send_request_body.complete\nDEBUG    httpcore.http11:_trace.py:45 receive_response_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 receive_response_headers.complete return_value=(b&amp;#x27;HTTP/1.1&amp;#x27;, 200, b&amp;#x27;OK&amp;#x27;, [(b&amp;#x27;Date&amp;#x27;, b&amp;#x27;Wed, 30 Oct 2024 15:53:24 GMT&amp;#x27;), (b&amp;#x27;Content-Type&amp;#x27;, b&amp;#x27;application/json&amp;#x27;), (b&amp;#x27;Transfer-Encoding&amp;#x27;, b&amp;#x27;chunked&amp;#x27;), (b&amp;#x27;Connection&amp;#x27;, b&amp;#x27;keep-alive&amp;#x27;), (b&amp;#x27;Cache-Control&amp;#x27;, b&amp;#x27;private, max-age=0, no-store, no-cache, must-revalidate&amp;#x27;), (b&amp;#x27;vary&amp;#x27;, b&amp;#x27;Origin&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-requests&amp;#x27;, b&amp;#x27;14400&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-tokens&amp;#x27;, b&amp;#x27;15000&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-requests&amp;#x27;, b&amp;#x27;14388&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-tokens&amp;#x27;, b&amp;#x27;14818&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-requests&amp;#x27;, b&amp;#x27;1m10.674s&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-tokens&amp;#x27;, b&amp;#x27;728ms&amp;#x27;), (b&amp;#x27;x-request-id&amp;#x27;, b&amp;#x27;req_01jbf23d8hf9rrn8m57x8svtvb&amp;#x27;), (b&amp;#x27;via&amp;#x27;, b&amp;#x27;1.1 google&amp;#x27;), (b&amp;#x27;alt-svc&amp;#x27;, b&amp;#x27;h3=&amp;quot;:443&amp;quot;; ma=86400&amp;#x27;), (b&amp;#x27;CF-Cache-Status&amp;#x27;, b&amp;#x27;DYNAMIC&amp;#x27;), (b&amp;#x27;Server&amp;#x27;, b&amp;#x27;cloudflare&amp;#x27;), (b&amp;#x27;CF-RAY&amp;#x27;, b&amp;#x27;8dac93f45d0cca58-HAM&amp;#x27;), (b&amp;#x27;Content-Encoding&amp;#x27;, b&amp;#x27;gzip&amp;#x27;)])\nINFO     httpx:_client.py:1038 HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;HTTP/1.1 200 OK&amp;quot;\nDEBUG    httpcore.http11:_trace.py:45 receive_response_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 receive_response_body.complete\nDEBUG    httpcore.http11:_trace.py:45 response_closed.started\nDEBUG    httpcore.http11:_trace.py:45 response_closed.complete\nDEBUG    groq._base_client:_base_client.py:956 HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;200 OK&amp;quot;\n\n&#34;}], &#34;tests/performance/test_compress_performance.py::TestCompressPerformance::test_single_version_compression&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Failed&#34;, &#34;testId&#34;: &#34;tests/performance/test_compress_performance.py::TestCompressPerformance::test_single_version_compression&#34;, &#34;duration&#34;: &#34;922 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Failed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/performance/test_compress_performance.py::TestCompressPerformance::test_single_version_compression&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;922 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;self = &amp;lt;tests.performance.test_compress_performance.TestCompressPerformance object at 0x1069d0080&amp;gt;\nclient = &amp;lt;FlaskClient &amp;lt;Flask &amp;#x27;app&amp;#x27;&amp;gt;&amp;gt;\nauth_headers = {&amp;#x27;Authorization&amp;#x27;: &amp;#x27;Bearer test_key&amp;#x27;, &amp;#x27;Content-Type&amp;#x27;: &amp;#x27;application/json&amp;#x27;}\n\n    @pytest.mark.unit\n    def test_single_version_compression(self, client, auth_headers):\n        response = client.post(self.ENDPOINTS[&amp;#x27;compress&amp;#x27;], json={\n            &amp;#x27;content&amp;#x27;: self.SAMPLE_TEXT,\n            &amp;#x27;target_percentage&amp;#x27;: 40\n        }, headers=auth_headers)\n    \n        assert response.status_code == 200\n        data = response.json\n    \n        # Test response structure\n        assert data[&amp;#x27;type&amp;#x27;] == &amp;#x27;cohesive&amp;#x27;\n        assert len(data[&amp;#x27;versions&amp;#x27;]) == 1\n    \n        version = data[&amp;#x27;versions&amp;#x27;][0]\n        assert &amp;#x27;text&amp;#x27; in version\n        assert &amp;#x27;final_percentage&amp;#x27; in version\n        assert isinstance(version[&amp;#x27;final_percentage&amp;#x27;], float)\n    \n        # Test compression quality\n        compressed_text = version[&amp;#x27;text&amp;#x27;]\n        target_percentage = 40\n&amp;gt;       assert abs(version[&amp;#x27;final_percentage&amp;#x27;] -\n                   target_percentage) &amp;lt;= 10  # 10% margin\nE       assert 28.599999999999994 &amp;lt;= 10\nE        +  where 28.599999999999994 = abs((68.6 - 40))\n\ntests/test_compress.py:52: AssertionError\n\n---------------------------- Captured stderr setup -----------------------------\nDEBUG:app:Registering blueprints...\nDEBUG:app:Registered routes:\nDEBUG:app:static: /static/&amp;lt;path:filename&amp;gt; [GET, OPTIONS, HEAD]\nDEBUG:app:generate.create_text: /text/v1/generate/text [OPTIONS, POST]\nDEBUG:app:compress.compress_text: /text/v1/compress/ [OPTIONS, POST]\nDEBUG:app:expand.expand_text: /text/v1/expand/ [OPTIONS, POST]\n\n------------------------------ Captured log setup ------------------------------\nDEBUG    app:__init__.py:106 Registering blueprints...\nDEBUG    app:__init__.py:112 Registered routes:\nDEBUG    app:__init__.py:114 static: /static/&amp;lt;path:filename&amp;gt; [GET, OPTIONS, HEAD]\nDEBUG    app:__init__.py:114 generate.create_text: /text/v1/generate/text [OPTIONS, POST]\nDEBUG    app:__init__.py:114 compress.compress_text: /text/v1/compress/ [OPTIONS, POST]\nDEBUG    app:__init__.py:114 expand.expand_text: /text/v1/expand/ [OPTIONS, POST]\n\n----------------------------- Captured stderr call -----------------------------\nDEBUG:app:Headers: {&amp;#x27;User-Agent&amp;#x27;: &amp;#x27;Werkzeug/3.0.6&amp;#x27;, &amp;#x27;Host&amp;#x27;: &amp;#x27;localhost&amp;#x27;, &amp;#x27;Content-Type&amp;#x27;: &amp;#x27;application/json&amp;#x27;, &amp;#x27;Content-Length&amp;#x27;: &amp;#x27;250&amp;#x27;, &amp;#x27;Authorization&amp;#x27;: &amp;#x27;Bearer test_key&amp;#x27;}\nDEBUG:app:Body: b&amp;#x27;{&amp;quot;content&amp;quot;: &amp;quot;The Text Transformation API offers a robust set of REST endpoints that enable developers to programmatically manipulate and transform text content. The operations include expansion, summarization, and chunking.&amp;quot;, &amp;quot;target_percentage&amp;quot;: 40}&amp;#x27;\nDEBUG:app:Query Params: {}\nDEBUG:app:Route: POST /text/v1/compress/\nDEBUG:groq._base_client:Request options: {&amp;#x27;method&amp;#x27;: &amp;#x27;post&amp;#x27;, &amp;#x27;url&amp;#x27;: &amp;#x27;/openai/v1/chat/completions&amp;#x27;, &amp;#x27;files&amp;#x27;: None, &amp;#x27;json_data&amp;#x27;: {&amp;#x27;messages&amp;#x27;: [{&amp;#x27;role&amp;#x27;: &amp;#x27;system&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate a JSON response following these rules:\\n1. Return exactly ONE compressed version:\\n   {&amp;quot;versions&amp;quot;: [{&amp;quot;text&amp;quot;: &amp;quot;compressed version&amp;quot;}]}\\n2. Target exactly the specified percentage of original length\\n3. Maintain core meaning while removing less essential details\\n4. Ensure complete sentences and proper punctuation\\n5. If task cannot be completed: {&amp;quot;error&amp;quot;: &amp;quot;specific reason&amp;quot;}&amp;#x27;}, {&amp;#x27;role&amp;#x27;: &amp;#x27;user&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate ONE compressed version at 40% length:\\n        Original length: 35 tokens\\n        Original text: The Text Transformation API offers a robust set of REST endpoints that enable developers to programmatically manipulate and transform text content. The operations include expansion, summarization, and chunking.&amp;#x27;}], &amp;#x27;model&amp;#x27;: &amp;#x27;llama3-groq-70b-8192-tool-use-preview&amp;#x27;, &amp;#x27;max_tokens&amp;#x27;: 1000, &amp;#x27;temperature&amp;#x27;: 0.7}}\nDEBUG:httpcore.http11:send_request_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.http11:send_request_headers.complete\nDEBUG:httpcore.http11:send_request_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.http11:send_request_body.complete\nDEBUG:httpcore.http11:receive_response_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.http11:receive_response_headers.complete return_value=(b&amp;#x27;HTTP/1.1&amp;#x27;, 200, b&amp;#x27;OK&amp;#x27;, [(b&amp;#x27;Date&amp;#x27;, b&amp;#x27;Wed, 30 Oct 2024 15:53:25 GMT&amp;#x27;), (b&amp;#x27;Content-Type&amp;#x27;, b&amp;#x27;application/json&amp;#x27;), (b&amp;#x27;Transfer-Encoding&amp;#x27;, b&amp;#x27;chunked&amp;#x27;), (b&amp;#x27;Connection&amp;#x27;, b&amp;#x27;keep-alive&amp;#x27;), (b&amp;#x27;Cache-Control&amp;#x27;, b&amp;#x27;private, max-age=0, no-store, no-cache, must-revalidate&amp;#x27;), (b&amp;#x27;vary&amp;#x27;, b&amp;#x27;Origin&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-requests&amp;#x27;, b&amp;#x27;14400&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-tokens&amp;#x27;, b&amp;#x27;15000&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-requests&amp;#x27;, b&amp;#x27;14387&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-tokens&amp;#x27;, b&amp;#x27;14810&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-requests&amp;#x27;, b&amp;#x27;1m17.088999999s&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-tokens&amp;#x27;, b&amp;#x27;759ms&amp;#x27;), (b&amp;#x27;x-request-id&amp;#x27;, b&amp;#x27;req_01jbf23e51fknaackyz3507tvz&amp;#x27;), (b&amp;#x27;via&amp;#x27;, b&amp;#x27;1.1 google&amp;#x27;), (b&amp;#x27;alt-svc&amp;#x27;, b&amp;#x27;h3=&amp;quot;:443&amp;quot;; ma=86400&amp;#x27;), (b&amp;#x27;CF-Cache-Status&amp;#x27;, b&amp;#x27;DYNAMIC&amp;#x27;), (b&amp;#x27;Server&amp;#x27;, b&amp;#x27;cloudflare&amp;#x27;), (b&amp;#x27;CF-RAY&amp;#x27;, b&amp;#x27;8dac93fa0b83ca58-HAM&amp;#x27;), (b&amp;#x27;Content-Encoding&amp;#x27;, b&amp;#x27;gzip&amp;#x27;)])\nINFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;HTTP/1.1 200 OK&amp;quot;\nDEBUG:httpcore.http11:receive_response_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.http11:receive_response_body.complete\nDEBUG:httpcore.http11:response_closed.started\nDEBUG:httpcore.http11:response_closed.complete\nDEBUG:groq._base_client:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;200 OK&amp;quot;\n\n------------------------------ Captured log call -------------------------------\nDEBUG    app:__init__.py:31 Headers: {&amp;#x27;User-Agent&amp;#x27;: &amp;#x27;Werkzeug/3.0.6&amp;#x27;, &amp;#x27;Host&amp;#x27;: &amp;#x27;localhost&amp;#x27;, &amp;#x27;Content-Type&amp;#x27;: &amp;#x27;application/json&amp;#x27;, &amp;#x27;Content-Length&amp;#x27;: &amp;#x27;250&amp;#x27;, &amp;#x27;Authorization&amp;#x27;: &amp;#x27;Bearer test_key&amp;#x27;}\nDEBUG    app:__init__.py:32 Body: b&amp;#x27;{&amp;quot;content&amp;quot;: &amp;quot;The Text Transformation API offers a robust set of REST endpoints that enable developers to programmatically manipulate and transform text content. The operations include expansion, summarization, and chunking.&amp;quot;, &amp;quot;target_percentage&amp;quot;: 40}&amp;#x27;\nDEBUG    app:__init__.py:33 Query Params: {}\nDEBUG    app:__init__.py:34 Route: POST /text/v1/compress/\nDEBUG    groq._base_client:_base_client.py:441 Request options: {&amp;#x27;method&amp;#x27;: &amp;#x27;post&amp;#x27;, &amp;#x27;url&amp;#x27;: &amp;#x27;/openai/v1/chat/completions&amp;#x27;, &amp;#x27;files&amp;#x27;: None, &amp;#x27;json_data&amp;#x27;: {&amp;#x27;messages&amp;#x27;: [{&amp;#x27;role&amp;#x27;: &amp;#x27;system&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate a JSON response following these rules:\\n1. Return exactly ONE compressed version:\\n   {&amp;quot;versions&amp;quot;: [{&amp;quot;text&amp;quot;: &amp;quot;compressed version&amp;quot;}]}\\n2. Target exactly the specified percentage of original length\\n3. Maintain core meaning while removing less essential details\\n4. Ensure complete sentences and proper punctuation\\n5. If task cannot be completed: {&amp;quot;error&amp;quot;: &amp;quot;specific reason&amp;quot;}&amp;#x27;}, {&amp;#x27;role&amp;#x27;: &amp;#x27;user&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate ONE compressed version at 40% length:\\n        Original length: 35 tokens\\n        Original text: The Text Transformation API offers a robust set of REST endpoints that enable developers to programmatically manipulate and transform text content. The operations include expansion, summarization, and chunking.&amp;#x27;}], &amp;#x27;model&amp;#x27;: &amp;#x27;llama3-groq-70b-8192-tool-use-preview&amp;#x27;, &amp;#x27;max_tokens&amp;#x27;: 1000, &amp;#x27;temperature&amp;#x27;: 0.7}}\nDEBUG    httpcore.http11:_trace.py:45 send_request_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 send_request_headers.complete\nDEBUG    httpcore.http11:_trace.py:45 send_request_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 send_request_body.complete\nDEBUG    httpcore.http11:_trace.py:45 receive_response_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 receive_response_headers.complete return_value=(b&amp;#x27;HTTP/1.1&amp;#x27;, 200, b&amp;#x27;OK&amp;#x27;, [(b&amp;#x27;Date&amp;#x27;, b&amp;#x27;Wed, 30 Oct 2024 15:53:25 GMT&amp;#x27;), (b&amp;#x27;Content-Type&amp;#x27;, b&amp;#x27;application/json&amp;#x27;), (b&amp;#x27;Transfer-Encoding&amp;#x27;, b&amp;#x27;chunked&amp;#x27;), (b&amp;#x27;Connection&amp;#x27;, b&amp;#x27;keep-alive&amp;#x27;), (b&amp;#x27;Cache-Control&amp;#x27;, b&amp;#x27;private, max-age=0, no-store, no-cache, must-revalidate&amp;#x27;), (b&amp;#x27;vary&amp;#x27;, b&amp;#x27;Origin&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-requests&amp;#x27;, b&amp;#x27;14400&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-tokens&amp;#x27;, b&amp;#x27;15000&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-requests&amp;#x27;, b&amp;#x27;14387&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-tokens&amp;#x27;, b&amp;#x27;14810&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-requests&amp;#x27;, b&amp;#x27;1m17.088999999s&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-tokens&amp;#x27;, b&amp;#x27;759ms&amp;#x27;), (b&amp;#x27;x-request-id&amp;#x27;, b&amp;#x27;req_01jbf23e51fknaackyz3507tvz&amp;#x27;), (b&amp;#x27;via&amp;#x27;, b&amp;#x27;1.1 google&amp;#x27;), (b&amp;#x27;alt-svc&amp;#x27;, b&amp;#x27;h3=&amp;quot;:443&amp;quot;; ma=86400&amp;#x27;), (b&amp;#x27;CF-Cache-Status&amp;#x27;, b&amp;#x27;DYNAMIC&amp;#x27;), (b&amp;#x27;Server&amp;#x27;, b&amp;#x27;cloudflare&amp;#x27;), (b&amp;#x27;CF-RAY&amp;#x27;, b&amp;#x27;8dac93fa0b83ca58-HAM&amp;#x27;), (b&amp;#x27;Content-Encoding&amp;#x27;, b&amp;#x27;gzip&amp;#x27;)])\nINFO     httpx:_client.py:1038 HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;HTTP/1.1 200 OK&amp;quot;\nDEBUG    httpcore.http11:_trace.py:45 receive_response_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 receive_response_body.complete\nDEBUG    httpcore.http11:_trace.py:45 response_closed.started\nDEBUG    httpcore.http11:_trace.py:45 response_closed.complete\nDEBUG    groq._base_client:_base_client.py:956 HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;200 OK&amp;quot;\n\n&#34;}], &#34;tests/performance/test_compress_performance.py::TestCompressPerformance::test_fixed_multiple_versions&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Failed&#34;, &#34;testId&#34;: &#34;tests/performance/test_compress_performance.py::TestCompressPerformance::test_fixed_multiple_versions&#34;, &#34;duration&#34;: &#34;00:00:01&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Failed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/performance/test_compress_performance.py::TestCompressPerformance::test_fixed_multiple_versions&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:01&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;self = &amp;lt;tests.performance.test_compress_performance.TestCompressPerformance object at 0x106953bf0&amp;gt;\nclient = &amp;lt;FlaskClient &amp;lt;Flask &amp;#x27;app&amp;#x27;&amp;gt;&amp;gt;\nauth_headers = {&amp;#x27;Authorization&amp;#x27;: &amp;#x27;Bearer test_key&amp;#x27;, &amp;#x27;Content-Type&amp;#x27;: &amp;#x27;application/json&amp;#x27;}\n\n    @pytest.mark.unit\n    def test_fixed_multiple_versions(self, client, auth_headers):\n        response = client.post(self.ENDPOINTS[&amp;#x27;compress&amp;#x27;], json={\n            &amp;#x27;content&amp;#x27;: self.SAMPLE_TEXT,\n            &amp;#x27;target_percentage&amp;#x27;: 50,\n            &amp;#x27;versions&amp;#x27;: 3\n        }, headers=auth_headers)\n    \n        assert response.status_code == 200\n        data = response.json\n        assert len(data[&amp;#x27;versions&amp;#x27;]) == 3\n        # All versions same length\n&amp;gt;       assert len(set(len(v[&amp;#x27;text&amp;#x27;]) for v in data[&amp;#x27;versions&amp;#x27;])) == 1\nE       assert 3 == 1\nE        +  where 3 = len({185, 192, 201})\nE        +    where {185, 192, 201} = set(&amp;lt;generator object TestCompressEndpoint.test_fixed_multiple_versions.&amp;lt;locals&amp;gt;.&amp;lt;genexpr&amp;gt; at 0x108983a00&amp;gt;)\n\ntests/test_compress.py:72: AssertionError\n\n---------------------------- Captured stderr setup -----------------------------\nDEBUG:app:Registering blueprints...\nDEBUG:app:Registered routes:\nDEBUG:app:static: /static/&amp;lt;path:filename&amp;gt; [GET, OPTIONS, HEAD]\nDEBUG:app:generate.create_text: /text/v1/generate/text [OPTIONS, POST]\nDEBUG:app:compress.compress_text: /text/v1/compress/ [OPTIONS, POST]\nDEBUG:app:expand.expand_text: /text/v1/expand/ [OPTIONS, POST]\n\n------------------------------ Captured log setup ------------------------------\nDEBUG    app:__init__.py:106 Registering blueprints...\nDEBUG    app:__init__.py:112 Registered routes:\nDEBUG    app:__init__.py:114 static: /static/&amp;lt;path:filename&amp;gt; [GET, OPTIONS, HEAD]\nDEBUG    app:__init__.py:114 generate.create_text: /text/v1/generate/text [OPTIONS, POST]\nDEBUG    app:__init__.py:114 compress.compress_text: /text/v1/compress/ [OPTIONS, POST]\nDEBUG    app:__init__.py:114 expand.expand_text: /text/v1/expand/ [OPTIONS, POST]\n\n----------------------------- Captured stderr call -----------------------------\nDEBUG:app:Headers: {&amp;#x27;User-Agent&amp;#x27;: &amp;#x27;Werkzeug/3.0.6&amp;#x27;, &amp;#x27;Host&amp;#x27;: &amp;#x27;localhost&amp;#x27;, &amp;#x27;Content-Type&amp;#x27;: &amp;#x27;application/json&amp;#x27;, &amp;#x27;Content-Length&amp;#x27;: &amp;#x27;265&amp;#x27;, &amp;#x27;Authorization&amp;#x27;: &amp;#x27;Bearer test_key&amp;#x27;}\nDEBUG:app:Body: b&amp;#x27;{&amp;quot;content&amp;quot;: &amp;quot;The Text Transformation API offers a robust set of REST endpoints that enable developers to programmatically manipulate and transform text content. The operations include expansion, summarization, and chunking.&amp;quot;, &amp;quot;target_percentage&amp;quot;: 50, &amp;quot;versions&amp;quot;: 3}&amp;#x27;\nDEBUG:app:Query Params: {}\nDEBUG:app:Route: POST /text/v1/compress/\nDEBUG:groq._base_client:Request options: {&amp;#x27;method&amp;#x27;: &amp;#x27;post&amp;#x27;, &amp;#x27;url&amp;#x27;: &amp;#x27;/openai/v1/chat/completions&amp;#x27;, &amp;#x27;files&amp;#x27;: None, &amp;#x27;json_data&amp;#x27;: {&amp;#x27;messages&amp;#x27;: [{&amp;#x27;role&amp;#x27;: &amp;#x27;system&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate a JSON response following these rules:\\n1. Return multiple UNIQUE versions at the SAME length:\\n   {&amp;quot;versions&amp;quot;: [{&amp;quot;text&amp;quot;: &amp;quot;version1&amp;quot;}, {&amp;quot;text&amp;quot;: &amp;quot;version2&amp;quot;}]}\\n2. Each version must:\\n   - Target exactly the specified percentage\\n   - Use different sentence structures\\n   - Vary word choices while keeping technical terms\\n   - Maintain the same meaning\\n3. If task cannot be completed: {&amp;quot;error&amp;quot;: &amp;quot;specific reason&amp;quot;}&amp;#x27;}, {&amp;#x27;role&amp;#x27;: &amp;#x27;user&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate 3 UNIQUE versions at 50% length:\\n        - Each must be exactly the same length\\n        - Use different phrasings\\n        Original length: 35 tokens\\n        Original text: The Text Transformation API offers a robust set of REST endpoints that enable developers to programmatically manipulate and transform text content. The operations include expansion, summarization, and chunking.&amp;#x27;}], &amp;#x27;model&amp;#x27;: &amp;#x27;llama3-groq-70b-8192-tool-use-preview&amp;#x27;, &amp;#x27;max_tokens&amp;#x27;: 1000, &amp;#x27;temperature&amp;#x27;: 0.7}}\nDEBUG:httpcore.http11:send_request_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.http11:send_request_headers.complete\nDEBUG:httpcore.http11:send_request_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.http11:send_request_body.complete\nDEBUG:httpcore.http11:receive_response_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.http11:receive_response_headers.complete return_value=(b&amp;#x27;HTTP/1.1&amp;#x27;, 200, b&amp;#x27;OK&amp;#x27;, [(b&amp;#x27;Date&amp;#x27;, b&amp;#x27;Wed, 30 Oct 2024 15:53:26 GMT&amp;#x27;), (b&amp;#x27;Content-Type&amp;#x27;, b&amp;#x27;application/json&amp;#x27;), (b&amp;#x27;Transfer-Encoding&amp;#x27;, b&amp;#x27;chunked&amp;#x27;), (b&amp;#x27;Connection&amp;#x27;, b&amp;#x27;keep-alive&amp;#x27;), (b&amp;#x27;Cache-Control&amp;#x27;, b&amp;#x27;private, max-age=0, no-store, no-cache, must-revalidate&amp;#x27;), (b&amp;#x27;vary&amp;#x27;, b&amp;#x27;Origin&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-requests&amp;#x27;, b&amp;#x27;14400&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-tokens&amp;#x27;, b&amp;#x27;15000&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-requests&amp;#x27;, b&amp;#x27;14386&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-tokens&amp;#x27;, b&amp;#x27;14790&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-requests&amp;#x27;, b&amp;#x27;1m23.077999999s&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-tokens&amp;#x27;, b&amp;#x27;840ms&amp;#x27;), (b&amp;#x27;x-request-id&amp;#x27;, b&amp;#x27;req_01jbf23f1xe6db7d9xmbpc78ty&amp;#x27;), (b&amp;#x27;via&amp;#x27;, b&amp;#x27;1.1 google&amp;#x27;), (b&amp;#x27;alt-svc&amp;#x27;, b&amp;#x27;h3=&amp;quot;:443&amp;quot;; ma=86400&amp;#x27;), (b&amp;#x27;CF-Cache-Status&amp;#x27;, b&amp;#x27;DYNAMIC&amp;#x27;), (b&amp;#x27;Server&amp;#x27;, b&amp;#x27;cloudflare&amp;#x27;), (b&amp;#x27;CF-RAY&amp;#x27;, b&amp;#x27;8dac93ffca1bca58-HAM&amp;#x27;), (b&amp;#x27;Content-Encoding&amp;#x27;, b&amp;#x27;gzip&amp;#x27;)])\nINFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;HTTP/1.1 200 OK&amp;quot;\nDEBUG:httpcore.http11:receive_response_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.http11:receive_response_body.complete\nDEBUG:httpcore.http11:response_closed.started\nDEBUG:httpcore.http11:response_closed.complete\nDEBUG:groq._base_client:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;200 OK&amp;quot;\n\n------------------------------ Captured log call -------------------------------\nDEBUG    app:__init__.py:31 Headers: {&amp;#x27;User-Agent&amp;#x27;: &amp;#x27;Werkzeug/3.0.6&amp;#x27;, &amp;#x27;Host&amp;#x27;: &amp;#x27;localhost&amp;#x27;, &amp;#x27;Content-Type&amp;#x27;: &amp;#x27;application/json&amp;#x27;, &amp;#x27;Content-Length&amp;#x27;: &amp;#x27;265&amp;#x27;, &amp;#x27;Authorization&amp;#x27;: &amp;#x27;Bearer test_key&amp;#x27;}\nDEBUG    app:__init__.py:32 Body: b&amp;#x27;{&amp;quot;content&amp;quot;: &amp;quot;The Text Transformation API offers a robust set of REST endpoints that enable developers to programmatically manipulate and transform text content. The operations include expansion, summarization, and chunking.&amp;quot;, &amp;quot;target_percentage&amp;quot;: 50, &amp;quot;versions&amp;quot;: 3}&amp;#x27;\nDEBUG    app:__init__.py:33 Query Params: {}\nDEBUG    app:__init__.py:34 Route: POST /text/v1/compress/\nDEBUG    groq._base_client:_base_client.py:441 Request options: {&amp;#x27;method&amp;#x27;: &amp;#x27;post&amp;#x27;, &amp;#x27;url&amp;#x27;: &amp;#x27;/openai/v1/chat/completions&amp;#x27;, &amp;#x27;files&amp;#x27;: None, &amp;#x27;json_data&amp;#x27;: {&amp;#x27;messages&amp;#x27;: [{&amp;#x27;role&amp;#x27;: &amp;#x27;system&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate a JSON response following these rules:\\n1. Return multiple UNIQUE versions at the SAME length:\\n   {&amp;quot;versions&amp;quot;: [{&amp;quot;text&amp;quot;: &amp;quot;version1&amp;quot;}, {&amp;quot;text&amp;quot;: &amp;quot;version2&amp;quot;}]}\\n2. Each version must:\\n   - Target exactly the specified percentage\\n   - Use different sentence structures\\n   - Vary word choices while keeping technical terms\\n   - Maintain the same meaning\\n3. If task cannot be completed: {&amp;quot;error&amp;quot;: &amp;quot;specific reason&amp;quot;}&amp;#x27;}, {&amp;#x27;role&amp;#x27;: &amp;#x27;user&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate 3 UNIQUE versions at 50% length:\\n        - Each must be exactly the same length\\n        - Use different phrasings\\n        Original length: 35 tokens\\n        Original text: The Text Transformation API offers a robust set of REST endpoints that enable developers to programmatically manipulate and transform text content. The operations include expansion, summarization, and chunking.&amp;#x27;}], &amp;#x27;model&amp;#x27;: &amp;#x27;llama3-groq-70b-8192-tool-use-preview&amp;#x27;, &amp;#x27;max_tokens&amp;#x27;: 1000, &amp;#x27;temperature&amp;#x27;: 0.7}}\nDEBUG    httpcore.http11:_trace.py:45 send_request_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 send_request_headers.complete\nDEBUG    httpcore.http11:_trace.py:45 send_request_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 send_request_body.complete\nDEBUG    httpcore.http11:_trace.py:45 receive_response_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 receive_response_headers.complete return_value=(b&amp;#x27;HTTP/1.1&amp;#x27;, 200, b&amp;#x27;OK&amp;#x27;, [(b&amp;#x27;Date&amp;#x27;, b&amp;#x27;Wed, 30 Oct 2024 15:53:26 GMT&amp;#x27;), (b&amp;#x27;Content-Type&amp;#x27;, b&amp;#x27;application/json&amp;#x27;), (b&amp;#x27;Transfer-Encoding&amp;#x27;, b&amp;#x27;chunked&amp;#x27;), (b&amp;#x27;Connection&amp;#x27;, b&amp;#x27;keep-alive&amp;#x27;), (b&amp;#x27;Cache-Control&amp;#x27;, b&amp;#x27;private, max-age=0, no-store, no-cache, must-revalidate&amp;#x27;), (b&amp;#x27;vary&amp;#x27;, b&amp;#x27;Origin&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-requests&amp;#x27;, b&amp;#x27;14400&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-tokens&amp;#x27;, b&amp;#x27;15000&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-requests&amp;#x27;, b&amp;#x27;14386&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-tokens&amp;#x27;, b&amp;#x27;14790&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-requests&amp;#x27;, b&amp;#x27;1m23.077999999s&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-tokens&amp;#x27;, b&amp;#x27;840ms&amp;#x27;), (b&amp;#x27;x-request-id&amp;#x27;, b&amp;#x27;req_01jbf23f1xe6db7d9xmbpc78ty&amp;#x27;), (b&amp;#x27;via&amp;#x27;, b&amp;#x27;1.1 google&amp;#x27;), (b&amp;#x27;alt-svc&amp;#x27;, b&amp;#x27;h3=&amp;quot;:443&amp;quot;; ma=86400&amp;#x27;), (b&amp;#x27;CF-Cache-Status&amp;#x27;, b&amp;#x27;DYNAMIC&amp;#x27;), (b&amp;#x27;Server&amp;#x27;, b&amp;#x27;cloudflare&amp;#x27;), (b&amp;#x27;CF-RAY&amp;#x27;, b&amp;#x27;8dac93ffca1bca58-HAM&amp;#x27;), (b&amp;#x27;Content-Encoding&amp;#x27;, b&amp;#x27;gzip&amp;#x27;)])\nINFO     httpx:_client.py:1038 HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;HTTP/1.1 200 OK&amp;quot;\nDEBUG    httpcore.http11:_trace.py:45 receive_response_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 receive_response_body.complete\nDEBUG    httpcore.http11:_trace.py:45 response_closed.started\nDEBUG    httpcore.http11:_trace.py:45 response_closed.complete\nDEBUG    groq._base_client:_base_client.py:956 HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;200 OK&amp;quot;\n\n&#34;}], &#34;tests/performance/test_compress_performance.py::TestCompressPerformance::test_staggered_with_steps&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/performance/test_compress_performance.py::TestCompressPerformance::test_staggered_with_steps&#34;, &#34;duration&#34;: &#34;00:00:01&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/performance/test_compress_performance.py::TestCompressPerformance::test_staggered_with_steps&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:01&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;---------------------------- Captured stderr setup -----------------------------\nDEBUG:app:Registering blueprints...\nDEBUG:app:Registered routes:\nDEBUG:app:static: /static/&amp;lt;path:filename&amp;gt; [GET, OPTIONS, HEAD]\nDEBUG:app:generate.create_text: /text/v1/generate/text [OPTIONS, POST]\nDEBUG:app:compress.compress_text: /text/v1/compress/ [OPTIONS, POST]\nDEBUG:app:expand.expand_text: /text/v1/expand/ [OPTIONS, POST]\n\n------------------------------ Captured log setup ------------------------------\nDEBUG    app:__init__.py:106 Registering blueprints...\nDEBUG    app:__init__.py:112 Registered routes:\nDEBUG    app:__init__.py:114 static: /static/&amp;lt;path:filename&amp;gt; [GET, OPTIONS, HEAD]\nDEBUG    app:__init__.py:114 generate.create_text: /text/v1/generate/text [OPTIONS, POST]\nDEBUG    app:__init__.py:114 compress.compress_text: /text/v1/compress/ [OPTIONS, POST]\nDEBUG    app:__init__.py:114 expand.expand_text: /text/v1/expand/ [OPTIONS, POST]\n\n----------------------------- Captured stderr call -----------------------------\nDEBUG:app:Headers: {&amp;#x27;User-Agent&amp;#x27;: &amp;#x27;Werkzeug/3.0.6&amp;#x27;, &amp;#x27;Host&amp;#x27;: &amp;#x27;localhost&amp;#x27;, &amp;#x27;Content-Type&amp;#x27;: &amp;#x27;application/json&amp;#x27;, &amp;#x27;Content-Length&amp;#x27;: &amp;#x27;274&amp;#x27;, &amp;#x27;Authorization&amp;#x27;: &amp;#x27;Bearer test_key&amp;#x27;}\nDEBUG:app:Body: b&amp;#x27;{&amp;quot;content&amp;quot;: &amp;quot;The Text Transformation API offers a robust set of REST endpoints that enable developers to programmatically manipulate and transform text content. The operations include expansion, summarization, and chunking.&amp;quot;, &amp;quot;steps_percentage&amp;quot;: 10, &amp;quot;target_percentage&amp;quot;: 40}&amp;#x27;\nDEBUG:app:Query Params: {}\nDEBUG:app:Route: POST /text/v1/compress/\nDEBUG:groq._base_client:Request options: {&amp;#x27;method&amp;#x27;: &amp;#x27;post&amp;#x27;, &amp;#x27;url&amp;#x27;: &amp;#x27;/openai/v1/chat/completions&amp;#x27;, &amp;#x27;files&amp;#x27;: None, &amp;#x27;json_data&amp;#x27;: {&amp;#x27;messages&amp;#x27;: [{&amp;#x27;role&amp;#x27;: &amp;#x27;system&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate a JSON response following these rules:\\n1. Return multiple versions with DECREASING length:\\n   {&amp;quot;versions&amp;quot;: [{&amp;quot;text&amp;quot;: &amp;quot;longest&amp;quot;}, {&amp;quot;text&amp;quot;: &amp;quot;shorter&amp;quot;}, {&amp;quot;text&amp;quot;: &amp;quot;shortest&amp;quot;}]}\\n2. Each version must:\\n   - Match its target percentage exactly\\n   - Remove less important information gradually\\n   - Keep core technical terms\\n   - Maintain readability\\n3. Sort versions from longest to shortest\\n4. If task cannot be completed: {&amp;quot;error&amp;quot;: &amp;quot;specific reason&amp;quot;}&amp;#x27;}, {&amp;#x27;role&amp;#x27;: &amp;#x27;user&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate 5 versions with decreasing length:\\n        Target percentages: 100%, 85%, 70%, 55%, 40%\\n        Original length: 35 tokens\\n        Original text: The Text Transformation API offers a robust set of REST endpoints that enable developers to programmatically manipulate and transform text content. The operations include expansion, summarization, and chunking.&amp;#x27;}], &amp;#x27;model&amp;#x27;: &amp;#x27;llama3-groq-70b-8192-tool-use-preview&amp;#x27;, &amp;#x27;max_tokens&amp;#x27;: 1000, &amp;#x27;temperature&amp;#x27;: 0.7}}\nDEBUG:httpcore.http11:send_request_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.http11:send_request_headers.complete\nDEBUG:httpcore.http11:send_request_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.http11:send_request_body.complete\nDEBUG:httpcore.http11:receive_response_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.http11:receive_response_headers.complete return_value=(b&amp;#x27;HTTP/1.1&amp;#x27;, 200, b&amp;#x27;OK&amp;#x27;, [(b&amp;#x27;Date&amp;#x27;, b&amp;#x27;Wed, 30 Oct 2024 15:53:27 GMT&amp;#x27;), (b&amp;#x27;Content-Type&amp;#x27;, b&amp;#x27;application/json&amp;#x27;), (b&amp;#x27;Transfer-Encoding&amp;#x27;, b&amp;#x27;chunked&amp;#x27;), (b&amp;#x27;Connection&amp;#x27;, b&amp;#x27;keep-alive&amp;#x27;), (b&amp;#x27;Cache-Control&amp;#x27;, b&amp;#x27;private, max-age=0, no-store, no-cache, must-revalidate&amp;#x27;), (b&amp;#x27;vary&amp;#x27;, b&amp;#x27;Origin&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-requests&amp;#x27;, b&amp;#x27;14400&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-tokens&amp;#x27;, b&amp;#x27;15000&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-requests&amp;#x27;, b&amp;#x27;14385&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-tokens&amp;#x27;, b&amp;#x27;14685&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-requests&amp;#x27;, b&amp;#x27;1m28.751999999s&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-tokens&amp;#x27;, b&amp;#x27;1.259s&amp;#x27;), (b&amp;#x27;x-request-id&amp;#x27;, b&amp;#x27;req_01jbf23g8xej8r2hj4ef2cq1k6&amp;#x27;), (b&amp;#x27;via&amp;#x27;, b&amp;#x27;1.1 google&amp;#x27;), (b&amp;#x27;alt-svc&amp;#x27;, b&amp;#x27;h3=&amp;quot;:443&amp;quot;; ma=86400&amp;#x27;), (b&amp;#x27;CF-Cache-Status&amp;#x27;, b&amp;#x27;DYNAMIC&amp;#x27;), (b&amp;#x27;Server&amp;#x27;, b&amp;#x27;cloudflare&amp;#x27;), (b&amp;#x27;CF-RAY&amp;#x27;, b&amp;#x27;8dac94079ba4ca58-HAM&amp;#x27;), (b&amp;#x27;Content-Encoding&amp;#x27;, b&amp;#x27;gzip&amp;#x27;)])\nINFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;HTTP/1.1 200 OK&amp;quot;\nDEBUG:httpcore.http11:receive_response_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.http11:receive_response_body.complete\nDEBUG:httpcore.http11:response_closed.started\nDEBUG:httpcore.http11:response_closed.complete\nDEBUG:groq._base_client:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;200 OK&amp;quot;\n\n------------------------------ Captured log call -------------------------------\nDEBUG    app:__init__.py:31 Headers: {&amp;#x27;User-Agent&amp;#x27;: &amp;#x27;Werkzeug/3.0.6&amp;#x27;, &amp;#x27;Host&amp;#x27;: &amp;#x27;localhost&amp;#x27;, &amp;#x27;Content-Type&amp;#x27;: &amp;#x27;application/json&amp;#x27;, &amp;#x27;Content-Length&amp;#x27;: &amp;#x27;274&amp;#x27;, &amp;#x27;Authorization&amp;#x27;: &amp;#x27;Bearer test_key&amp;#x27;}\nDEBUG    app:__init__.py:32 Body: b&amp;#x27;{&amp;quot;content&amp;quot;: &amp;quot;The Text Transformation API offers a robust set of REST endpoints that enable developers to programmatically manipulate and transform text content. The operations include expansion, summarization, and chunking.&amp;quot;, &amp;quot;steps_percentage&amp;quot;: 10, &amp;quot;target_percentage&amp;quot;: 40}&amp;#x27;\nDEBUG    app:__init__.py:33 Query Params: {}\nDEBUG    app:__init__.py:34 Route: POST /text/v1/compress/\nDEBUG    groq._base_client:_base_client.py:441 Request options: {&amp;#x27;method&amp;#x27;: &amp;#x27;post&amp;#x27;, &amp;#x27;url&amp;#x27;: &amp;#x27;/openai/v1/chat/completions&amp;#x27;, &amp;#x27;files&amp;#x27;: None, &amp;#x27;json_data&amp;#x27;: {&amp;#x27;messages&amp;#x27;: [{&amp;#x27;role&amp;#x27;: &amp;#x27;system&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate a JSON response following these rules:\\n1. Return multiple versions with DECREASING length:\\n   {&amp;quot;versions&amp;quot;: [{&amp;quot;text&amp;quot;: &amp;quot;longest&amp;quot;}, {&amp;quot;text&amp;quot;: &amp;quot;shorter&amp;quot;}, {&amp;quot;text&amp;quot;: &amp;quot;shortest&amp;quot;}]}\\n2. Each version must:\\n   - Match its target percentage exactly\\n   - Remove less important information gradually\\n   - Keep core technical terms\\n   - Maintain readability\\n3. Sort versions from longest to shortest\\n4. If task cannot be completed: {&amp;quot;error&amp;quot;: &amp;quot;specific reason&amp;quot;}&amp;#x27;}, {&amp;#x27;role&amp;#x27;: &amp;#x27;user&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate 5 versions with decreasing length:\\n        Target percentages: 100%, 85%, 70%, 55%, 40%\\n        Original length: 35 tokens\\n        Original text: The Text Transformation API offers a robust set of REST endpoints that enable developers to programmatically manipulate and transform text content. The operations include expansion, summarization, and chunking.&amp;#x27;}], &amp;#x27;model&amp;#x27;: &amp;#x27;llama3-groq-70b-8192-tool-use-preview&amp;#x27;, &amp;#x27;max_tokens&amp;#x27;: 1000, &amp;#x27;temperature&amp;#x27;: 0.7}}\nDEBUG    httpcore.http11:_trace.py:45 send_request_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 send_request_headers.complete\nDEBUG    httpcore.http11:_trace.py:45 send_request_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 send_request_body.complete\nDEBUG    httpcore.http11:_trace.py:45 receive_response_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 receive_response_headers.complete return_value=(b&amp;#x27;HTTP/1.1&amp;#x27;, 200, b&amp;#x27;OK&amp;#x27;, [(b&amp;#x27;Date&amp;#x27;, b&amp;#x27;Wed, 30 Oct 2024 15:53:27 GMT&amp;#x27;), (b&amp;#x27;Content-Type&amp;#x27;, b&amp;#x27;application/json&amp;#x27;), (b&amp;#x27;Transfer-Encoding&amp;#x27;, b&amp;#x27;chunked&amp;#x27;), (b&amp;#x27;Connection&amp;#x27;, b&amp;#x27;keep-alive&amp;#x27;), (b&amp;#x27;Cache-Control&amp;#x27;, b&amp;#x27;private, max-age=0, no-store, no-cache, must-revalidate&amp;#x27;), (b&amp;#x27;vary&amp;#x27;, b&amp;#x27;Origin&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-requests&amp;#x27;, b&amp;#x27;14400&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-tokens&amp;#x27;, b&amp;#x27;15000&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-requests&amp;#x27;, b&amp;#x27;14385&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-tokens&amp;#x27;, b&amp;#x27;14685&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-requests&amp;#x27;, b&amp;#x27;1m28.751999999s&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-tokens&amp;#x27;, b&amp;#x27;1.259s&amp;#x27;), (b&amp;#x27;x-request-id&amp;#x27;, b&amp;#x27;req_01jbf23g8xej8r2hj4ef2cq1k6&amp;#x27;), (b&amp;#x27;via&amp;#x27;, b&amp;#x27;1.1 google&amp;#x27;), (b&amp;#x27;alt-svc&amp;#x27;, b&amp;#x27;h3=&amp;quot;:443&amp;quot;; ma=86400&amp;#x27;), (b&amp;#x27;CF-Cache-Status&amp;#x27;, b&amp;#x27;DYNAMIC&amp;#x27;), (b&amp;#x27;Server&amp;#x27;, b&amp;#x27;cloudflare&amp;#x27;), (b&amp;#x27;CF-RAY&amp;#x27;, b&amp;#x27;8dac94079ba4ca58-HAM&amp;#x27;), (b&amp;#x27;Content-Encoding&amp;#x27;, b&amp;#x27;gzip&amp;#x27;)])\nINFO     httpx:_client.py:1038 HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;HTTP/1.1 200 OK&amp;quot;\nDEBUG    httpcore.http11:_trace.py:45 receive_response_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 receive_response_body.complete\nDEBUG    httpcore.http11:_trace.py:45 response_closed.started\nDEBUG    httpcore.http11:_trace.py:45 response_closed.complete\nDEBUG    groq._base_client:_base_client.py:956 HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;200 OK&amp;quot;\n\n&#34;}], &#34;tests/performance/test_compress_performance.py::TestCompressPerformance::test_staggered_custom_range&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Failed&#34;, &#34;testId&#34;: &#34;tests/performance/test_compress_performance.py::TestCompressPerformance::test_staggered_custom_range&#34;, &#34;duration&#34;: &#34;00:00:01&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Failed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/performance/test_compress_performance.py::TestCompressPerformance::test_staggered_custom_range&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:01&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;self = &amp;lt;tests.performance.test_compress_performance.TestCompressPerformance object at 0x1069d0260&amp;gt;\nclient = &amp;lt;FlaskClient &amp;lt;Flask &amp;#x27;app&amp;#x27;&amp;gt;&amp;gt;\nauth_headers = {&amp;#x27;Authorization&amp;#x27;: &amp;#x27;Bearer test_key&amp;#x27;, &amp;#x27;Content-Type&amp;#x27;: &amp;#x27;application/json&amp;#x27;}\n\n    @pytest.mark.unit\n    def test_staggered_custom_range(self, client, auth_headers):\n        response = client.post(self.ENDPOINTS[&amp;#x27;compress&amp;#x27;], json={\n            &amp;#x27;content&amp;#x27;: self.SAMPLE_TEXT,\n            &amp;#x27;start_percentage&amp;#x27;: 60,\n            &amp;#x27;target_percentage&amp;#x27;: 40,\n            &amp;#x27;versions&amp;#x27;: 5\n        }, headers=auth_headers)\n    \n        data = response.json\n        percentages = data[&amp;#x27;metadata&amp;#x27;][&amp;#x27;target_percentages&amp;#x27;]\n&amp;gt;       assert percentages == [60, 55, 50, 45, 40]\nE       AssertionError: assert [40, 40, 40, 40, 40] == [60, 55, 50, 45, 40]\nE         \nE         At index 0 diff: 40 != 60\nE         \nE         Full diff:\nE           [\nE         -     60,\nE         ?     ^...\nE         \nE         ...Full output truncated (14 lines hidden), use &amp;#x27;-vv&amp;#x27; to show\n\ntests/test_compress.py:101: AssertionError\n\n---------------------------- Captured stderr setup -----------------------------\nDEBUG:app:Registering blueprints...\nDEBUG:app:Registered routes:\nDEBUG:app:static: /static/&amp;lt;path:filename&amp;gt; [GET, OPTIONS, HEAD]\nDEBUG:app:generate.create_text: /text/v1/generate/text [OPTIONS, POST]\nDEBUG:app:compress.compress_text: /text/v1/compress/ [OPTIONS, POST]\nDEBUG:app:expand.expand_text: /text/v1/expand/ [OPTIONS, POST]\n\n------------------------------ Captured log setup ------------------------------\nDEBUG    app:__init__.py:106 Registering blueprints...\nDEBUG    app:__init__.py:112 Registered routes:\nDEBUG    app:__init__.py:114 static: /static/&amp;lt;path:filename&amp;gt; [GET, OPTIONS, HEAD]\nDEBUG    app:__init__.py:114 generate.create_text: /text/v1/generate/text [OPTIONS, POST]\nDEBUG    app:__init__.py:114 compress.compress_text: /text/v1/compress/ [OPTIONS, POST]\nDEBUG    app:__init__.py:114 expand.expand_text: /text/v1/expand/ [OPTIONS, POST]\n\n----------------------------- Captured stderr call -----------------------------\nDEBUG:app:Headers: {&amp;#x27;User-Agent&amp;#x27;: &amp;#x27;Werkzeug/3.0.6&amp;#x27;, &amp;#x27;Host&amp;#x27;: &amp;#x27;localhost&amp;#x27;, &amp;#x27;Content-Type&amp;#x27;: &amp;#x27;application/json&amp;#x27;, &amp;#x27;Content-Length&amp;#x27;: &amp;#x27;289&amp;#x27;, &amp;#x27;Authorization&amp;#x27;: &amp;#x27;Bearer test_key&amp;#x27;}\nDEBUG:app:Body: b&amp;#x27;{&amp;quot;content&amp;quot;: &amp;quot;The Text Transformation API offers a robust set of REST endpoints that enable developers to programmatically manipulate and transform text content. The operations include expansion, summarization, and chunking.&amp;quot;, &amp;quot;start_percentage&amp;quot;: 60, &amp;quot;target_percentage&amp;quot;: 40, &amp;quot;versions&amp;quot;: 5}&amp;#x27;\nDEBUG:app:Query Params: {}\nDEBUG:app:Route: POST /text/v1/compress/\nDEBUG:groq._base_client:Request options: {&amp;#x27;method&amp;#x27;: &amp;#x27;post&amp;#x27;, &amp;#x27;url&amp;#x27;: &amp;#x27;/openai/v1/chat/completions&amp;#x27;, &amp;#x27;files&amp;#x27;: None, &amp;#x27;json_data&amp;#x27;: {&amp;#x27;messages&amp;#x27;: [{&amp;#x27;role&amp;#x27;: &amp;#x27;system&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate a JSON response following these rules:\\n1. Return multiple UNIQUE versions at the SAME length:\\n   {&amp;quot;versions&amp;quot;: [{&amp;quot;text&amp;quot;: &amp;quot;version1&amp;quot;}, {&amp;quot;text&amp;quot;: &amp;quot;version2&amp;quot;}]}\\n2. Each version must:\\n   - Target exactly the specified percentage\\n   - Use different sentence structures\\n   - Vary word choices while keeping technical terms\\n   - Maintain the same meaning\\n3. If task cannot be completed: {&amp;quot;error&amp;quot;: &amp;quot;specific reason&amp;quot;}&amp;#x27;}, {&amp;#x27;role&amp;#x27;: &amp;#x27;user&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate 5 UNIQUE versions at 40% length:\\n        - Each must be exactly the same length\\n        - Use different phrasings\\n        Original length: 35 tokens\\n        Original text: The Text Transformation API offers a robust set of REST endpoints that enable developers to programmatically manipulate and transform text content. The operations include expansion, summarization, and chunking.&amp;#x27;}], &amp;#x27;model&amp;#x27;: &amp;#x27;llama3-groq-70b-8192-tool-use-preview&amp;#x27;, &amp;#x27;max_tokens&amp;#x27;: 1000, &amp;#x27;temperature&amp;#x27;: 0.7}}\nDEBUG:httpcore.http11:send_request_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.http11:send_request_headers.complete\nDEBUG:httpcore.http11:send_request_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.http11:send_request_body.complete\nDEBUG:httpcore.http11:receive_response_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.http11:receive_response_headers.complete return_value=(b&amp;#x27;HTTP/1.1&amp;#x27;, 200, b&amp;#x27;OK&amp;#x27;, [(b&amp;#x27;Date&amp;#x27;, b&amp;#x27;Wed, 30 Oct 2024 15:53:29 GMT&amp;#x27;), (b&amp;#x27;Content-Type&amp;#x27;, b&amp;#x27;application/json&amp;#x27;), (b&amp;#x27;Transfer-Encoding&amp;#x27;, b&amp;#x27;chunked&amp;#x27;), (b&amp;#x27;Connection&amp;#x27;, b&amp;#x27;keep-alive&amp;#x27;), (b&amp;#x27;Cache-Control&amp;#x27;, b&amp;#x27;private, max-age=0, no-store, no-cache, must-revalidate&amp;#x27;), (b&amp;#x27;vary&amp;#x27;, b&amp;#x27;Origin&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-requests&amp;#x27;, b&amp;#x27;14400&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-tokens&amp;#x27;, b&amp;#x27;15000&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-requests&amp;#x27;, b&amp;#x27;14384&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-tokens&amp;#x27;, b&amp;#x27;14599&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-requests&amp;#x27;, b&amp;#x27;1m34.667s&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-tokens&amp;#x27;, b&amp;#x27;1.602s&amp;#x27;), (b&amp;#x27;x-request-id&amp;#x27;, b&amp;#x27;req_01jbf23hjkfknsk26dwdpq72v6&amp;#x27;), (b&amp;#x27;via&amp;#x27;, b&amp;#x27;1.1 google&amp;#x27;), (b&amp;#x27;alt-svc&amp;#x27;, b&amp;#x27;h3=&amp;quot;:443&amp;quot;; ma=86400&amp;#x27;), (b&amp;#x27;CF-Cache-Status&amp;#x27;, b&amp;#x27;DYNAMIC&amp;#x27;), (b&amp;#x27;Server&amp;#x27;, b&amp;#x27;cloudflare&amp;#x27;), (b&amp;#x27;CF-RAY&amp;#x27;, b&amp;#x27;8dac940ffdbeca58-HAM&amp;#x27;), (b&amp;#x27;Content-Encoding&amp;#x27;, b&amp;#x27;gzip&amp;#x27;)])\nINFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;HTTP/1.1 200 OK&amp;quot;\nDEBUG:httpcore.http11:receive_response_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.http11:receive_response_body.complete\nDEBUG:httpcore.http11:response_closed.started\nDEBUG:httpcore.http11:response_closed.complete\nDEBUG:groq._base_client:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;200 OK&amp;quot;\n\n------------------------------ Captured log call -------------------------------\nDEBUG    app:__init__.py:31 Headers: {&amp;#x27;User-Agent&amp;#x27;: &amp;#x27;Werkzeug/3.0.6&amp;#x27;, &amp;#x27;Host&amp;#x27;: &amp;#x27;localhost&amp;#x27;, &amp;#x27;Content-Type&amp;#x27;: &amp;#x27;application/json&amp;#x27;, &amp;#x27;Content-Length&amp;#x27;: &amp;#x27;289&amp;#x27;, &amp;#x27;Authorization&amp;#x27;: &amp;#x27;Bearer test_key&amp;#x27;}\nDEBUG    app:__init__.py:32 Body: b&amp;#x27;{&amp;quot;content&amp;quot;: &amp;quot;The Text Transformation API offers a robust set of REST endpoints that enable developers to programmatically manipulate and transform text content. The operations include expansion, summarization, and chunking.&amp;quot;, &amp;quot;start_percentage&amp;quot;: 60, &amp;quot;target_percentage&amp;quot;: 40, &amp;quot;versions&amp;quot;: 5}&amp;#x27;\nDEBUG    app:__init__.py:33 Query Params: {}\nDEBUG    app:__init__.py:34 Route: POST /text/v1/compress/\nDEBUG    groq._base_client:_base_client.py:441 Request options: {&amp;#x27;method&amp;#x27;: &amp;#x27;post&amp;#x27;, &amp;#x27;url&amp;#x27;: &amp;#x27;/openai/v1/chat/completions&amp;#x27;, &amp;#x27;files&amp;#x27;: None, &amp;#x27;json_data&amp;#x27;: {&amp;#x27;messages&amp;#x27;: [{&amp;#x27;role&amp;#x27;: &amp;#x27;system&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate a JSON response following these rules:\\n1. Return multiple UNIQUE versions at the SAME length:\\n   {&amp;quot;versions&amp;quot;: [{&amp;quot;text&amp;quot;: &amp;quot;version1&amp;quot;}, {&amp;quot;text&amp;quot;: &amp;quot;version2&amp;quot;}]}\\n2. Each version must:\\n   - Target exactly the specified percentage\\n   - Use different sentence structures\\n   - Vary word choices while keeping technical terms\\n   - Maintain the same meaning\\n3. If task cannot be completed: {&amp;quot;error&amp;quot;: &amp;quot;specific reason&amp;quot;}&amp;#x27;}, {&amp;#x27;role&amp;#x27;: &amp;#x27;user&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate 5 UNIQUE versions at 40% length:\\n        - Each must be exactly the same length\\n        - Use different phrasings\\n        Original length: 35 tokens\\n        Original text: The Text Transformation API offers a robust set of REST endpoints that enable developers to programmatically manipulate and transform text content. The operations include expansion, summarization, and chunking.&amp;#x27;}], &amp;#x27;model&amp;#x27;: &amp;#x27;llama3-groq-70b-8192-tool-use-preview&amp;#x27;, &amp;#x27;max_tokens&amp;#x27;: 1000, &amp;#x27;temperature&amp;#x27;: 0.7}}\nDEBUG    httpcore.http11:_trace.py:45 send_request_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 send_request_headers.complete\nDEBUG    httpcore.http11:_trace.py:45 send_request_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 send_request_body.complete\nDEBUG    httpcore.http11:_trace.py:45 receive_response_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 receive_response_headers.complete return_value=(b&amp;#x27;HTTP/1.1&amp;#x27;, 200, b&amp;#x27;OK&amp;#x27;, [(b&amp;#x27;Date&amp;#x27;, b&amp;#x27;Wed, 30 Oct 2024 15:53:29 GMT&amp;#x27;), (b&amp;#x27;Content-Type&amp;#x27;, b&amp;#x27;application/json&amp;#x27;), (b&amp;#x27;Transfer-Encoding&amp;#x27;, b&amp;#x27;chunked&amp;#x27;), (b&amp;#x27;Connection&amp;#x27;, b&amp;#x27;keep-alive&amp;#x27;), (b&amp;#x27;Cache-Control&amp;#x27;, b&amp;#x27;private, max-age=0, no-store, no-cache, must-revalidate&amp;#x27;), (b&amp;#x27;vary&amp;#x27;, b&amp;#x27;Origin&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-requests&amp;#x27;, b&amp;#x27;14400&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-tokens&amp;#x27;, b&amp;#x27;15000&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-requests&amp;#x27;, b&amp;#x27;14384&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-tokens&amp;#x27;, b&amp;#x27;14599&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-requests&amp;#x27;, b&amp;#x27;1m34.667s&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-tokens&amp;#x27;, b&amp;#x27;1.602s&amp;#x27;), (b&amp;#x27;x-request-id&amp;#x27;, b&amp;#x27;req_01jbf23hjkfknsk26dwdpq72v6&amp;#x27;), (b&amp;#x27;via&amp;#x27;, b&amp;#x27;1.1 google&amp;#x27;), (b&amp;#x27;alt-svc&amp;#x27;, b&amp;#x27;h3=&amp;quot;:443&amp;quot;; ma=86400&amp;#x27;), (b&amp;#x27;CF-Cache-Status&amp;#x27;, b&amp;#x27;DYNAMIC&amp;#x27;), (b&amp;#x27;Server&amp;#x27;, b&amp;#x27;cloudflare&amp;#x27;), (b&amp;#x27;CF-RAY&amp;#x27;, b&amp;#x27;8dac940ffdbeca58-HAM&amp;#x27;), (b&amp;#x27;Content-Encoding&amp;#x27;, b&amp;#x27;gzip&amp;#x27;)])\nINFO     httpx:_client.py:1038 HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;HTTP/1.1 200 OK&amp;quot;\nDEBUG    httpcore.http11:_trace.py:45 receive_response_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 receive_response_body.complete\nDEBUG    httpcore.http11:_trace.py:45 response_closed.started\nDEBUG    httpcore.http11:_trace.py:45 response_closed.complete\nDEBUG    groq._base_client:_base_client.py:956 HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;200 OK&amp;quot;\n\n&#34;}], &#34;tests/performance/test_compress_performance.py::TestCompressPerformance::test_array_input&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Failed&#34;, &#34;testId&#34;: &#34;tests/performance/test_compress_performance.py::TestCompressPerformance::test_array_input&#34;, &#34;duration&#34;: &#34;00:00:03&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Failed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/performance/test_compress_performance.py::TestCompressPerformance::test_array_input&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:03&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;self = &amp;lt;tests.performance.test_compress_performance.TestCompressPerformance object at 0x1069d0350&amp;gt;\nclient = &amp;lt;FlaskClient &amp;lt;Flask &amp;#x27;app&amp;#x27;&amp;gt;&amp;gt;\nauth_headers = {&amp;#x27;Authorization&amp;#x27;: &amp;#x27;Bearer test_key&amp;#x27;, &amp;#x27;Content-Type&amp;#x27;: &amp;#x27;application/json&amp;#x27;}\n\n    @pytest.mark.unit\n    def test_array_input(self, client, auth_headers):\n        response = client.post(self.ENDPOINTS[&amp;#x27;compress&amp;#x27;], json={\n            &amp;#x27;content&amp;#x27;: [\n                &amp;quot;The Text Transformation API offers REST endpoints&amp;quot;,\n                &amp;quot;These endpoints enable text manipulation&amp;quot;,\n                &amp;quot;Operations include various transformations&amp;quot;\n            ],\n            &amp;#x27;target_percentage&amp;#x27;: 50,\n            &amp;#x27;versions&amp;#x27;: 2\n        }, headers=auth_headers)\n    \n        data = response.json\n        assert data[&amp;#x27;type&amp;#x27;] == &amp;#x27;fragments&amp;#x27;\n        assert len(data[&amp;#x27;fragments&amp;#x27;]) == 3\n    \n        for fragment in data[&amp;#x27;fragments&amp;#x27;]:\n            assert len(fragment[&amp;#x27;versions&amp;#x27;]) == 2\n            for version in fragment[&amp;#x27;versions&amp;#x27;]:\n                assert &amp;#x27;text&amp;#x27; in version\n                assert &amp;#x27;final_percentage&amp;#x27; in version\n                assert isinstance(version[&amp;#x27;final_percentage&amp;#x27;], float)\n                # Check if compression is roughly within target\n&amp;gt;               assert abs(version[&amp;#x27;final_percentage&amp;#x27;] - 50) &amp;lt;= 10\nE               assert 54.099999999999994 &amp;lt;= 10\nE                +  where 54.099999999999994 = abs((104.1 - 50))\n\ntests/test_compress.py:126: AssertionError\n\n---------------------------- Captured stderr setup -----------------------------\nDEBUG:app:Registering blueprints...\nDEBUG:app:Registered routes:\nDEBUG:app:static: /static/&amp;lt;path:filename&amp;gt; [GET, OPTIONS, HEAD]\nDEBUG:app:generate.create_text: /text/v1/generate/text [OPTIONS, POST]\nDEBUG:app:compress.compress_text: /text/v1/compress/ [OPTIONS, POST]\nDEBUG:app:expand.expand_text: /text/v1/expand/ [OPTIONS, POST]\n\n------------------------------ Captured log setup ------------------------------\nDEBUG    app:__init__.py:106 Registering blueprints...\nDEBUG    app:__init__.py:112 Registered routes:\nDEBUG    app:__init__.py:114 static: /static/&amp;lt;path:filename&amp;gt; [GET, OPTIONS, HEAD]\nDEBUG    app:__init__.py:114 generate.create_text: /text/v1/generate/text [OPTIONS, POST]\nDEBUG    app:__init__.py:114 compress.compress_text: /text/v1/compress/ [OPTIONS, POST]\nDEBUG    app:__init__.py:114 expand.expand_text: /text/v1/expand/ [OPTIONS, POST]\n\n----------------------------- Captured stderr call -----------------------------\nDEBUG:app:Headers: {&amp;#x27;User-Agent&amp;#x27;: &amp;#x27;Werkzeug/3.0.6&amp;#x27;, &amp;#x27;Host&amp;#x27;: &amp;#x27;localhost&amp;#x27;, &amp;#x27;Content-Type&amp;#x27;: &amp;#x27;application/json&amp;#x27;, &amp;#x27;Content-Length&amp;#x27;: &amp;#x27;196&amp;#x27;, &amp;#x27;Authorization&amp;#x27;: &amp;#x27;Bearer test_key&amp;#x27;}\nDEBUG:app:Body: b&amp;#x27;{&amp;quot;content&amp;quot;: [&amp;quot;The Text Transformation API offers REST endpoints&amp;quot;, &amp;quot;These endpoints enable text manipulation&amp;quot;, &amp;quot;Operations include various transformations&amp;quot;], &amp;quot;target_percentage&amp;quot;: 50, &amp;quot;versions&amp;quot;: 2}&amp;#x27;\nDEBUG:app:Query Params: {}\nDEBUG:app:Route: POST /text/v1/compress/\nDEBUG:groq._base_client:Request options: {&amp;#x27;method&amp;#x27;: &amp;#x27;post&amp;#x27;, &amp;#x27;url&amp;#x27;: &amp;#x27;/openai/v1/chat/completions&amp;#x27;, &amp;#x27;files&amp;#x27;: None, &amp;#x27;json_data&amp;#x27;: {&amp;#x27;messages&amp;#x27;: [{&amp;#x27;role&amp;#x27;: &amp;#x27;system&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate a JSON response following these rules:\\n1. Return multiple UNIQUE versions at the SAME length:\\n   {&amp;quot;versions&amp;quot;: [{&amp;quot;text&amp;quot;: &amp;quot;version1&amp;quot;}, {&amp;quot;text&amp;quot;: &amp;quot;version2&amp;quot;}]}\\n2. Each version must:\\n   - Target exactly the specified percentage\\n   - Use different sentence structures\\n   - Vary word choices while keeping technical terms\\n   - Maintain the same meaning\\n3. If task cannot be completed: {&amp;quot;error&amp;quot;: &amp;quot;specific reason&amp;quot;}&amp;#x27;}, {&amp;#x27;role&amp;#x27;: &amp;#x27;user&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate 2 UNIQUE versions at 50% length:\\n        - Each must be exactly the same length\\n        - Use different phrasings\\n        Original length: 7 tokens\\n        Original text: The Text Transformation API offers REST endpoints&amp;#x27;}], &amp;#x27;model&amp;#x27;: &amp;#x27;llama3-groq-70b-8192-tool-use-preview&amp;#x27;, &amp;#x27;max_tokens&amp;#x27;: 1000, &amp;#x27;temperature&amp;#x27;: 0.7}}\nDEBUG:httpcore.http11:send_request_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.http11:send_request_headers.complete\nDEBUG:httpcore.http11:send_request_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.http11:send_request_body.complete\nDEBUG:httpcore.http11:receive_response_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.http11:receive_response_headers.complete return_value=(b&amp;#x27;HTTP/1.1&amp;#x27;, 200, b&amp;#x27;OK&amp;#x27;, [(b&amp;#x27;Date&amp;#x27;, b&amp;#x27;Wed, 30 Oct 2024 15:53:31 GMT&amp;#x27;), (b&amp;#x27;Content-Type&amp;#x27;, b&amp;#x27;application/json&amp;#x27;), (b&amp;#x27;Transfer-Encoding&amp;#x27;, b&amp;#x27;chunked&amp;#x27;), (b&amp;#x27;Connection&amp;#x27;, b&amp;#x27;keep-alive&amp;#x27;), (b&amp;#x27;Cache-Control&amp;#x27;, b&amp;#x27;private, max-age=0, no-store, no-cache, must-revalidate&amp;#x27;), (b&amp;#x27;vary&amp;#x27;, b&amp;#x27;Origin&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-requests&amp;#x27;, b&amp;#x27;14400&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-tokens&amp;#x27;, b&amp;#x27;15000&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-requests&amp;#x27;, b&amp;#x27;14383&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-tokens&amp;#x27;, b&amp;#x27;14612&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-requests&amp;#x27;, b&amp;#x27;1m40.562s&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-tokens&amp;#x27;, b&amp;#x27;1.55s&amp;#x27;), (b&amp;#x27;x-request-id&amp;#x27;, b&amp;#x27;req_01jbf23jzjf16swvwn4pxa335n&amp;#x27;), (b&amp;#x27;via&amp;#x27;, b&amp;#x27;1.1 google&amp;#x27;), (b&amp;#x27;alt-svc&amp;#x27;, b&amp;#x27;h3=&amp;quot;:443&amp;quot;; ma=86400&amp;#x27;), (b&amp;#x27;CF-Cache-Status&amp;#x27;, b&amp;#x27;DYNAMIC&amp;#x27;), (b&amp;#x27;Server&amp;#x27;, b&amp;#x27;cloudflare&amp;#x27;), (b&amp;#x27;CF-RAY&amp;#x27;, b&amp;#x27;8dac9418f862ca58-HAM&amp;#x27;), (b&amp;#x27;Content-Encoding&amp;#x27;, b&amp;#x27;gzip&amp;#x27;)])\nINFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;HTTP/1.1 200 OK&amp;quot;\nDEBUG:httpcore.http11:receive_response_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.http11:receive_response_body.complete\nDEBUG:httpcore.http11:response_closed.started\nDEBUG:httpcore.http11:response_closed.complete\nDEBUG:groq._base_client:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;200 OK&amp;quot;\nDEBUG:groq._base_client:Request options: {&amp;#x27;method&amp;#x27;: &amp;#x27;post&amp;#x27;, &amp;#x27;url&amp;#x27;: &amp;#x27;/openai/v1/chat/completions&amp;#x27;, &amp;#x27;files&amp;#x27;: None, &amp;#x27;json_data&amp;#x27;: {&amp;#x27;messages&amp;#x27;: [{&amp;#x27;role&amp;#x27;: &amp;#x27;system&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate a JSON response following these rules:\\n1. Return multiple UNIQUE versions at the SAME length:\\n   {&amp;quot;versions&amp;quot;: [{&amp;quot;text&amp;quot;: &amp;quot;version1&amp;quot;}, {&amp;quot;text&amp;quot;: &amp;quot;version2&amp;quot;}]}\\n2. Each version must:\\n   - Target exactly the specified percentage\\n   - Use different sentence structures\\n   - Vary word choices while keeping technical terms\\n   - Maintain the same meaning\\n3. If task cannot be completed: {&amp;quot;error&amp;quot;: &amp;quot;specific reason&amp;quot;}&amp;#x27;}, {&amp;#x27;role&amp;#x27;: &amp;#x27;user&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate 2 UNIQUE versions at 50% length:\\n        - Each must be exactly the same length\\n        - Use different phrasings\\n        Original length: 5 tokens\\n        Original text: These endpoints enable text manipulation&amp;#x27;}], &amp;#x27;model&amp;#x27;: &amp;#x27;llama3-groq-70b-8192-tool-use-preview&amp;#x27;, &amp;#x27;max_tokens&amp;#x27;: 1000, &amp;#x27;temperature&amp;#x27;: 0.7}}\nDEBUG:httpcore.http11:send_request_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.http11:send_request_headers.complete\nDEBUG:httpcore.http11:send_request_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.http11:send_request_body.complete\nDEBUG:httpcore.http11:receive_response_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.http11:receive_response_headers.complete return_value=(b&amp;#x27;HTTP/1.1&amp;#x27;, 200, b&amp;#x27;OK&amp;#x27;, [(b&amp;#x27;Date&amp;#x27;, b&amp;#x27;Wed, 30 Oct 2024 15:53:31 GMT&amp;#x27;), (b&amp;#x27;Content-Type&amp;#x27;, b&amp;#x27;application/json&amp;#x27;), (b&amp;#x27;Transfer-Encoding&amp;#x27;, b&amp;#x27;chunked&amp;#x27;), (b&amp;#x27;Connection&amp;#x27;, b&amp;#x27;keep-alive&amp;#x27;), (b&amp;#x27;Cache-Control&amp;#x27;, b&amp;#x27;private, max-age=0, no-store, no-cache, must-revalidate&amp;#x27;), (b&amp;#x27;vary&amp;#x27;, b&amp;#x27;Origin&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-requests&amp;#x27;, b&amp;#x27;14400&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-tokens&amp;#x27;, b&amp;#x27;15000&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-requests&amp;#x27;, b&amp;#x27;14382&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-tokens&amp;#x27;, b&amp;#x27;14693&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-requests&amp;#x27;, b&amp;#x27;1m46.457s&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-tokens&amp;#x27;, b&amp;#x27;1.228s&amp;#x27;), (b&amp;#x27;x-request-id&amp;#x27;, b&amp;#x27;req_01jbf23mfvfsms6rnwmn33t5hb&amp;#x27;), (b&amp;#x27;via&amp;#x27;, b&amp;#x27;1.1 google&amp;#x27;), (b&amp;#x27;alt-svc&amp;#x27;, b&amp;#x27;h3=&amp;quot;:443&amp;quot;; ma=86400&amp;#x27;), (b&amp;#x27;CF-Cache-Status&amp;#x27;, b&amp;#x27;DYNAMIC&amp;#x27;), (b&amp;#x27;Server&amp;#x27;, b&amp;#x27;cloudflare&amp;#x27;), (b&amp;#x27;CF-RAY&amp;#x27;, b&amp;#x27;8dac9422ac02ca58-HAM&amp;#x27;), (b&amp;#x27;Content-Encoding&amp;#x27;, b&amp;#x27;gzip&amp;#x27;)])\nINFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;HTTP/1.1 200 OK&amp;quot;\nDEBUG:httpcore.http11:receive_response_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.http11:receive_response_body.complete\nDEBUG:httpcore.http11:response_closed.started\nDEBUG:httpcore.http11:response_closed.complete\nDEBUG:groq._base_client:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;200 OK&amp;quot;\nDEBUG:groq._base_client:Request options: {&amp;#x27;method&amp;#x27;: &amp;#x27;post&amp;#x27;, &amp;#x27;url&amp;#x27;: &amp;#x27;/openai/v1/chat/completions&amp;#x27;, &amp;#x27;files&amp;#x27;: None, &amp;#x27;json_data&amp;#x27;: {&amp;#x27;messages&amp;#x27;: [{&amp;#x27;role&amp;#x27;: &amp;#x27;system&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate a JSON response following these rules:\\n1. Return multiple UNIQUE versions at the SAME length:\\n   {&amp;quot;versions&amp;quot;: [{&amp;quot;text&amp;quot;: &amp;quot;version1&amp;quot;}, {&amp;quot;text&amp;quot;: &amp;quot;version2&amp;quot;}]}\\n2. Each version must:\\n   - Target exactly the specified percentage\\n   - Use different sentence structures\\n   - Vary word choices while keeping technical terms\\n   - Maintain the same meaning\\n3. If task cannot be completed: {&amp;quot;error&amp;quot;: &amp;quot;specific reason&amp;quot;}&amp;#x27;}, {&amp;#x27;role&amp;#x27;: &amp;#x27;user&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate 2 UNIQUE versions at 50% length:\\n        - Each must be exactly the same length\\n        - Use different phrasings\\n        Original length: 4 tokens\\n        Original text: Operations include various transformations&amp;#x27;}], &amp;#x27;model&amp;#x27;: &amp;#x27;llama3-groq-70b-8192-tool-use-preview&amp;#x27;, &amp;#x27;max_tokens&amp;#x27;: 1000, &amp;#x27;temperature&amp;#x27;: 0.7}}\nDEBUG:httpcore.http11:send_request_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.http11:send_request_headers.complete\nDEBUG:httpcore.http11:send_request_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.http11:send_request_body.complete\nDEBUG:httpcore.http11:receive_response_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.http11:receive_response_headers.complete return_value=(b&amp;#x27;HTTP/1.1&amp;#x27;, 200, b&amp;#x27;OK&amp;#x27;, [(b&amp;#x27;Date&amp;#x27;, b&amp;#x27;Wed, 30 Oct 2024 15:53:31 GMT&amp;#x27;), (b&amp;#x27;Content-Type&amp;#x27;, b&amp;#x27;application/json&amp;#x27;), (b&amp;#x27;Transfer-Encoding&amp;#x27;, b&amp;#x27;chunked&amp;#x27;), (b&amp;#x27;Connection&amp;#x27;, b&amp;#x27;keep-alive&amp;#x27;), (b&amp;#x27;Cache-Control&amp;#x27;, b&amp;#x27;private, max-age=0, no-store, no-cache, must-revalidate&amp;#x27;), (b&amp;#x27;vary&amp;#x27;, b&amp;#x27;Origin&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-requests&amp;#x27;, b&amp;#x27;14400&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-tokens&amp;#x27;, b&amp;#x27;15000&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-requests&amp;#x27;, b&amp;#x27;14381&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-tokens&amp;#x27;, b&amp;#x27;14594&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-requests&amp;#x27;, b&amp;#x27;1m53.677999999s&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-tokens&amp;#x27;, b&amp;#x27;1.621s&amp;#x27;), (b&amp;#x27;x-request-id&amp;#x27;, b&amp;#x27;req_01jbf23msyf16sz4vz53xvjngj&amp;#x27;), (b&amp;#x27;via&amp;#x27;, b&amp;#x27;1.1 google&amp;#x27;), (b&amp;#x27;alt-svc&amp;#x27;, b&amp;#x27;h3=&amp;quot;:443&amp;quot;; ma=86400&amp;#x27;), (b&amp;#x27;CF-Cache-Status&amp;#x27;, b&amp;#x27;DYNAMIC&amp;#x27;), (b&amp;#x27;Server&amp;#x27;, b&amp;#x27;cloudflare&amp;#x27;), (b&amp;#x27;CF-RAY&amp;#x27;, b&amp;#x27;8dac94249e99ca58-HAM&amp;#x27;), (b&amp;#x27;Content-Encoding&amp;#x27;, b&amp;#x27;gzip&amp;#x27;)])\nINFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;HTTP/1.1 200 OK&amp;quot;\nDEBUG:httpcore.http11:receive_response_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.http11:receive_response_body.complete\nDEBUG:httpcore.http11:response_closed.started\nDEBUG:httpcore.http11:response_closed.complete\nDEBUG:groq._base_client:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;200 OK&amp;quot;\n\n------------------------------ Captured log call -------------------------------\nDEBUG    app:__init__.py:31 Headers: {&amp;#x27;User-Agent&amp;#x27;: &amp;#x27;Werkzeug/3.0.6&amp;#x27;, &amp;#x27;Host&amp;#x27;: &amp;#x27;localhost&amp;#x27;, &amp;#x27;Content-Type&amp;#x27;: &amp;#x27;application/json&amp;#x27;, &amp;#x27;Content-Length&amp;#x27;: &amp;#x27;196&amp;#x27;, &amp;#x27;Authorization&amp;#x27;: &amp;#x27;Bearer test_key&amp;#x27;}\nDEBUG    app:__init__.py:32 Body: b&amp;#x27;{&amp;quot;content&amp;quot;: [&amp;quot;The Text Transformation API offers REST endpoints&amp;quot;, &amp;quot;These endpoints enable text manipulation&amp;quot;, &amp;quot;Operations include various transformations&amp;quot;], &amp;quot;target_percentage&amp;quot;: 50, &amp;quot;versions&amp;quot;: 2}&amp;#x27;\nDEBUG    app:__init__.py:33 Query Params: {}\nDEBUG    app:__init__.py:34 Route: POST /text/v1/compress/\nDEBUG    groq._base_client:_base_client.py:441 Request options: {&amp;#x27;method&amp;#x27;: &amp;#x27;post&amp;#x27;, &amp;#x27;url&amp;#x27;: &amp;#x27;/openai/v1/chat/completions&amp;#x27;, &amp;#x27;files&amp;#x27;: None, &amp;#x27;json_data&amp;#x27;: {&amp;#x27;messages&amp;#x27;: [{&amp;#x27;role&amp;#x27;: &amp;#x27;system&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate a JSON response following these rules:\\n1. Return multiple UNIQUE versions at the SAME length:\\n   {&amp;quot;versions&amp;quot;: [{&amp;quot;text&amp;quot;: &amp;quot;version1&amp;quot;}, {&amp;quot;text&amp;quot;: &amp;quot;version2&amp;quot;}]}\\n2. Each version must:\\n   - Target exactly the specified percentage\\n   - Use different sentence structures\\n   - Vary word choices while keeping technical terms\\n   - Maintain the same meaning\\n3. If task cannot be completed: {&amp;quot;error&amp;quot;: &amp;quot;specific reason&amp;quot;}&amp;#x27;}, {&amp;#x27;role&amp;#x27;: &amp;#x27;user&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate 2 UNIQUE versions at 50% length:\\n        - Each must be exactly the same length\\n        - Use different phrasings\\n        Original length: 7 tokens\\n        Original text: The Text Transformation API offers REST endpoints&amp;#x27;}], &amp;#x27;model&amp;#x27;: &amp;#x27;llama3-groq-70b-8192-tool-use-preview&amp;#x27;, &amp;#x27;max_tokens&amp;#x27;: 1000, &amp;#x27;temperature&amp;#x27;: 0.7}}\nDEBUG    httpcore.http11:_trace.py:45 send_request_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 send_request_headers.complete\nDEBUG    httpcore.http11:_trace.py:45 send_request_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 send_request_body.complete\nDEBUG    httpcore.http11:_trace.py:45 receive_response_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 receive_response_headers.complete return_value=(b&amp;#x27;HTTP/1.1&amp;#x27;, 200, b&amp;#x27;OK&amp;#x27;, [(b&amp;#x27;Date&amp;#x27;, b&amp;#x27;Wed, 30 Oct 2024 15:53:31 GMT&amp;#x27;), (b&amp;#x27;Content-Type&amp;#x27;, b&amp;#x27;application/json&amp;#x27;), (b&amp;#x27;Transfer-Encoding&amp;#x27;, b&amp;#x27;chunked&amp;#x27;), (b&amp;#x27;Connection&amp;#x27;, b&amp;#x27;keep-alive&amp;#x27;), (b&amp;#x27;Cache-Control&amp;#x27;, b&amp;#x27;private, max-age=0, no-store, no-cache, must-revalidate&amp;#x27;), (b&amp;#x27;vary&amp;#x27;, b&amp;#x27;Origin&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-requests&amp;#x27;, b&amp;#x27;14400&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-tokens&amp;#x27;, b&amp;#x27;15000&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-requests&amp;#x27;, b&amp;#x27;14383&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-tokens&amp;#x27;, b&amp;#x27;14612&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-requests&amp;#x27;, b&amp;#x27;1m40.562s&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-tokens&amp;#x27;, b&amp;#x27;1.55s&amp;#x27;), (b&amp;#x27;x-request-id&amp;#x27;, b&amp;#x27;req_01jbf23jzjf16swvwn4pxa335n&amp;#x27;), (b&amp;#x27;via&amp;#x27;, b&amp;#x27;1.1 google&amp;#x27;), (b&amp;#x27;alt-svc&amp;#x27;, b&amp;#x27;h3=&amp;quot;:443&amp;quot;; ma=86400&amp;#x27;), (b&amp;#x27;CF-Cache-Status&amp;#x27;, b&amp;#x27;DYNAMIC&amp;#x27;), (b&amp;#x27;Server&amp;#x27;, b&amp;#x27;cloudflare&amp;#x27;), (b&amp;#x27;CF-RAY&amp;#x27;, b&amp;#x27;8dac9418f862ca58-HAM&amp;#x27;), (b&amp;#x27;Content-Encoding&amp;#x27;, b&amp;#x27;gzip&amp;#x27;)])\nINFO     httpx:_client.py:1038 HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;HTTP/1.1 200 OK&amp;quot;\nDEBUG    httpcore.http11:_trace.py:45 receive_response_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 receive_response_body.complete\nDEBUG    httpcore.http11:_trace.py:45 response_closed.started\nDEBUG    httpcore.http11:_trace.py:45 response_closed.complete\nDEBUG    groq._base_client:_base_client.py:956 HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;200 OK&amp;quot;\nDEBUG    groq._base_client:_base_client.py:441 Request options: {&amp;#x27;method&amp;#x27;: &amp;#x27;post&amp;#x27;, &amp;#x27;url&amp;#x27;: &amp;#x27;/openai/v1/chat/completions&amp;#x27;, &amp;#x27;files&amp;#x27;: None, &amp;#x27;json_data&amp;#x27;: {&amp;#x27;messages&amp;#x27;: [{&amp;#x27;role&amp;#x27;: &amp;#x27;system&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate a JSON response following these rules:\\n1. Return multiple UNIQUE versions at the SAME length:\\n   {&amp;quot;versions&amp;quot;: [{&amp;quot;text&amp;quot;: &amp;quot;version1&amp;quot;}, {&amp;quot;text&amp;quot;: &amp;quot;version2&amp;quot;}]}\\n2. Each version must:\\n   - Target exactly the specified percentage\\n   - Use different sentence structures\\n   - Vary word choices while keeping technical terms\\n   - Maintain the same meaning\\n3. If task cannot be completed: {&amp;quot;error&amp;quot;: &amp;quot;specific reason&amp;quot;}&amp;#x27;}, {&amp;#x27;role&amp;#x27;: &amp;#x27;user&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate 2 UNIQUE versions at 50% length:\\n        - Each must be exactly the same length\\n        - Use different phrasings\\n        Original length: 5 tokens\\n        Original text: These endpoints enable text manipulation&amp;#x27;}], &amp;#x27;model&amp;#x27;: &amp;#x27;llama3-groq-70b-8192-tool-use-preview&amp;#x27;, &amp;#x27;max_tokens&amp;#x27;: 1000, &amp;#x27;temperature&amp;#x27;: 0.7}}\nDEBUG    httpcore.http11:_trace.py:45 send_request_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 send_request_headers.complete\nDEBUG    httpcore.http11:_trace.py:45 send_request_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 send_request_body.complete\nDEBUG    httpcore.http11:_trace.py:45 receive_response_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 receive_response_headers.complete return_value=(b&amp;#x27;HTTP/1.1&amp;#x27;, 200, b&amp;#x27;OK&amp;#x27;, [(b&amp;#x27;Date&amp;#x27;, b&amp;#x27;Wed, 30 Oct 2024 15:53:31 GMT&amp;#x27;), (b&amp;#x27;Content-Type&amp;#x27;, b&amp;#x27;application/json&amp;#x27;), (b&amp;#x27;Transfer-Encoding&amp;#x27;, b&amp;#x27;chunked&amp;#x27;), (b&amp;#x27;Connection&amp;#x27;, b&amp;#x27;keep-alive&amp;#x27;), (b&amp;#x27;Cache-Control&amp;#x27;, b&amp;#x27;private, max-age=0, no-store, no-cache, must-revalidate&amp;#x27;), (b&amp;#x27;vary&amp;#x27;, b&amp;#x27;Origin&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-requests&amp;#x27;, b&amp;#x27;14400&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-tokens&amp;#x27;, b&amp;#x27;15000&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-requests&amp;#x27;, b&amp;#x27;14382&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-tokens&amp;#x27;, b&amp;#x27;14693&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-requests&amp;#x27;, b&amp;#x27;1m46.457s&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-tokens&amp;#x27;, b&amp;#x27;1.228s&amp;#x27;), (b&amp;#x27;x-request-id&amp;#x27;, b&amp;#x27;req_01jbf23mfvfsms6rnwmn33t5hb&amp;#x27;), (b&amp;#x27;via&amp;#x27;, b&amp;#x27;1.1 google&amp;#x27;), (b&amp;#x27;alt-svc&amp;#x27;, b&amp;#x27;h3=&amp;quot;:443&amp;quot;; ma=86400&amp;#x27;), (b&amp;#x27;CF-Cache-Status&amp;#x27;, b&amp;#x27;DYNAMIC&amp;#x27;), (b&amp;#x27;Server&amp;#x27;, b&amp;#x27;cloudflare&amp;#x27;), (b&amp;#x27;CF-RAY&amp;#x27;, b&amp;#x27;8dac9422ac02ca58-HAM&amp;#x27;), (b&amp;#x27;Content-Encoding&amp;#x27;, b&amp;#x27;gzip&amp;#x27;)])\nINFO     httpx:_client.py:1038 HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;HTTP/1.1 200 OK&amp;quot;\nDEBUG    httpcore.http11:_trace.py:45 receive_response_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 receive_response_body.complete\nDEBUG    httpcore.http11:_trace.py:45 response_closed.started\nDEBUG    httpcore.http11:_trace.py:45 response_closed.complete\nDEBUG    groq._base_client:_base_client.py:956 HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;200 OK&amp;quot;\nDEBUG    groq._base_client:_base_client.py:441 Request options: {&amp;#x27;method&amp;#x27;: &amp;#x27;post&amp;#x27;, &amp;#x27;url&amp;#x27;: &amp;#x27;/openai/v1/chat/completions&amp;#x27;, &amp;#x27;files&amp;#x27;: None, &amp;#x27;json_data&amp;#x27;: {&amp;#x27;messages&amp;#x27;: [{&amp;#x27;role&amp;#x27;: &amp;#x27;system&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate a JSON response following these rules:\\n1. Return multiple UNIQUE versions at the SAME length:\\n   {&amp;quot;versions&amp;quot;: [{&amp;quot;text&amp;quot;: &amp;quot;version1&amp;quot;}, {&amp;quot;text&amp;quot;: &amp;quot;version2&amp;quot;}]}\\n2. Each version must:\\n   - Target exactly the specified percentage\\n   - Use different sentence structures\\n   - Vary word choices while keeping technical terms\\n   - Maintain the same meaning\\n3. If task cannot be completed: {&amp;quot;error&amp;quot;: &amp;quot;specific reason&amp;quot;}&amp;#x27;}, {&amp;#x27;role&amp;#x27;: &amp;#x27;user&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate 2 UNIQUE versions at 50% length:\\n        - Each must be exactly the same length\\n        - Use different phrasings\\n        Original length: 4 tokens\\n        Original text: Operations include various transformations&amp;#x27;}], &amp;#x27;model&amp;#x27;: &amp;#x27;llama3-groq-70b-8192-tool-use-preview&amp;#x27;, &amp;#x27;max_tokens&amp;#x27;: 1000, &amp;#x27;temperature&amp;#x27;: 0.7}}\nDEBUG    httpcore.http11:_trace.py:45 send_request_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 send_request_headers.complete\nDEBUG    httpcore.http11:_trace.py:45 send_request_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 send_request_body.complete\nDEBUG    httpcore.http11:_trace.py:45 receive_response_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 receive_response_headers.complete return_value=(b&amp;#x27;HTTP/1.1&amp;#x27;, 200, b&amp;#x27;OK&amp;#x27;, [(b&amp;#x27;Date&amp;#x27;, b&amp;#x27;Wed, 30 Oct 2024 15:53:31 GMT&amp;#x27;), (b&amp;#x27;Content-Type&amp;#x27;, b&amp;#x27;application/json&amp;#x27;), (b&amp;#x27;Transfer-Encoding&amp;#x27;, b&amp;#x27;chunked&amp;#x27;), (b&amp;#x27;Connection&amp;#x27;, b&amp;#x27;keep-alive&amp;#x27;), (b&amp;#x27;Cache-Control&amp;#x27;, b&amp;#x27;private, max-age=0, no-store, no-cache, must-revalidate&amp;#x27;), (b&amp;#x27;vary&amp;#x27;, b&amp;#x27;Origin&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-requests&amp;#x27;, b&amp;#x27;14400&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-tokens&amp;#x27;, b&amp;#x27;15000&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-requests&amp;#x27;, b&amp;#x27;14381&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-tokens&amp;#x27;, b&amp;#x27;14594&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-requests&amp;#x27;, b&amp;#x27;1m53.677999999s&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-tokens&amp;#x27;, b&amp;#x27;1.621s&amp;#x27;), (b&amp;#x27;x-request-id&amp;#x27;, b&amp;#x27;req_01jbf23msyf16sz4vz53xvjngj&amp;#x27;), (b&amp;#x27;via&amp;#x27;, b&amp;#x27;1.1 google&amp;#x27;), (b&amp;#x27;alt-svc&amp;#x27;, b&amp;#x27;h3=&amp;quot;:443&amp;quot;; ma=86400&amp;#x27;), (b&amp;#x27;CF-Cache-Status&amp;#x27;, b&amp;#x27;DYNAMIC&amp;#x27;), (b&amp;#x27;Server&amp;#x27;, b&amp;#x27;cloudflare&amp;#x27;), (b&amp;#x27;CF-RAY&amp;#x27;, b&amp;#x27;8dac94249e99ca58-HAM&amp;#x27;), (b&amp;#x27;Content-Encoding&amp;#x27;, b&amp;#x27;gzip&amp;#x27;)])\nINFO     httpx:_client.py:1038 HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;HTTP/1.1 200 OK&amp;quot;\nDEBUG    httpcore.http11:_trace.py:45 receive_response_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 receive_response_body.complete\nDEBUG    httpcore.http11:_trace.py:45 response_closed.started\nDEBUG    httpcore.http11:_trace.py:45 response_closed.complete\nDEBUG    groq._base_client:_base_client.py:956 HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;200 OK&amp;quot;\n\n&#34;}], &#34;tests/performance/test_compress_performance.py::TestCompressPerformance::test_invalid_inputs[invalid_input0]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Failed&#34;, &#34;testId&#34;: &#34;tests/performance/test_compress_performance.py::TestCompressPerformance::test_invalid_inputs[invalid_input0]&#34;, &#34;duration&#34;: &#34;803 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Failed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/performance/test_compress_performance.py::TestCompressPerformance::test_invalid_inputs[invalid_input0]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;803 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;self = &amp;lt;tests.performance.test_compress_performance.TestCompressPerformance object at 0x1069d05f0&amp;gt;\nclient = &amp;lt;FlaskClient &amp;lt;Flask &amp;#x27;app&amp;#x27;&amp;gt;&amp;gt;\nauth_headers = {&amp;#x27;Authorization&amp;#x27;: &amp;#x27;Bearer test_key&amp;#x27;, &amp;#x27;Content-Type&amp;#x27;: &amp;#x27;application/json&amp;#x27;}\ninvalid_input = {&amp;#x27;content&amp;#x27;: &amp;#x27;text&amp;#x27;, &amp;#x27;target_percentage&amp;#x27;: 150}\n\n    @pytest.mark.unit\n    @pytest.mark.parametrize(&amp;#x27;invalid_input&amp;#x27;, [\n        {&amp;#x27;content&amp;#x27;: &amp;quot;text&amp;quot;, &amp;#x27;target_percentage&amp;#x27;: 150},  # Invalid percentage\n        {&amp;#x27;content&amp;#x27;: &amp;quot;text&amp;quot;, &amp;#x27;steps_percentage&amp;#x27;: -10},   # Negative steps\n        {&amp;#x27;content&amp;#x27;: &amp;quot;text&amp;quot;, &amp;#x27;versions&amp;#x27;: 10},            # Too many versions\n        {&amp;#x27;content&amp;#x27;: &amp;quot;&amp;quot;, &amp;#x27;target_percentage&amp;#x27;: 50},       # Empty content\n        {&amp;#x27;target_percentage&amp;#x27;: 50},                      # Missing content\n    ])\n    def test_invalid_inputs(self, client, auth_headers, invalid_input):\n        response = client.post(\n            self.ENDPOINTS[&amp;#x27;compress&amp;#x27;], json=invalid_input, headers=auth_headers)\n&amp;gt;       assert response.status_code == 400\nE       assert 200 == 400\nE        +  where 200 = &amp;lt;WrapperTestResponse streamed [200 OK]&amp;gt;.status_code\n\ntests/test_compress.py:139: AssertionError\n\n---------------------------- Captured stderr setup -----------------------------\nDEBUG:app:Registering blueprints...\nDEBUG:app:Registered routes:\nDEBUG:app:static: /static/&amp;lt;path:filename&amp;gt; [GET, OPTIONS, HEAD]\nDEBUG:app:generate.create_text: /text/v1/generate/text [OPTIONS, POST]\nDEBUG:app:compress.compress_text: /text/v1/compress/ [OPTIONS, POST]\nDEBUG:app:expand.expand_text: /text/v1/expand/ [OPTIONS, POST]\n\n------------------------------ Captured log setup ------------------------------\nDEBUG    app:__init__.py:106 Registering blueprints...\nDEBUG    app:__init__.py:112 Registered routes:\nDEBUG    app:__init__.py:114 static: /static/&amp;lt;path:filename&amp;gt; [GET, OPTIONS, HEAD]\nDEBUG    app:__init__.py:114 generate.create_text: /text/v1/generate/text [OPTIONS, POST]\nDEBUG    app:__init__.py:114 compress.compress_text: /text/v1/compress/ [OPTIONS, POST]\nDEBUG    app:__init__.py:114 expand.expand_text: /text/v1/expand/ [OPTIONS, POST]\n\n----------------------------- Captured stderr call -----------------------------\nDEBUG:app:Headers: {&amp;#x27;User-Agent&amp;#x27;: &amp;#x27;Werkzeug/3.0.6&amp;#x27;, &amp;#x27;Host&amp;#x27;: &amp;#x27;localhost&amp;#x27;, &amp;#x27;Content-Type&amp;#x27;: &amp;#x27;application/json&amp;#x27;, &amp;#x27;Content-Length&amp;#x27;: &amp;#x27;45&amp;#x27;, &amp;#x27;Authorization&amp;#x27;: &amp;#x27;Bearer test_key&amp;#x27;}\nDEBUG:app:Body: b&amp;#x27;{&amp;quot;content&amp;quot;: &amp;quot;text&amp;quot;, &amp;quot;target_percentage&amp;quot;: 150}&amp;#x27;\nDEBUG:app:Query Params: {}\nDEBUG:app:Route: POST /text/v1/compress/\nDEBUG:groq._base_client:Request options: {&amp;#x27;method&amp;#x27;: &amp;#x27;post&amp;#x27;, &amp;#x27;url&amp;#x27;: &amp;#x27;/openai/v1/chat/completions&amp;#x27;, &amp;#x27;files&amp;#x27;: None, &amp;#x27;json_data&amp;#x27;: {&amp;#x27;messages&amp;#x27;: [{&amp;#x27;role&amp;#x27;: &amp;#x27;system&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate a JSON response following these rules:\\n1. Return exactly ONE compressed version:\\n   {&amp;quot;versions&amp;quot;: [{&amp;quot;text&amp;quot;: &amp;quot;compressed version&amp;quot;}]}\\n2. Target exactly the specified percentage of original length\\n3. Maintain core meaning while removing less essential details\\n4. Ensure complete sentences and proper punctuation\\n5. If task cannot be completed: {&amp;quot;error&amp;quot;: &amp;quot;specific reason&amp;quot;}&amp;#x27;}, {&amp;#x27;role&amp;#x27;: &amp;#x27;user&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate ONE compressed version at 150% length:\\n        Original length: 1 tokens\\n        Original text: text&amp;#x27;}], &amp;#x27;model&amp;#x27;: &amp;#x27;llama3-groq-70b-8192-tool-use-preview&amp;#x27;, &amp;#x27;max_tokens&amp;#x27;: 1000, &amp;#x27;temperature&amp;#x27;: 0.7}}\nDEBUG:httpcore.http11:send_request_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.http11:send_request_headers.complete\nDEBUG:httpcore.http11:send_request_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.http11:send_request_body.complete\nDEBUG:httpcore.http11:receive_response_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.http11:receive_response_headers.complete return_value=(b&amp;#x27;HTTP/1.1&amp;#x27;, 200, b&amp;#x27;OK&amp;#x27;, [(b&amp;#x27;Date&amp;#x27;, b&amp;#x27;Wed, 30 Oct 2024 15:53:32 GMT&amp;#x27;), (b&amp;#x27;Content-Type&amp;#x27;, b&amp;#x27;application/json&amp;#x27;), (b&amp;#x27;Transfer-Encoding&amp;#x27;, b&amp;#x27;chunked&amp;#x27;), (b&amp;#x27;Connection&amp;#x27;, b&amp;#x27;keep-alive&amp;#x27;), (b&amp;#x27;Cache-Control&amp;#x27;, b&amp;#x27;private, max-age=0, no-store, no-cache, must-revalidate&amp;#x27;), (b&amp;#x27;vary&amp;#x27;, b&amp;#x27;Origin&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-requests&amp;#x27;, b&amp;#x27;14400&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-tokens&amp;#x27;, b&amp;#x27;15000&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-requests&amp;#x27;, b&amp;#x27;14380&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-tokens&amp;#x27;, b&amp;#x27;14665&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-requests&amp;#x27;, b&amp;#x27;1m59.157s&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-tokens&amp;#x27;, b&amp;#x27;1.338s&amp;#x27;), (b&amp;#x27;x-request-id&amp;#x27;, b&amp;#x27;req_01jbf23nm9fvv82pdnx0xs00kp&amp;#x27;), (b&amp;#x27;via&amp;#x27;, b&amp;#x27;1.1 google&amp;#x27;), (b&amp;#x27;alt-svc&amp;#x27;, b&amp;#x27;h3=&amp;quot;:443&amp;quot;; ma=86400&amp;#x27;), (b&amp;#x27;CF-Cache-Status&amp;#x27;, b&amp;#x27;DYNAMIC&amp;#x27;), (b&amp;#x27;Server&amp;#x27;, b&amp;#x27;cloudflare&amp;#x27;), (b&amp;#x27;CF-RAY&amp;#x27;, b&amp;#x27;8dac9429ed4dca58-HAM&amp;#x27;), (b&amp;#x27;Content-Encoding&amp;#x27;, b&amp;#x27;gzip&amp;#x27;)])\nINFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;HTTP/1.1 200 OK&amp;quot;\nDEBUG:httpcore.http11:receive_response_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.http11:receive_response_body.complete\nDEBUG:httpcore.http11:response_closed.started\nDEBUG:httpcore.http11:response_closed.complete\nDEBUG:groq._base_client:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;200 OK&amp;quot;\n\n------------------------------ Captured log call -------------------------------\nDEBUG    app:__init__.py:31 Headers: {&amp;#x27;User-Agent&amp;#x27;: &amp;#x27;Werkzeug/3.0.6&amp;#x27;, &amp;#x27;Host&amp;#x27;: &amp;#x27;localhost&amp;#x27;, &amp;#x27;Content-Type&amp;#x27;: &amp;#x27;application/json&amp;#x27;, &amp;#x27;Content-Length&amp;#x27;: &amp;#x27;45&amp;#x27;, &amp;#x27;Authorization&amp;#x27;: &amp;#x27;Bearer test_key&amp;#x27;}\nDEBUG    app:__init__.py:32 Body: b&amp;#x27;{&amp;quot;content&amp;quot;: &amp;quot;text&amp;quot;, &amp;quot;target_percentage&amp;quot;: 150}&amp;#x27;\nDEBUG    app:__init__.py:33 Query Params: {}\nDEBUG    app:__init__.py:34 Route: POST /text/v1/compress/\nDEBUG    groq._base_client:_base_client.py:441 Request options: {&amp;#x27;method&amp;#x27;: &amp;#x27;post&amp;#x27;, &amp;#x27;url&amp;#x27;: &amp;#x27;/openai/v1/chat/completions&amp;#x27;, &amp;#x27;files&amp;#x27;: None, &amp;#x27;json_data&amp;#x27;: {&amp;#x27;messages&amp;#x27;: [{&amp;#x27;role&amp;#x27;: &amp;#x27;system&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate a JSON response following these rules:\\n1. Return exactly ONE compressed version:\\n   {&amp;quot;versions&amp;quot;: [{&amp;quot;text&amp;quot;: &amp;quot;compressed version&amp;quot;}]}\\n2. Target exactly the specified percentage of original length\\n3. Maintain core meaning while removing less essential details\\n4. Ensure complete sentences and proper punctuation\\n5. If task cannot be completed: {&amp;quot;error&amp;quot;: &amp;quot;specific reason&amp;quot;}&amp;#x27;}, {&amp;#x27;role&amp;#x27;: &amp;#x27;user&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate ONE compressed version at 150% length:\\n        Original length: 1 tokens\\n        Original text: text&amp;#x27;}], &amp;#x27;model&amp;#x27;: &amp;#x27;llama3-groq-70b-8192-tool-use-preview&amp;#x27;, &amp;#x27;max_tokens&amp;#x27;: 1000, &amp;#x27;temperature&amp;#x27;: 0.7}}\nDEBUG    httpcore.http11:_trace.py:45 send_request_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 send_request_headers.complete\nDEBUG    httpcore.http11:_trace.py:45 send_request_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 send_request_body.complete\nDEBUG    httpcore.http11:_trace.py:45 receive_response_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 receive_response_headers.complete return_value=(b&amp;#x27;HTTP/1.1&amp;#x27;, 200, b&amp;#x27;OK&amp;#x27;, [(b&amp;#x27;Date&amp;#x27;, b&amp;#x27;Wed, 30 Oct 2024 15:53:32 GMT&amp;#x27;), (b&amp;#x27;Content-Type&amp;#x27;, b&amp;#x27;application/json&amp;#x27;), (b&amp;#x27;Transfer-Encoding&amp;#x27;, b&amp;#x27;chunked&amp;#x27;), (b&amp;#x27;Connection&amp;#x27;, b&amp;#x27;keep-alive&amp;#x27;), (b&amp;#x27;Cache-Control&amp;#x27;, b&amp;#x27;private, max-age=0, no-store, no-cache, must-revalidate&amp;#x27;), (b&amp;#x27;vary&amp;#x27;, b&amp;#x27;Origin&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-requests&amp;#x27;, b&amp;#x27;14400&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-tokens&amp;#x27;, b&amp;#x27;15000&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-requests&amp;#x27;, b&amp;#x27;14380&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-tokens&amp;#x27;, b&amp;#x27;14665&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-requests&amp;#x27;, b&amp;#x27;1m59.157s&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-tokens&amp;#x27;, b&amp;#x27;1.338s&amp;#x27;), (b&amp;#x27;x-request-id&amp;#x27;, b&amp;#x27;req_01jbf23nm9fvv82pdnx0xs00kp&amp;#x27;), (b&amp;#x27;via&amp;#x27;, b&amp;#x27;1.1 google&amp;#x27;), (b&amp;#x27;alt-svc&amp;#x27;, b&amp;#x27;h3=&amp;quot;:443&amp;quot;; ma=86400&amp;#x27;), (b&amp;#x27;CF-Cache-Status&amp;#x27;, b&amp;#x27;DYNAMIC&amp;#x27;), (b&amp;#x27;Server&amp;#x27;, b&amp;#x27;cloudflare&amp;#x27;), (b&amp;#x27;CF-RAY&amp;#x27;, b&amp;#x27;8dac9429ed4dca58-HAM&amp;#x27;), (b&amp;#x27;Content-Encoding&amp;#x27;, b&amp;#x27;gzip&amp;#x27;)])\nINFO     httpx:_client.py:1038 HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;HTTP/1.1 200 OK&amp;quot;\nDEBUG    httpcore.http11:_trace.py:45 receive_response_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 receive_response_body.complete\nDEBUG    httpcore.http11:_trace.py:45 response_closed.started\nDEBUG    httpcore.http11:_trace.py:45 response_closed.complete\nDEBUG    groq._base_client:_base_client.py:956 HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;200 OK&amp;quot;\n\n&#34;}], &#34;tests/performance/test_compress_performance.py::TestCompressPerformance::test_invalid_inputs[invalid_input1]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Failed&#34;, &#34;testId&#34;: &#34;tests/performance/test_compress_performance.py::TestCompressPerformance::test_invalid_inputs[invalid_input1]&#34;, &#34;duration&#34;: &#34;860 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Failed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/performance/test_compress_performance.py::TestCompressPerformance::test_invalid_inputs[invalid_input1]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;860 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;self = &amp;lt;tests.performance.test_compress_performance.TestCompressPerformance object at 0x1069d0800&amp;gt;\nclient = &amp;lt;FlaskClient &amp;lt;Flask &amp;#x27;app&amp;#x27;&amp;gt;&amp;gt;\nauth_headers = {&amp;#x27;Authorization&amp;#x27;: &amp;#x27;Bearer test_key&amp;#x27;, &amp;#x27;Content-Type&amp;#x27;: &amp;#x27;application/json&amp;#x27;}\ninvalid_input = {&amp;#x27;content&amp;#x27;: &amp;#x27;text&amp;#x27;, &amp;#x27;steps_percentage&amp;#x27;: -10}\n\n    @pytest.mark.unit\n    @pytest.mark.parametrize(&amp;#x27;invalid_input&amp;#x27;, [\n        {&amp;#x27;content&amp;#x27;: &amp;quot;text&amp;quot;, &amp;#x27;target_percentage&amp;#x27;: 150},  # Invalid percentage\n        {&amp;#x27;content&amp;#x27;: &amp;quot;text&amp;quot;, &amp;#x27;steps_percentage&amp;#x27;: -10},   # Negative steps\n        {&amp;#x27;content&amp;#x27;: &amp;quot;text&amp;quot;, &amp;#x27;versions&amp;#x27;: 10},            # Too many versions\n        {&amp;#x27;content&amp;#x27;: &amp;quot;&amp;quot;, &amp;#x27;target_percentage&amp;#x27;: 50},       # Empty content\n        {&amp;#x27;target_percentage&amp;#x27;: 50},                      # Missing content\n    ])\n    def test_invalid_inputs(self, client, auth_headers, invalid_input):\n        response = client.post(\n            self.ENDPOINTS[&amp;#x27;compress&amp;#x27;], json=invalid_input, headers=auth_headers)\n&amp;gt;       assert response.status_code == 400\nE       assert 200 == 400\nE        +  where 200 = &amp;lt;WrapperTestResponse streamed [200 OK]&amp;gt;.status_code\n\ntests/test_compress.py:139: AssertionError\n\n---------------------------- Captured stderr setup -----------------------------\nDEBUG:app:Registering blueprints...\nDEBUG:app:Registered routes:\nDEBUG:app:static: /static/&amp;lt;path:filename&amp;gt; [GET, OPTIONS, HEAD]\nDEBUG:app:generate.create_text: /text/v1/generate/text [OPTIONS, POST]\nDEBUG:app:compress.compress_text: /text/v1/compress/ [OPTIONS, POST]\nDEBUG:app:expand.expand_text: /text/v1/expand/ [OPTIONS, POST]\n\n------------------------------ Captured log setup ------------------------------\nDEBUG    app:__init__.py:106 Registering blueprints...\nDEBUG    app:__init__.py:112 Registered routes:\nDEBUG    app:__init__.py:114 static: /static/&amp;lt;path:filename&amp;gt; [GET, OPTIONS, HEAD]\nDEBUG    app:__init__.py:114 generate.create_text: /text/v1/generate/text [OPTIONS, POST]\nDEBUG    app:__init__.py:114 compress.compress_text: /text/v1/compress/ [OPTIONS, POST]\nDEBUG    app:__init__.py:114 expand.expand_text: /text/v1/expand/ [OPTIONS, POST]\n\n----------------------------- Captured stderr call -----------------------------\nDEBUG:app:Headers: {&amp;#x27;User-Agent&amp;#x27;: &amp;#x27;Werkzeug/3.0.6&amp;#x27;, &amp;#x27;Host&amp;#x27;: &amp;#x27;localhost&amp;#x27;, &amp;#x27;Content-Type&amp;#x27;: &amp;#x27;application/json&amp;#x27;, &amp;#x27;Content-Length&amp;#x27;: &amp;#x27;44&amp;#x27;, &amp;#x27;Authorization&amp;#x27;: &amp;#x27;Bearer test_key&amp;#x27;}\nDEBUG:app:Body: b&amp;#x27;{&amp;quot;content&amp;quot;: &amp;quot;text&amp;quot;, &amp;quot;steps_percentage&amp;quot;: -10}&amp;#x27;\nDEBUG:app:Query Params: {}\nDEBUG:app:Route: POST /text/v1/compress/\nDEBUG:groq._base_client:Request options: {&amp;#x27;method&amp;#x27;: &amp;#x27;post&amp;#x27;, &amp;#x27;url&amp;#x27;: &amp;#x27;/openai/v1/chat/completions&amp;#x27;, &amp;#x27;files&amp;#x27;: None, &amp;#x27;json_data&amp;#x27;: {&amp;#x27;messages&amp;#x27;: [{&amp;#x27;role&amp;#x27;: &amp;#x27;system&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate a JSON response following these rules:\\n1. Return exactly ONE compressed version:\\n   {&amp;quot;versions&amp;quot;: [{&amp;quot;text&amp;quot;: &amp;quot;compressed version&amp;quot;}]}\\n2. Target exactly the specified percentage of original length\\n3. Maintain core meaning while removing less essential details\\n4. Ensure complete sentences and proper punctuation\\n5. If task cannot be completed: {&amp;quot;error&amp;quot;: &amp;quot;specific reason&amp;quot;}&amp;#x27;}, {&amp;#x27;role&amp;#x27;: &amp;#x27;user&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate ONE compressed version at 20% length:\\n        Original length: 1 tokens\\n        Original text: text&amp;#x27;}], &amp;#x27;model&amp;#x27;: &amp;#x27;llama3-groq-70b-8192-tool-use-preview&amp;#x27;, &amp;#x27;max_tokens&amp;#x27;: 1000, &amp;#x27;temperature&amp;#x27;: 0.7}}\nDEBUG:httpcore.http11:send_request_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.http11:send_request_headers.complete\nDEBUG:httpcore.http11:send_request_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.http11:send_request_body.complete\nDEBUG:httpcore.http11:receive_response_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.http11:receive_response_headers.complete return_value=(b&amp;#x27;HTTP/1.1&amp;#x27;, 200, b&amp;#x27;OK&amp;#x27;, [(b&amp;#x27;Date&amp;#x27;, b&amp;#x27;Wed, 30 Oct 2024 15:53:33 GMT&amp;#x27;), (b&amp;#x27;Content-Type&amp;#x27;, b&amp;#x27;application/json&amp;#x27;), (b&amp;#x27;Transfer-Encoding&amp;#x27;, b&amp;#x27;chunked&amp;#x27;), (b&amp;#x27;Connection&amp;#x27;, b&amp;#x27;keep-alive&amp;#x27;), (b&amp;#x27;Cache-Control&amp;#x27;, b&amp;#x27;private, max-age=0, no-store, no-cache, must-revalidate&amp;#x27;), (b&amp;#x27;vary&amp;#x27;, b&amp;#x27;Origin&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-requests&amp;#x27;, b&amp;#x27;14400&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-tokens&amp;#x27;, b&amp;#x27;15000&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-requests&amp;#x27;, b&amp;#x27;14379&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-tokens&amp;#x27;, b&amp;#x27;14746&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-requests&amp;#x27;, b&amp;#x27;2m5.183999999s&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-tokens&amp;#x27;, b&amp;#x27;1.012999999s&amp;#x27;), (b&amp;#x27;x-request-id&amp;#x27;, b&amp;#x27;req_01jbf23pdvebn8tym13zvcm9a0&amp;#x27;), (b&amp;#x27;via&amp;#x27;, b&amp;#x27;1.1 google&amp;#x27;), (b&amp;#x27;alt-svc&amp;#x27;, b&amp;#x27;h3=&amp;quot;:443&amp;quot;; ma=86400&amp;#x27;), (b&amp;#x27;CF-Cache-Status&amp;#x27;, b&amp;#x27;DYNAMIC&amp;#x27;), (b&amp;#x27;Server&amp;#x27;, b&amp;#x27;cloudflare&amp;#x27;), (b&amp;#x27;CF-RAY&amp;#x27;, b&amp;#x27;8dac942efad9ca58-HAM&amp;#x27;), (b&amp;#x27;Content-Encoding&amp;#x27;, b&amp;#x27;gzip&amp;#x27;)])\nINFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;HTTP/1.1 200 OK&amp;quot;\nDEBUG:httpcore.http11:receive_response_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.http11:receive_response_body.complete\nDEBUG:httpcore.http11:response_closed.started\nDEBUG:httpcore.http11:response_closed.complete\nDEBUG:groq._base_client:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;200 OK&amp;quot;\n\n------------------------------ Captured log call -------------------------------\nDEBUG    app:__init__.py:31 Headers: {&amp;#x27;User-Agent&amp;#x27;: &amp;#x27;Werkzeug/3.0.6&amp;#x27;, &amp;#x27;Host&amp;#x27;: &amp;#x27;localhost&amp;#x27;, &amp;#x27;Content-Type&amp;#x27;: &amp;#x27;application/json&amp;#x27;, &amp;#x27;Content-Length&amp;#x27;: &amp;#x27;44&amp;#x27;, &amp;#x27;Authorization&amp;#x27;: &amp;#x27;Bearer test_key&amp;#x27;}\nDEBUG    app:__init__.py:32 Body: b&amp;#x27;{&amp;quot;content&amp;quot;: &amp;quot;text&amp;quot;, &amp;quot;steps_percentage&amp;quot;: -10}&amp;#x27;\nDEBUG    app:__init__.py:33 Query Params: {}\nDEBUG    app:__init__.py:34 Route: POST /text/v1/compress/\nDEBUG    groq._base_client:_base_client.py:441 Request options: {&amp;#x27;method&amp;#x27;: &amp;#x27;post&amp;#x27;, &amp;#x27;url&amp;#x27;: &amp;#x27;/openai/v1/chat/completions&amp;#x27;, &amp;#x27;files&amp;#x27;: None, &amp;#x27;json_data&amp;#x27;: {&amp;#x27;messages&amp;#x27;: [{&amp;#x27;role&amp;#x27;: &amp;#x27;system&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate a JSON response following these rules:\\n1. Return exactly ONE compressed version:\\n   {&amp;quot;versions&amp;quot;: [{&amp;quot;text&amp;quot;: &amp;quot;compressed version&amp;quot;}]}\\n2. Target exactly the specified percentage of original length\\n3. Maintain core meaning while removing less essential details\\n4. Ensure complete sentences and proper punctuation\\n5. If task cannot be completed: {&amp;quot;error&amp;quot;: &amp;quot;specific reason&amp;quot;}&amp;#x27;}, {&amp;#x27;role&amp;#x27;: &amp;#x27;user&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate ONE compressed version at 20% length:\\n        Original length: 1 tokens\\n        Original text: text&amp;#x27;}], &amp;#x27;model&amp;#x27;: &amp;#x27;llama3-groq-70b-8192-tool-use-preview&amp;#x27;, &amp;#x27;max_tokens&amp;#x27;: 1000, &amp;#x27;temperature&amp;#x27;: 0.7}}\nDEBUG    httpcore.http11:_trace.py:45 send_request_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 send_request_headers.complete\nDEBUG    httpcore.http11:_trace.py:45 send_request_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 send_request_body.complete\nDEBUG    httpcore.http11:_trace.py:45 receive_response_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 receive_response_headers.complete return_value=(b&amp;#x27;HTTP/1.1&amp;#x27;, 200, b&amp;#x27;OK&amp;#x27;, [(b&amp;#x27;Date&amp;#x27;, b&amp;#x27;Wed, 30 Oct 2024 15:53:33 GMT&amp;#x27;), (b&amp;#x27;Content-Type&amp;#x27;, b&amp;#x27;application/json&amp;#x27;), (b&amp;#x27;Transfer-Encoding&amp;#x27;, b&amp;#x27;chunked&amp;#x27;), (b&amp;#x27;Connection&amp;#x27;, b&amp;#x27;keep-alive&amp;#x27;), (b&amp;#x27;Cache-Control&amp;#x27;, b&amp;#x27;private, max-age=0, no-store, no-cache, must-revalidate&amp;#x27;), (b&amp;#x27;vary&amp;#x27;, b&amp;#x27;Origin&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-requests&amp;#x27;, b&amp;#x27;14400&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-tokens&amp;#x27;, b&amp;#x27;15000&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-requests&amp;#x27;, b&amp;#x27;14379&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-tokens&amp;#x27;, b&amp;#x27;14746&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-requests&amp;#x27;, b&amp;#x27;2m5.183999999s&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-tokens&amp;#x27;, b&amp;#x27;1.012999999s&amp;#x27;), (b&amp;#x27;x-request-id&amp;#x27;, b&amp;#x27;req_01jbf23pdvebn8tym13zvcm9a0&amp;#x27;), (b&amp;#x27;via&amp;#x27;, b&amp;#x27;1.1 google&amp;#x27;), (b&amp;#x27;alt-svc&amp;#x27;, b&amp;#x27;h3=&amp;quot;:443&amp;quot;; ma=86400&amp;#x27;), (b&amp;#x27;CF-Cache-Status&amp;#x27;, b&amp;#x27;DYNAMIC&amp;#x27;), (b&amp;#x27;Server&amp;#x27;, b&amp;#x27;cloudflare&amp;#x27;), (b&amp;#x27;CF-RAY&amp;#x27;, b&amp;#x27;8dac942efad9ca58-HAM&amp;#x27;), (b&amp;#x27;Content-Encoding&amp;#x27;, b&amp;#x27;gzip&amp;#x27;)])\nINFO     httpx:_client.py:1038 HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;HTTP/1.1 200 OK&amp;quot;\nDEBUG    httpcore.http11:_trace.py:45 receive_response_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 receive_response_body.complete\nDEBUG    httpcore.http11:_trace.py:45 response_closed.started\nDEBUG    httpcore.http11:_trace.py:45 response_closed.complete\nDEBUG    groq._base_client:_base_client.py:956 HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;200 OK&amp;quot;\n\n&#34;}], &#34;tests/performance/test_compress_performance.py::TestCompressPerformance::test_invalid_inputs[invalid_input2]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Failed&#34;, &#34;testId&#34;: &#34;tests/performance/test_compress_performance.py::TestCompressPerformance::test_invalid_inputs[invalid_input2]&#34;, &#34;duration&#34;: &#34;940 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Failed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/performance/test_compress_performance.py::TestCompressPerformance::test_invalid_inputs[invalid_input2]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;940 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;self = &amp;lt;tests.performance.test_compress_performance.TestCompressPerformance object at 0x1069d09b0&amp;gt;\nclient = &amp;lt;FlaskClient &amp;lt;Flask &amp;#x27;app&amp;#x27;&amp;gt;&amp;gt;\nauth_headers = {&amp;#x27;Authorization&amp;#x27;: &amp;#x27;Bearer test_key&amp;#x27;, &amp;#x27;Content-Type&amp;#x27;: &amp;#x27;application/json&amp;#x27;}\ninvalid_input = {&amp;#x27;content&amp;#x27;: &amp;#x27;text&amp;#x27;, &amp;#x27;versions&amp;#x27;: 10}\n\n    @pytest.mark.unit\n    @pytest.mark.parametrize(&amp;#x27;invalid_input&amp;#x27;, [\n        {&amp;#x27;content&amp;#x27;: &amp;quot;text&amp;quot;, &amp;#x27;target_percentage&amp;#x27;: 150},  # Invalid percentage\n        {&amp;#x27;content&amp;#x27;: &amp;quot;text&amp;quot;, &amp;#x27;steps_percentage&amp;#x27;: -10},   # Negative steps\n        {&amp;#x27;content&amp;#x27;: &amp;quot;text&amp;quot;, &amp;#x27;versions&amp;#x27;: 10},            # Too many versions\n        {&amp;#x27;content&amp;#x27;: &amp;quot;&amp;quot;, &amp;#x27;target_percentage&amp;#x27;: 50},       # Empty content\n        {&amp;#x27;target_percentage&amp;#x27;: 50},                      # Missing content\n    ])\n    def test_invalid_inputs(self, client, auth_headers, invalid_input):\n        response = client.post(\n            self.ENDPOINTS[&amp;#x27;compress&amp;#x27;], json=invalid_input, headers=auth_headers)\n&amp;gt;       assert response.status_code == 400\nE       assert 200 == 400\nE        +  where 200 = &amp;lt;WrapperTestResponse streamed [200 OK]&amp;gt;.status_code\n\ntests/test_compress.py:139: AssertionError\n\n---------------------------- Captured stderr setup -----------------------------\nDEBUG:app:Registering blueprints...\nDEBUG:app:Registered routes:\nDEBUG:app:static: /static/&amp;lt;path:filename&amp;gt; [GET, OPTIONS, HEAD]\nDEBUG:app:generate.create_text: /text/v1/generate/text [OPTIONS, POST]\nDEBUG:app:compress.compress_text: /text/v1/compress/ [OPTIONS, POST]\nDEBUG:app:expand.expand_text: /text/v1/expand/ [OPTIONS, POST]\n\n------------------------------ Captured log setup ------------------------------\nDEBUG    app:__init__.py:106 Registering blueprints...\nDEBUG    app:__init__.py:112 Registered routes:\nDEBUG    app:__init__.py:114 static: /static/&amp;lt;path:filename&amp;gt; [GET, OPTIONS, HEAD]\nDEBUG    app:__init__.py:114 generate.create_text: /text/v1/generate/text [OPTIONS, POST]\nDEBUG    app:__init__.py:114 compress.compress_text: /text/v1/compress/ [OPTIONS, POST]\nDEBUG    app:__init__.py:114 expand.expand_text: /text/v1/expand/ [OPTIONS, POST]\n\n----------------------------- Captured stderr call -----------------------------\nDEBUG:app:Headers: {&amp;#x27;User-Agent&amp;#x27;: &amp;#x27;Werkzeug/3.0.6&amp;#x27;, &amp;#x27;Host&amp;#x27;: &amp;#x27;localhost&amp;#x27;, &amp;#x27;Content-Type&amp;#x27;: &amp;#x27;application/json&amp;#x27;, &amp;#x27;Content-Length&amp;#x27;: &amp;#x27;35&amp;#x27;, &amp;#x27;Authorization&amp;#x27;: &amp;#x27;Bearer test_key&amp;#x27;}\nDEBUG:app:Body: b&amp;#x27;{&amp;quot;content&amp;quot;: &amp;quot;text&amp;quot;, &amp;quot;versions&amp;quot;: 10}&amp;#x27;\nDEBUG:app:Query Params: {}\nDEBUG:app:Route: POST /text/v1/compress/\nDEBUG:groq._base_client:Request options: {&amp;#x27;method&amp;#x27;: &amp;#x27;post&amp;#x27;, &amp;#x27;url&amp;#x27;: &amp;#x27;/openai/v1/chat/completions&amp;#x27;, &amp;#x27;files&amp;#x27;: None, &amp;#x27;json_data&amp;#x27;: {&amp;#x27;messages&amp;#x27;: [{&amp;#x27;role&amp;#x27;: &amp;#x27;system&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate a JSON response following these rules:\\n1. Return multiple UNIQUE versions at the SAME length:\\n   {&amp;quot;versions&amp;quot;: [{&amp;quot;text&amp;quot;: &amp;quot;version1&amp;quot;}, {&amp;quot;text&amp;quot;: &amp;quot;version2&amp;quot;}]}\\n2. Each version must:\\n   - Target exactly the specified percentage\\n   - Use different sentence structures\\n   - Vary word choices while keeping technical terms\\n   - Maintain the same meaning\\n3. If task cannot be completed: {&amp;quot;error&amp;quot;: &amp;quot;specific reason&amp;quot;}&amp;#x27;}, {&amp;#x27;role&amp;#x27;: &amp;#x27;user&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate 5 UNIQUE versions at 20% length:\\n        - Each must be exactly the same length\\n        - Use different phrasings\\n        Original length: 1 tokens\\n        Original text: text&amp;#x27;}], &amp;#x27;model&amp;#x27;: &amp;#x27;llama3-groq-70b-8192-tool-use-preview&amp;#x27;, &amp;#x27;max_tokens&amp;#x27;: 1000, &amp;#x27;temperature&amp;#x27;: 0.7}}\nDEBUG:httpcore.http11:send_request_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.http11:send_request_headers.complete\nDEBUG:httpcore.http11:send_request_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.http11:send_request_body.complete\nDEBUG:httpcore.http11:receive_response_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.http11:receive_response_headers.complete return_value=(b&amp;#x27;HTTP/1.1&amp;#x27;, 200, b&amp;#x27;OK&amp;#x27;, [(b&amp;#x27;Date&amp;#x27;, b&amp;#x27;Wed, 30 Oct 2024 15:53:34 GMT&amp;#x27;), (b&amp;#x27;Content-Type&amp;#x27;, b&amp;#x27;application/json&amp;#x27;), (b&amp;#x27;Transfer-Encoding&amp;#x27;, b&amp;#x27;chunked&amp;#x27;), (b&amp;#x27;Connection&amp;#x27;, b&amp;#x27;keep-alive&amp;#x27;), (b&amp;#x27;Cache-Control&amp;#x27;, b&amp;#x27;private, max-age=0, no-store, no-cache, must-revalidate&amp;#x27;), (b&amp;#x27;vary&amp;#x27;, b&amp;#x27;Origin&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-requests&amp;#x27;, b&amp;#x27;14400&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-tokens&amp;#x27;, b&amp;#x27;15000&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-requests&amp;#x27;, b&amp;#x27;14378&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-tokens&amp;#x27;, b&amp;#x27;14811&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-requests&amp;#x27;, b&amp;#x27;2m11.137999999s&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-tokens&amp;#x27;, b&amp;#x27;756ms&amp;#x27;), (b&amp;#x27;x-request-id&amp;#x27;, b&amp;#x27;req_01jbf23q8rf2387qmw9g3de5mr&amp;#x27;), (b&amp;#x27;via&amp;#x27;, b&amp;#x27;1.1 google&amp;#x27;), (b&amp;#x27;alt-svc&amp;#x27;, b&amp;#x27;h3=&amp;quot;:443&amp;quot;; ma=86400&amp;#x27;), (b&amp;#x27;CF-Cache-Status&amp;#x27;, b&amp;#x27;DYNAMIC&amp;#x27;), (b&amp;#x27;Server&amp;#x27;, b&amp;#x27;cloudflare&amp;#x27;), (b&amp;#x27;CF-RAY&amp;#x27;, b&amp;#x27;8dac943468f4ca58-HAM&amp;#x27;), (b&amp;#x27;Content-Encoding&amp;#x27;, b&amp;#x27;gzip&amp;#x27;)])\nINFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;HTTP/1.1 200 OK&amp;quot;\nDEBUG:httpcore.http11:receive_response_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.http11:receive_response_body.complete\nDEBUG:httpcore.http11:response_closed.started\nDEBUG:httpcore.http11:response_closed.complete\nDEBUG:groq._base_client:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;200 OK&amp;quot;\n\n------------------------------ Captured log call -------------------------------\nDEBUG    app:__init__.py:31 Headers: {&amp;#x27;User-Agent&amp;#x27;: &amp;#x27;Werkzeug/3.0.6&amp;#x27;, &amp;#x27;Host&amp;#x27;: &amp;#x27;localhost&amp;#x27;, &amp;#x27;Content-Type&amp;#x27;: &amp;#x27;application/json&amp;#x27;, &amp;#x27;Content-Length&amp;#x27;: &amp;#x27;35&amp;#x27;, &amp;#x27;Authorization&amp;#x27;: &amp;#x27;Bearer test_key&amp;#x27;}\nDEBUG    app:__init__.py:32 Body: b&amp;#x27;{&amp;quot;content&amp;quot;: &amp;quot;text&amp;quot;, &amp;quot;versions&amp;quot;: 10}&amp;#x27;\nDEBUG    app:__init__.py:33 Query Params: {}\nDEBUG    app:__init__.py:34 Route: POST /text/v1/compress/\nDEBUG    groq._base_client:_base_client.py:441 Request options: {&amp;#x27;method&amp;#x27;: &amp;#x27;post&amp;#x27;, &amp;#x27;url&amp;#x27;: &amp;#x27;/openai/v1/chat/completions&amp;#x27;, &amp;#x27;files&amp;#x27;: None, &amp;#x27;json_data&amp;#x27;: {&amp;#x27;messages&amp;#x27;: [{&amp;#x27;role&amp;#x27;: &amp;#x27;system&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate a JSON response following these rules:\\n1. Return multiple UNIQUE versions at the SAME length:\\n   {&amp;quot;versions&amp;quot;: [{&amp;quot;text&amp;quot;: &amp;quot;version1&amp;quot;}, {&amp;quot;text&amp;quot;: &amp;quot;version2&amp;quot;}]}\\n2. Each version must:\\n   - Target exactly the specified percentage\\n   - Use different sentence structures\\n   - Vary word choices while keeping technical terms\\n   - Maintain the same meaning\\n3. If task cannot be completed: {&amp;quot;error&amp;quot;: &amp;quot;specific reason&amp;quot;}&amp;#x27;}, {&amp;#x27;role&amp;#x27;: &amp;#x27;user&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate 5 UNIQUE versions at 20% length:\\n        - Each must be exactly the same length\\n        - Use different phrasings\\n        Original length: 1 tokens\\n        Original text: text&amp;#x27;}], &amp;#x27;model&amp;#x27;: &amp;#x27;llama3-groq-70b-8192-tool-use-preview&amp;#x27;, &amp;#x27;max_tokens&amp;#x27;: 1000, &amp;#x27;temperature&amp;#x27;: 0.7}}\nDEBUG    httpcore.http11:_trace.py:45 send_request_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 send_request_headers.complete\nDEBUG    httpcore.http11:_trace.py:45 send_request_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 send_request_body.complete\nDEBUG    httpcore.http11:_trace.py:45 receive_response_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 receive_response_headers.complete return_value=(b&amp;#x27;HTTP/1.1&amp;#x27;, 200, b&amp;#x27;OK&amp;#x27;, [(b&amp;#x27;Date&amp;#x27;, b&amp;#x27;Wed, 30 Oct 2024 15:53:34 GMT&amp;#x27;), (b&amp;#x27;Content-Type&amp;#x27;, b&amp;#x27;application/json&amp;#x27;), (b&amp;#x27;Transfer-Encoding&amp;#x27;, b&amp;#x27;chunked&amp;#x27;), (b&amp;#x27;Connection&amp;#x27;, b&amp;#x27;keep-alive&amp;#x27;), (b&amp;#x27;Cache-Control&amp;#x27;, b&amp;#x27;private, max-age=0, no-store, no-cache, must-revalidate&amp;#x27;), (b&amp;#x27;vary&amp;#x27;, b&amp;#x27;Origin&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-requests&amp;#x27;, b&amp;#x27;14400&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-tokens&amp;#x27;, b&amp;#x27;15000&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-requests&amp;#x27;, b&amp;#x27;14378&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-tokens&amp;#x27;, b&amp;#x27;14811&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-requests&amp;#x27;, b&amp;#x27;2m11.137999999s&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-tokens&amp;#x27;, b&amp;#x27;756ms&amp;#x27;), (b&amp;#x27;x-request-id&amp;#x27;, b&amp;#x27;req_01jbf23q8rf2387qmw9g3de5mr&amp;#x27;), (b&amp;#x27;via&amp;#x27;, b&amp;#x27;1.1 google&amp;#x27;), (b&amp;#x27;alt-svc&amp;#x27;, b&amp;#x27;h3=&amp;quot;:443&amp;quot;; ma=86400&amp;#x27;), (b&amp;#x27;CF-Cache-Status&amp;#x27;, b&amp;#x27;DYNAMIC&amp;#x27;), (b&amp;#x27;Server&amp;#x27;, b&amp;#x27;cloudflare&amp;#x27;), (b&amp;#x27;CF-RAY&amp;#x27;, b&amp;#x27;8dac943468f4ca58-HAM&amp;#x27;), (b&amp;#x27;Content-Encoding&amp;#x27;, b&amp;#x27;gzip&amp;#x27;)])\nINFO     httpx:_client.py:1038 HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;HTTP/1.1 200 OK&amp;quot;\nDEBUG    httpcore.http11:_trace.py:45 receive_response_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 receive_response_body.complete\nDEBUG    httpcore.http11:_trace.py:45 response_closed.started\nDEBUG    httpcore.http11:_trace.py:45 response_closed.complete\nDEBUG    groq._base_client:_base_client.py:956 HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;200 OK&amp;quot;\n\n&#34;}], &#34;tests/performance/test_compress_performance.py::TestCompressPerformance::test_invalid_inputs[invalid_input3]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Failed&#34;, &#34;testId&#34;: &#34;tests/performance/test_compress_performance.py::TestCompressPerformance::test_invalid_inputs[invalid_input3]&#34;, &#34;duration&#34;: &#34;802 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Failed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/performance/test_compress_performance.py::TestCompressPerformance::test_invalid_inputs[invalid_input3]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;802 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;self = &amp;lt;tests.performance.test_compress_performance.TestCompressPerformance object at 0x1069d0a40&amp;gt;\nclient = &amp;lt;FlaskClient &amp;lt;Flask &amp;#x27;app&amp;#x27;&amp;gt;&amp;gt;\nauth_headers = {&amp;#x27;Authorization&amp;#x27;: &amp;#x27;Bearer test_key&amp;#x27;, &amp;#x27;Content-Type&amp;#x27;: &amp;#x27;application/json&amp;#x27;}\ninvalid_input = {&amp;#x27;content&amp;#x27;: &amp;#x27;&amp;#x27;, &amp;#x27;target_percentage&amp;#x27;: 50}\n\n    @pytest.mark.unit\n    @pytest.mark.parametrize(&amp;#x27;invalid_input&amp;#x27;, [\n        {&amp;#x27;content&amp;#x27;: &amp;quot;text&amp;quot;, &amp;#x27;target_percentage&amp;#x27;: 150},  # Invalid percentage\n        {&amp;#x27;content&amp;#x27;: &amp;quot;text&amp;quot;, &amp;#x27;steps_percentage&amp;#x27;: -10},   # Negative steps\n        {&amp;#x27;content&amp;#x27;: &amp;quot;text&amp;quot;, &amp;#x27;versions&amp;#x27;: 10},            # Too many versions\n        {&amp;#x27;content&amp;#x27;: &amp;quot;&amp;quot;, &amp;#x27;target_percentage&amp;#x27;: 50},       # Empty content\n        {&amp;#x27;target_percentage&amp;#x27;: 50},                      # Missing content\n    ])\n    def test_invalid_inputs(self, client, auth_headers, invalid_input):\n        response = client.post(\n            self.ENDPOINTS[&amp;#x27;compress&amp;#x27;], json=invalid_input, headers=auth_headers)\n&amp;gt;       assert response.status_code == 400\nE       assert 500 == 400\nE        +  where 500 = &amp;lt;WrapperTestResponse streamed [500 INTERNAL SERVER ERROR]&amp;gt;.status_code\n\ntests/test_compress.py:139: AssertionError\n\n---------------------------- Captured stderr setup -----------------------------\nDEBUG:app:Registering blueprints...\nDEBUG:app:Registered routes:\nDEBUG:app:static: /static/&amp;lt;path:filename&amp;gt; [GET, OPTIONS, HEAD]\nDEBUG:app:generate.create_text: /text/v1/generate/text [OPTIONS, POST]\nDEBUG:app:compress.compress_text: /text/v1/compress/ [OPTIONS, POST]\nDEBUG:app:expand.expand_text: /text/v1/expand/ [OPTIONS, POST]\n\n------------------------------ Captured log setup ------------------------------\nDEBUG    app:__init__.py:106 Registering blueprints...\nDEBUG    app:__init__.py:112 Registered routes:\nDEBUG    app:__init__.py:114 static: /static/&amp;lt;path:filename&amp;gt; [GET, OPTIONS, HEAD]\nDEBUG    app:__init__.py:114 generate.create_text: /text/v1/generate/text [OPTIONS, POST]\nDEBUG    app:__init__.py:114 compress.compress_text: /text/v1/compress/ [OPTIONS, POST]\nDEBUG    app:__init__.py:114 expand.expand_text: /text/v1/expand/ [OPTIONS, POST]\n\n----------------------------- Captured stderr call -----------------------------\nDEBUG:app:Headers: {&amp;#x27;User-Agent&amp;#x27;: &amp;#x27;Werkzeug/3.0.6&amp;#x27;, &amp;#x27;Host&amp;#x27;: &amp;#x27;localhost&amp;#x27;, &amp;#x27;Content-Type&amp;#x27;: &amp;#x27;application/json&amp;#x27;, &amp;#x27;Content-Length&amp;#x27;: &amp;#x27;40&amp;#x27;, &amp;#x27;Authorization&amp;#x27;: &amp;#x27;Bearer test_key&amp;#x27;}\nDEBUG:app:Body: b&amp;#x27;{&amp;quot;content&amp;quot;: &amp;quot;&amp;quot;, &amp;quot;target_percentage&amp;quot;: 50}&amp;#x27;\nDEBUG:app:Query Params: {}\nDEBUG:app:Route: POST /text/v1/compress/\nDEBUG:groq._base_client:Request options: {&amp;#x27;method&amp;#x27;: &amp;#x27;post&amp;#x27;, &amp;#x27;url&amp;#x27;: &amp;#x27;/openai/v1/chat/completions&amp;#x27;, &amp;#x27;files&amp;#x27;: None, &amp;#x27;json_data&amp;#x27;: {&amp;#x27;messages&amp;#x27;: [{&amp;#x27;role&amp;#x27;: &amp;#x27;system&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate a JSON response following these rules:\\n1. Return exactly ONE compressed version:\\n   {&amp;quot;versions&amp;quot;: [{&amp;quot;text&amp;quot;: &amp;quot;compressed version&amp;quot;}]}\\n2. Target exactly the specified percentage of original length\\n3. Maintain core meaning while removing less essential details\\n4. Ensure complete sentences and proper punctuation\\n5. If task cannot be completed: {&amp;quot;error&amp;quot;: &amp;quot;specific reason&amp;quot;}&amp;#x27;}, {&amp;#x27;role&amp;#x27;: &amp;#x27;user&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate ONE compressed version at 50% length:\\n        Original length: 0 tokens\\n        Original text: &amp;#x27;}], &amp;#x27;model&amp;#x27;: &amp;#x27;llama3-groq-70b-8192-tool-use-preview&amp;#x27;, &amp;#x27;max_tokens&amp;#x27;: 1000, &amp;#x27;temperature&amp;#x27;: 0.7}}\nDEBUG:httpcore.http11:send_request_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.http11:send_request_headers.complete\nDEBUG:httpcore.http11:send_request_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.http11:send_request_body.complete\nDEBUG:httpcore.http11:receive_response_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.http11:receive_response_headers.complete return_value=(b&amp;#x27;HTTP/1.1&amp;#x27;, 200, b&amp;#x27;OK&amp;#x27;, [(b&amp;#x27;Date&amp;#x27;, b&amp;#x27;Wed, 30 Oct 2024 15:53:35 GMT&amp;#x27;), (b&amp;#x27;Content-Type&amp;#x27;, b&amp;#x27;application/json&amp;#x27;), (b&amp;#x27;Transfer-Encoding&amp;#x27;, b&amp;#x27;chunked&amp;#x27;), (b&amp;#x27;Connection&amp;#x27;, b&amp;#x27;keep-alive&amp;#x27;), (b&amp;#x27;Cache-Control&amp;#x27;, b&amp;#x27;private, max-age=0, no-store, no-cache, must-revalidate&amp;#x27;), (b&amp;#x27;vary&amp;#x27;, b&amp;#x27;Origin&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-requests&amp;#x27;, b&amp;#x27;14400&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-tokens&amp;#x27;, b&amp;#x27;15000&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-requests&amp;#x27;, b&amp;#x27;14377&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-tokens&amp;#x27;, b&amp;#x27;14848&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-requests&amp;#x27;, b&amp;#x27;2m17.057s&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-tokens&amp;#x27;, b&amp;#x27;607ms&amp;#x27;), (b&amp;#x27;x-request-id&amp;#x27;, b&amp;#x27;req_01jbf23r69f49vc20xycxpketd&amp;#x27;), (b&amp;#x27;via&amp;#x27;, b&amp;#x27;1.1 google&amp;#x27;), (b&amp;#x27;alt-svc&amp;#x27;, b&amp;#x27;h3=&amp;quot;:443&amp;quot;; ma=86400&amp;#x27;), (b&amp;#x27;CF-Cache-Status&amp;#x27;, b&amp;#x27;DYNAMIC&amp;#x27;), (b&amp;#x27;Server&amp;#x27;, b&amp;#x27;cloudflare&amp;#x27;), (b&amp;#x27;CF-RAY&amp;#x27;, b&amp;#x27;8dac943a5fdaca58-HAM&amp;#x27;), (b&amp;#x27;Content-Encoding&amp;#x27;, b&amp;#x27;gzip&amp;#x27;)])\nINFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;HTTP/1.1 200 OK&amp;quot;\nDEBUG:httpcore.http11:receive_response_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.http11:receive_response_body.complete\nDEBUG:httpcore.http11:response_closed.started\nDEBUG:httpcore.http11:response_closed.complete\nDEBUG:groq._base_client:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;200 OK&amp;quot;\n\n------------------------------ Captured log call -------------------------------\nDEBUG    app:__init__.py:31 Headers: {&amp;#x27;User-Agent&amp;#x27;: &amp;#x27;Werkzeug/3.0.6&amp;#x27;, &amp;#x27;Host&amp;#x27;: &amp;#x27;localhost&amp;#x27;, &amp;#x27;Content-Type&amp;#x27;: &amp;#x27;application/json&amp;#x27;, &amp;#x27;Content-Length&amp;#x27;: &amp;#x27;40&amp;#x27;, &amp;#x27;Authorization&amp;#x27;: &amp;#x27;Bearer test_key&amp;#x27;}\nDEBUG    app:__init__.py:32 Body: b&amp;#x27;{&amp;quot;content&amp;quot;: &amp;quot;&amp;quot;, &amp;quot;target_percentage&amp;quot;: 50}&amp;#x27;\nDEBUG    app:__init__.py:33 Query Params: {}\nDEBUG    app:__init__.py:34 Route: POST /text/v1/compress/\nDEBUG    groq._base_client:_base_client.py:441 Request options: {&amp;#x27;method&amp;#x27;: &amp;#x27;post&amp;#x27;, &amp;#x27;url&amp;#x27;: &amp;#x27;/openai/v1/chat/completions&amp;#x27;, &amp;#x27;files&amp;#x27;: None, &amp;#x27;json_data&amp;#x27;: {&amp;#x27;messages&amp;#x27;: [{&amp;#x27;role&amp;#x27;: &amp;#x27;system&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate a JSON response following these rules:\\n1. Return exactly ONE compressed version:\\n   {&amp;quot;versions&amp;quot;: [{&amp;quot;text&amp;quot;: &amp;quot;compressed version&amp;quot;}]}\\n2. Target exactly the specified percentage of original length\\n3. Maintain core meaning while removing less essential details\\n4. Ensure complete sentences and proper punctuation\\n5. If task cannot be completed: {&amp;quot;error&amp;quot;: &amp;quot;specific reason&amp;quot;}&amp;#x27;}, {&amp;#x27;role&amp;#x27;: &amp;#x27;user&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate ONE compressed version at 50% length:\\n        Original length: 0 tokens\\n        Original text: &amp;#x27;}], &amp;#x27;model&amp;#x27;: &amp;#x27;llama3-groq-70b-8192-tool-use-preview&amp;#x27;, &amp;#x27;max_tokens&amp;#x27;: 1000, &amp;#x27;temperature&amp;#x27;: 0.7}}\nDEBUG    httpcore.http11:_trace.py:45 send_request_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 send_request_headers.complete\nDEBUG    httpcore.http11:_trace.py:45 send_request_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 send_request_body.complete\nDEBUG    httpcore.http11:_trace.py:45 receive_response_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 receive_response_headers.complete return_value=(b&amp;#x27;HTTP/1.1&amp;#x27;, 200, b&amp;#x27;OK&amp;#x27;, [(b&amp;#x27;Date&amp;#x27;, b&amp;#x27;Wed, 30 Oct 2024 15:53:35 GMT&amp;#x27;), (b&amp;#x27;Content-Type&amp;#x27;, b&amp;#x27;application/json&amp;#x27;), (b&amp;#x27;Transfer-Encoding&amp;#x27;, b&amp;#x27;chunked&amp;#x27;), (b&amp;#x27;Connection&amp;#x27;, b&amp;#x27;keep-alive&amp;#x27;), (b&amp;#x27;Cache-Control&amp;#x27;, b&amp;#x27;private, max-age=0, no-store, no-cache, must-revalidate&amp;#x27;), (b&amp;#x27;vary&amp;#x27;, b&amp;#x27;Origin&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-requests&amp;#x27;, b&amp;#x27;14400&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-tokens&amp;#x27;, b&amp;#x27;15000&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-requests&amp;#x27;, b&amp;#x27;14377&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-tokens&amp;#x27;, b&amp;#x27;14848&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-requests&amp;#x27;, b&amp;#x27;2m17.057s&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-tokens&amp;#x27;, b&amp;#x27;607ms&amp;#x27;), (b&amp;#x27;x-request-id&amp;#x27;, b&amp;#x27;req_01jbf23r69f49vc20xycxpketd&amp;#x27;), (b&amp;#x27;via&amp;#x27;, b&amp;#x27;1.1 google&amp;#x27;), (b&amp;#x27;alt-svc&amp;#x27;, b&amp;#x27;h3=&amp;quot;:443&amp;quot;; ma=86400&amp;#x27;), (b&amp;#x27;CF-Cache-Status&amp;#x27;, b&amp;#x27;DYNAMIC&amp;#x27;), (b&amp;#x27;Server&amp;#x27;, b&amp;#x27;cloudflare&amp;#x27;), (b&amp;#x27;CF-RAY&amp;#x27;, b&amp;#x27;8dac943a5fdaca58-HAM&amp;#x27;), (b&amp;#x27;Content-Encoding&amp;#x27;, b&amp;#x27;gzip&amp;#x27;)])\nINFO     httpx:_client.py:1038 HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;HTTP/1.1 200 OK&amp;quot;\nDEBUG    httpcore.http11:_trace.py:45 receive_response_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 receive_response_body.complete\nDEBUG    httpcore.http11:_trace.py:45 response_closed.started\nDEBUG    httpcore.http11:_trace.py:45 response_closed.complete\nDEBUG    groq._base_client:_base_client.py:956 HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;200 OK&amp;quot;\n\n&#34;}], &#34;tests/performance/test_compress_performance.py::TestCompressPerformance::test_invalid_inputs[invalid_input4]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Failed&#34;, &#34;testId&#34;: &#34;tests/performance/test_compress_performance.py::TestCompressPerformance::test_invalid_inputs[invalid_input4]&#34;, &#34;duration&#34;: &#34;513 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Failed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/performance/test_compress_performance.py::TestCompressPerformance::test_invalid_inputs[invalid_input4]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;513 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;self = &amp;lt;tests.performance.test_compress_performance.TestCompressPerformance object at 0x1069d0ad0&amp;gt;\nclient = &amp;lt;FlaskClient &amp;lt;Flask &amp;#x27;app&amp;#x27;&amp;gt;&amp;gt;\nauth_headers = {&amp;#x27;Authorization&amp;#x27;: &amp;#x27;Bearer test_key&amp;#x27;, &amp;#x27;Content-Type&amp;#x27;: &amp;#x27;application/json&amp;#x27;}\ninvalid_input = {&amp;#x27;target_percentage&amp;#x27;: 50}\n\n    @pytest.mark.unit\n    @pytest.mark.parametrize(&amp;#x27;invalid_input&amp;#x27;, [\n        {&amp;#x27;content&amp;#x27;: &amp;quot;text&amp;quot;, &amp;#x27;target_percentage&amp;#x27;: 150},  # Invalid percentage\n        {&amp;#x27;content&amp;#x27;: &amp;quot;text&amp;quot;, &amp;#x27;steps_percentage&amp;#x27;: -10},   # Negative steps\n        {&amp;#x27;content&amp;#x27;: &amp;quot;text&amp;quot;, &amp;#x27;versions&amp;#x27;: 10},            # Too many versions\n        {&amp;#x27;content&amp;#x27;: &amp;quot;&amp;quot;, &amp;#x27;target_percentage&amp;#x27;: 50},       # Empty content\n        {&amp;#x27;target_percentage&amp;#x27;: 50},                      # Missing content\n    ])\n    def test_invalid_inputs(self, client, auth_headers, invalid_input):\n        response = client.post(\n            self.ENDPOINTS[&amp;#x27;compress&amp;#x27;], json=invalid_input, headers=auth_headers)\n&amp;gt;       assert response.status_code == 400\nE       assert 500 == 400\nE        +  where 500 = &amp;lt;WrapperTestResponse streamed [500 INTERNAL SERVER ERROR]&amp;gt;.status_code\n\ntests/test_compress.py:139: AssertionError\n\n---------------------------- Captured stderr setup -----------------------------\nDEBUG:app:Registering blueprints...\nDEBUG:app:Registered routes:\nDEBUG:app:static: /static/&amp;lt;path:filename&amp;gt; [GET, OPTIONS, HEAD]\nDEBUG:app:generate.create_text: /text/v1/generate/text [OPTIONS, POST]\nDEBUG:app:compress.compress_text: /text/v1/compress/ [OPTIONS, POST]\nDEBUG:app:expand.expand_text: /text/v1/expand/ [OPTIONS, POST]\n\n------------------------------ Captured log setup ------------------------------\nDEBUG    app:__init__.py:106 Registering blueprints...\nDEBUG    app:__init__.py:112 Registered routes:\nDEBUG    app:__init__.py:114 static: /static/&amp;lt;path:filename&amp;gt; [GET, OPTIONS, HEAD]\nDEBUG    app:__init__.py:114 generate.create_text: /text/v1/generate/text [OPTIONS, POST]\nDEBUG    app:__init__.py:114 compress.compress_text: /text/v1/compress/ [OPTIONS, POST]\nDEBUG    app:__init__.py:114 expand.expand_text: /text/v1/expand/ [OPTIONS, POST]\n\n----------------------------- Captured stderr call -----------------------------\nDEBUG:app:Headers: {&amp;#x27;User-Agent&amp;#x27;: &amp;#x27;Werkzeug/3.0.6&amp;#x27;, &amp;#x27;Host&amp;#x27;: &amp;#x27;localhost&amp;#x27;, &amp;#x27;Content-Type&amp;#x27;: &amp;#x27;application/json&amp;#x27;, &amp;#x27;Content-Length&amp;#x27;: &amp;#x27;25&amp;#x27;, &amp;#x27;Authorization&amp;#x27;: &amp;#x27;Bearer test_key&amp;#x27;}\nDEBUG:app:Body: b&amp;#x27;{&amp;quot;target_percentage&amp;quot;: 50}&amp;#x27;\nDEBUG:app:Query Params: {}\nDEBUG:app:Route: POST /text/v1/compress/\n\n------------------------------ Captured log call -------------------------------\nDEBUG    app:__init__.py:31 Headers: {&amp;#x27;User-Agent&amp;#x27;: &amp;#x27;Werkzeug/3.0.6&amp;#x27;, &amp;#x27;Host&amp;#x27;: &amp;#x27;localhost&amp;#x27;, &amp;#x27;Content-Type&amp;#x27;: &amp;#x27;application/json&amp;#x27;, &amp;#x27;Content-Length&amp;#x27;: &amp;#x27;25&amp;#x27;, &amp;#x27;Authorization&amp;#x27;: &amp;#x27;Bearer test_key&amp;#x27;}\nDEBUG    app:__init__.py:32 Body: b&amp;#x27;{&amp;quot;target_percentage&amp;quot;: 50}&amp;#x27;\nDEBUG    app:__init__.py:33 Query Params: {}\nDEBUG    app:__init__.py:34 Route: POST /text/v1/compress/\n\n&#34;}], &#34;tests/performance/test_compress_performance.py::TestCompressPerformance::test_length_validation&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Failed&#34;, &#34;testId&#34;: &#34;tests/performance/test_compress_performance.py::TestCompressPerformance::test_length_validation&#34;, &#34;duration&#34;: &#34;868 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Failed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/performance/test_compress_performance.py::TestCompressPerformance::test_length_validation&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;868 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;self = &amp;lt;tests.performance.test_compress_performance.TestCompressPerformance object at 0x1069d0740&amp;gt;\nclient = &amp;lt;FlaskClient &amp;lt;Flask &amp;#x27;app&amp;#x27;&amp;gt;&amp;gt;\nauth_headers = {&amp;#x27;Authorization&amp;#x27;: &amp;#x27;Bearer test_key&amp;#x27;, &amp;#x27;Content-Type&amp;#x27;: &amp;#x27;application/json&amp;#x27;}\n\n    @pytest.mark.unit\n    def test_length_validation(self, client, auth_headers):\n        &amp;quot;&amp;quot;&amp;quot;Test if compressed versions roughly match target percentages&amp;quot;&amp;quot;&amp;quot;\n        response = client.post(self.ENDPOINTS[&amp;#x27;compress&amp;#x27;], json={\n            &amp;#x27;content&amp;#x27;: self.SAMPLE_TEXT,\n            &amp;#x27;target_percentage&amp;#x27;: 50,\n            &amp;#x27;versions&amp;#x27;: 1\n        }, headers=auth_headers)\n    \n        data = response.json\n        original_length = len(self.SAMPLE_TEXT)\n        compressed_length = len(data[&amp;#x27;versions&amp;#x27;][0][&amp;#x27;text&amp;#x27;])\n        # Allow 10% margin of error\n&amp;gt;       assert abs(compressed_length/original_length - 0.5) &amp;lt;= 0.1\nE       assert 0.2142857142857143 &amp;lt;= 0.1\nE        +  where 0.2142857142857143 = abs(((150 / 210) - 0.5))\n\ntests/test_compress.py:155: AssertionError\n\n---------------------------- Captured stderr setup -----------------------------\nDEBUG:app:Registering blueprints...\nDEBUG:app:Registered routes:\nDEBUG:app:static: /static/&amp;lt;path:filename&amp;gt; [GET, OPTIONS, HEAD]\nDEBUG:app:generate.create_text: /text/v1/generate/text [OPTIONS, POST]\nDEBUG:app:compress.compress_text: /text/v1/compress/ [OPTIONS, POST]\nDEBUG:app:expand.expand_text: /text/v1/expand/ [OPTIONS, POST]\n\n------------------------------ Captured log setup ------------------------------\nDEBUG    app:__init__.py:106 Registering blueprints...\nDEBUG    app:__init__.py:112 Registered routes:\nDEBUG    app:__init__.py:114 static: /static/&amp;lt;path:filename&amp;gt; [GET, OPTIONS, HEAD]\nDEBUG    app:__init__.py:114 generate.create_text: /text/v1/generate/text [OPTIONS, POST]\nDEBUG    app:__init__.py:114 compress.compress_text: /text/v1/compress/ [OPTIONS, POST]\nDEBUG    app:__init__.py:114 expand.expand_text: /text/v1/expand/ [OPTIONS, POST]\n\n----------------------------- Captured stderr call -----------------------------\nDEBUG:app:Headers: {&amp;#x27;User-Agent&amp;#x27;: &amp;#x27;Werkzeug/3.0.6&amp;#x27;, &amp;#x27;Host&amp;#x27;: &amp;#x27;localhost&amp;#x27;, &amp;#x27;Content-Type&amp;#x27;: &amp;#x27;application/json&amp;#x27;, &amp;#x27;Content-Length&amp;#x27;: &amp;#x27;265&amp;#x27;, &amp;#x27;Authorization&amp;#x27;: &amp;#x27;Bearer test_key&amp;#x27;}\nDEBUG:app:Body: b&amp;#x27;{&amp;quot;content&amp;quot;: &amp;quot;The Text Transformation API offers a robust set of REST endpoints that enable developers to programmatically manipulate and transform text content. The operations include expansion, summarization, and chunking.&amp;quot;, &amp;quot;target_percentage&amp;quot;: 50, &amp;quot;versions&amp;quot;: 1}&amp;#x27;\nDEBUG:app:Query Params: {}\nDEBUG:app:Route: POST /text/v1/compress/\nDEBUG:groq._base_client:Request options: {&amp;#x27;method&amp;#x27;: &amp;#x27;post&amp;#x27;, &amp;#x27;url&amp;#x27;: &amp;#x27;/openai/v1/chat/completions&amp;#x27;, &amp;#x27;files&amp;#x27;: None, &amp;#x27;json_data&amp;#x27;: {&amp;#x27;messages&amp;#x27;: [{&amp;#x27;role&amp;#x27;: &amp;#x27;system&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate a JSON response following these rules:\\n1. Return exactly ONE compressed version:\\n   {&amp;quot;versions&amp;quot;: [{&amp;quot;text&amp;quot;: &amp;quot;compressed version&amp;quot;}]}\\n2. Target exactly the specified percentage of original length\\n3. Maintain core meaning while removing less essential details\\n4. Ensure complete sentences and proper punctuation\\n5. If task cannot be completed: {&amp;quot;error&amp;quot;: &amp;quot;specific reason&amp;quot;}&amp;#x27;}, {&amp;#x27;role&amp;#x27;: &amp;#x27;user&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate ONE compressed version at 50% length:\\n        Original length: 35 tokens\\n        Original text: The Text Transformation API offers a robust set of REST endpoints that enable developers to programmatically manipulate and transform text content. The operations include expansion, summarization, and chunking.&amp;#x27;}], &amp;#x27;model&amp;#x27;: &amp;#x27;llama3-groq-70b-8192-tool-use-preview&amp;#x27;, &amp;#x27;max_tokens&amp;#x27;: 1000, &amp;#x27;temperature&amp;#x27;: 0.7}}\nDEBUG:httpcore.http11:send_request_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.http11:send_request_headers.complete\nDEBUG:httpcore.http11:send_request_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.http11:send_request_body.complete\nDEBUG:httpcore.http11:receive_response_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.http11:receive_response_headers.complete return_value=(b&amp;#x27;HTTP/1.1&amp;#x27;, 200, b&amp;#x27;OK&amp;#x27;, [(b&amp;#x27;Date&amp;#x27;, b&amp;#x27;Wed, 30 Oct 2024 15:53:36 GMT&amp;#x27;), (b&amp;#x27;Content-Type&amp;#x27;, b&amp;#x27;application/json&amp;#x27;), (b&amp;#x27;Transfer-Encoding&amp;#x27;, b&amp;#x27;chunked&amp;#x27;), (b&amp;#x27;Connection&amp;#x27;, b&amp;#x27;keep-alive&amp;#x27;), (b&amp;#x27;Cache-Control&amp;#x27;, b&amp;#x27;private, max-age=0, no-store, no-cache, must-revalidate&amp;#x27;), (b&amp;#x27;vary&amp;#x27;, b&amp;#x27;Origin&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-requests&amp;#x27;, b&amp;#x27;14400&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-tokens&amp;#x27;, b&amp;#x27;15000&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-requests&amp;#x27;, b&amp;#x27;14376&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-tokens&amp;#x27;, b&amp;#x27;14818&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-requests&amp;#x27;, b&amp;#x27;2m22.67s&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-tokens&amp;#x27;, b&amp;#x27;728ms&amp;#x27;), (b&amp;#x27;x-request-id&amp;#x27;, b&amp;#x27;req_01jbf23sfwf1gv3x9vhb4wv0wv&amp;#x27;), (b&amp;#x27;via&amp;#x27;, b&amp;#x27;1.1 google&amp;#x27;), (b&amp;#x27;alt-svc&amp;#x27;, b&amp;#x27;h3=&amp;quot;:443&amp;quot;; ma=86400&amp;#x27;), (b&amp;#x27;CF-Cache-Status&amp;#x27;, b&amp;#x27;DYNAMIC&amp;#x27;), (b&amp;#x27;Server&amp;#x27;, b&amp;#x27;cloudflare&amp;#x27;), (b&amp;#x27;CF-RAY&amp;#x27;, b&amp;#x27;8dac94429a29ca58-HAM&amp;#x27;), (b&amp;#x27;Content-Encoding&amp;#x27;, b&amp;#x27;gzip&amp;#x27;)])\nINFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;HTTP/1.1 200 OK&amp;quot;\nDEBUG:httpcore.http11:receive_response_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.http11:receive_response_body.complete\nDEBUG:httpcore.http11:response_closed.started\nDEBUG:httpcore.http11:response_closed.complete\nDEBUG:groq._base_client:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;200 OK&amp;quot;\n\n------------------------------ Captured log call -------------------------------\nDEBUG    app:__init__.py:31 Headers: {&amp;#x27;User-Agent&amp;#x27;: &amp;#x27;Werkzeug/3.0.6&amp;#x27;, &amp;#x27;Host&amp;#x27;: &amp;#x27;localhost&amp;#x27;, &amp;#x27;Content-Type&amp;#x27;: &amp;#x27;application/json&amp;#x27;, &amp;#x27;Content-Length&amp;#x27;: &amp;#x27;265&amp;#x27;, &amp;#x27;Authorization&amp;#x27;: &amp;#x27;Bearer test_key&amp;#x27;}\nDEBUG    app:__init__.py:32 Body: b&amp;#x27;{&amp;quot;content&amp;quot;: &amp;quot;The Text Transformation API offers a robust set of REST endpoints that enable developers to programmatically manipulate and transform text content. The operations include expansion, summarization, and chunking.&amp;quot;, &amp;quot;target_percentage&amp;quot;: 50, &amp;quot;versions&amp;quot;: 1}&amp;#x27;\nDEBUG    app:__init__.py:33 Query Params: {}\nDEBUG    app:__init__.py:34 Route: POST /text/v1/compress/\nDEBUG    groq._base_client:_base_client.py:441 Request options: {&amp;#x27;method&amp;#x27;: &amp;#x27;post&amp;#x27;, &amp;#x27;url&amp;#x27;: &amp;#x27;/openai/v1/chat/completions&amp;#x27;, &amp;#x27;files&amp;#x27;: None, &amp;#x27;json_data&amp;#x27;: {&amp;#x27;messages&amp;#x27;: [{&amp;#x27;role&amp;#x27;: &amp;#x27;system&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate a JSON response following these rules:\\n1. Return exactly ONE compressed version:\\n   {&amp;quot;versions&amp;quot;: [{&amp;quot;text&amp;quot;: &amp;quot;compressed version&amp;quot;}]}\\n2. Target exactly the specified percentage of original length\\n3. Maintain core meaning while removing less essential details\\n4. Ensure complete sentences and proper punctuation\\n5. If task cannot be completed: {&amp;quot;error&amp;quot;: &amp;quot;specific reason&amp;quot;}&amp;#x27;}, {&amp;#x27;role&amp;#x27;: &amp;#x27;user&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate ONE compressed version at 50% length:\\n        Original length: 35 tokens\\n        Original text: The Text Transformation API offers a robust set of REST endpoints that enable developers to programmatically manipulate and transform text content. The operations include expansion, summarization, and chunking.&amp;#x27;}], &amp;#x27;model&amp;#x27;: &amp;#x27;llama3-groq-70b-8192-tool-use-preview&amp;#x27;, &amp;#x27;max_tokens&amp;#x27;: 1000, &amp;#x27;temperature&amp;#x27;: 0.7}}\nDEBUG    httpcore.http11:_trace.py:45 send_request_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 send_request_headers.complete\nDEBUG    httpcore.http11:_trace.py:45 send_request_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 send_request_body.complete\nDEBUG    httpcore.http11:_trace.py:45 receive_response_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 receive_response_headers.complete return_value=(b&amp;#x27;HTTP/1.1&amp;#x27;, 200, b&amp;#x27;OK&amp;#x27;, [(b&amp;#x27;Date&amp;#x27;, b&amp;#x27;Wed, 30 Oct 2024 15:53:36 GMT&amp;#x27;), (b&amp;#x27;Content-Type&amp;#x27;, b&amp;#x27;application/json&amp;#x27;), (b&amp;#x27;Transfer-Encoding&amp;#x27;, b&amp;#x27;chunked&amp;#x27;), (b&amp;#x27;Connection&amp;#x27;, b&amp;#x27;keep-alive&amp;#x27;), (b&amp;#x27;Cache-Control&amp;#x27;, b&amp;#x27;private, max-age=0, no-store, no-cache, must-revalidate&amp;#x27;), (b&amp;#x27;vary&amp;#x27;, b&amp;#x27;Origin&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-requests&amp;#x27;, b&amp;#x27;14400&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-tokens&amp;#x27;, b&amp;#x27;15000&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-requests&amp;#x27;, b&amp;#x27;14376&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-tokens&amp;#x27;, b&amp;#x27;14818&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-requests&amp;#x27;, b&amp;#x27;2m22.67s&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-tokens&amp;#x27;, b&amp;#x27;728ms&amp;#x27;), (b&amp;#x27;x-request-id&amp;#x27;, b&amp;#x27;req_01jbf23sfwf1gv3x9vhb4wv0wv&amp;#x27;), (b&amp;#x27;via&amp;#x27;, b&amp;#x27;1.1 google&amp;#x27;), (b&amp;#x27;alt-svc&amp;#x27;, b&amp;#x27;h3=&amp;quot;:443&amp;quot;; ma=86400&amp;#x27;), (b&amp;#x27;CF-Cache-Status&amp;#x27;, b&amp;#x27;DYNAMIC&amp;#x27;), (b&amp;#x27;Server&amp;#x27;, b&amp;#x27;cloudflare&amp;#x27;), (b&amp;#x27;CF-RAY&amp;#x27;, b&amp;#x27;8dac94429a29ca58-HAM&amp;#x27;), (b&amp;#x27;Content-Encoding&amp;#x27;, b&amp;#x27;gzip&amp;#x27;)])\nINFO     httpx:_client.py:1038 HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;HTTP/1.1 200 OK&amp;quot;\nDEBUG    httpcore.http11:_trace.py:45 receive_response_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 receive_response_body.complete\nDEBUG    httpcore.http11:_trace.py:45 response_closed.started\nDEBUG    httpcore.http11:_trace.py:45 response_closed.complete\nDEBUG    groq._base_client:_base_client.py:956 HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;200 OK&amp;quot;\n\n&#34;}], &#34;tests/performance/test_compress_performance.py::TestCompressPerformance::test_response_time&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Failed&#34;, &#34;testId&#34;: &#34;tests/performance/test_compress_performance.py::TestCompressPerformance::test_response_time&#34;, &#34;duration&#34;: &#34;00:00:04&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Failed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/performance/test_compress_performance.py::TestCompressPerformance::test_response_time&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:04&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;self = &amp;lt;tests.performance.test_compress_performance.TestCompressPerformance object at 0x106953c20&amp;gt;\nclient = &amp;lt;FlaskClient &amp;lt;Flask &amp;#x27;app&amp;#x27;&amp;gt;&amp;gt;\nauth_headers = {&amp;#x27;Authorization&amp;#x27;: &amp;#x27;Bearer test_key&amp;#x27;, &amp;#x27;Content-Type&amp;#x27;: &amp;#x27;application/json&amp;#x27;}\n\n    def test_response_time(self, client, auth_headers):\n        start_time = time.time()\n        response = client.post(self.ENDPOINTS[&amp;#x27;compress&amp;#x27;], json={\n            &amp;#x27;content&amp;#x27;: &amp;quot;A&amp;quot; * 1000,  # 1000 character text\n            &amp;#x27;target_percentage&amp;#x27;: 50\n        }, headers=auth_headers)\n        duration = time.time() - start_time\n    \n&amp;gt;       assert duration &amp;lt; 2.0  # Should respond within 2 seconds\nE       assert 3.5081489086151123 &amp;lt; 2.0\n\ntests/performance/test_compress_performance.py:17: AssertionError\n\n---------------------------- Captured stderr setup -----------------------------\nDEBUG:app:Registering blueprints...\nDEBUG:app:Registered routes:\nDEBUG:app:static: /static/&amp;lt;path:filename&amp;gt; [GET, OPTIONS, HEAD]\nDEBUG:app:generate.create_text: /text/v1/generate/text [OPTIONS, POST]\nDEBUG:app:compress.compress_text: /text/v1/compress/ [OPTIONS, POST]\nDEBUG:app:expand.expand_text: /text/v1/expand/ [OPTIONS, POST]\n\n------------------------------ Captured log setup ------------------------------\nDEBUG    app:__init__.py:106 Registering blueprints...\nDEBUG    app:__init__.py:112 Registered routes:\nDEBUG    app:__init__.py:114 static: /static/&amp;lt;path:filename&amp;gt; [GET, OPTIONS, HEAD]\nDEBUG    app:__init__.py:114 generate.create_text: /text/v1/generate/text [OPTIONS, POST]\nDEBUG    app:__init__.py:114 compress.compress_text: /text/v1/compress/ [OPTIONS, POST]\nDEBUG    app:__init__.py:114 expand.expand_text: /text/v1/expand/ [OPTIONS, POST]\n\n----------------------------- Captured stderr call -----------------------------\nDEBUG:app:Headers: {&amp;#x27;User-Agent&amp;#x27;: &amp;#x27;Werkzeug/3.0.6&amp;#x27;, &amp;#x27;Host&amp;#x27;: &amp;#x27;localhost&amp;#x27;, &amp;#x27;Content-Type&amp;#x27;: &amp;#x27;application/json&amp;#x27;, &amp;#x27;Content-Length&amp;#x27;: &amp;#x27;1040&amp;#x27;, &amp;#x27;Authorization&amp;#x27;: &amp;#x27;Bearer test_key&amp;#x27;}\nDEBUG:app:Body: b&amp;#x27;{&amp;quot;content&amp;quot;: &amp;quot;AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA&amp;quot;, &amp;quot;target_percentage&amp;quot;: 50}&amp;#x27;\nDEBUG:app:Query Params: {}\nDEBUG:app:Route: POST /text/v1/compress/\nDEBUG:groq._base_client:Request options: {&amp;#x27;method&amp;#x27;: &amp;#x27;post&amp;#x27;, &amp;#x27;url&amp;#x27;: &amp;#x27;/openai/v1/chat/completions&amp;#x27;, &amp;#x27;files&amp;#x27;: None, &amp;#x27;json_data&amp;#x27;: {&amp;#x27;messages&amp;#x27;: [{&amp;#x27;role&amp;#x27;: &amp;#x27;system&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate a JSON response following these rules:\\n1. Return exactly ONE compressed version:\\n   {&amp;quot;versions&amp;quot;: [{&amp;quot;text&amp;quot;: &amp;quot;compressed version&amp;quot;}]}\\n2. Target exactly the specified percentage of original length\\n3. Maintain core meaning while removing less essential details\\n4. Ensure complete sentences and proper punctuation\\n5. If task cannot be completed: {&amp;quot;error&amp;quot;: &amp;quot;specific reason&amp;quot;}&amp;#x27;}, {&amp;#x27;role&amp;#x27;: &amp;#x27;user&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate ONE compressed version at 50% length:\\n        Original length: 125 tokens\\n        Original text: AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA&amp;#x27;}], &amp;#x27;model&amp;#x27;: &amp;#x27;llama3-groq-70b-8192-tool-use-preview&amp;#x27;, &amp;#x27;max_tokens&amp;#x27;: 1000, &amp;#x27;temperature&amp;#x27;: 0.7}}\nDEBUG:httpcore.http11:send_request_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.http11:send_request_headers.complete\nDEBUG:httpcore.http11:send_request_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.http11:send_request_body.complete\nDEBUG:httpcore.http11:receive_response_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.http11:receive_response_headers.complete return_value=(b&amp;#x27;HTTP/1.1&amp;#x27;, 200, b&amp;#x27;OK&amp;#x27;, [(b&amp;#x27;Date&amp;#x27;, b&amp;#x27;Wed, 30 Oct 2024 15:53:40 GMT&amp;#x27;), (b&amp;#x27;Content-Type&amp;#x27;, b&amp;#x27;application/json&amp;#x27;), (b&amp;#x27;Transfer-Encoding&amp;#x27;, b&amp;#x27;chunked&amp;#x27;), (b&amp;#x27;Connection&amp;#x27;, b&amp;#x27;keep-alive&amp;#x27;), (b&amp;#x27;Cache-Control&amp;#x27;, b&amp;#x27;private, max-age=0, no-store, no-cache, must-revalidate&amp;#x27;), (b&amp;#x27;vary&amp;#x27;, b&amp;#x27;Origin&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-requests&amp;#x27;, b&amp;#x27;14400&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-tokens&amp;#x27;, b&amp;#x27;15000&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-requests&amp;#x27;, b&amp;#x27;14375&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-tokens&amp;#x27;, b&amp;#x27;14615&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-requests&amp;#x27;, b&amp;#x27;2m29.123999999s&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-tokens&amp;#x27;, b&amp;#x27;1.538s&amp;#x27;), (b&amp;#x27;x-request-id&amp;#x27;, b&amp;#x27;req_01jbf23tb8f4cr3nm0efs3bcm8&amp;#x27;), (b&amp;#x27;via&amp;#x27;, b&amp;#x27;1.1 google&amp;#x27;), (b&amp;#x27;alt-svc&amp;#x27;, b&amp;#x27;h3=&amp;quot;:443&amp;quot;; ma=86400&amp;#x27;), (b&amp;#x27;CF-Cache-Status&amp;#x27;, b&amp;#x27;DYNAMIC&amp;#x27;), (b&amp;#x27;Server&amp;#x27;, b&amp;#x27;cloudflare&amp;#x27;), (b&amp;#x27;CF-RAY&amp;#x27;, b&amp;#x27;8dac9448196cca58-HAM&amp;#x27;), (b&amp;#x27;Content-Encoding&amp;#x27;, b&amp;#x27;gzip&amp;#x27;)])\nINFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;HTTP/1.1 200 OK&amp;quot;\nDEBUG:httpcore.http11:receive_response_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.http11:receive_response_body.complete\nDEBUG:httpcore.http11:response_closed.started\nDEBUG:httpcore.http11:response_closed.complete\nDEBUG:groq._base_client:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;200 OK&amp;quot;\n\n------------------------------ Captured log call -------------------------------\nDEBUG    app:__init__.py:31 Headers: {&amp;#x27;User-Agent&amp;#x27;: &amp;#x27;Werkzeug/3.0.6&amp;#x27;, &amp;#x27;Host&amp;#x27;: &amp;#x27;localhost&amp;#x27;, &amp;#x27;Content-Type&amp;#x27;: &amp;#x27;application/json&amp;#x27;, &amp;#x27;Content-Length&amp;#x27;: &amp;#x27;1040&amp;#x27;, &amp;#x27;Authorization&amp;#x27;: &amp;#x27;Bearer test_key&amp;#x27;}\nDEBUG    app:__init__.py:32 Body: b&amp;#x27;{&amp;quot;content&amp;quot;: &amp;quot;AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA&amp;quot;, &amp;quot;target_percentage&amp;quot;: 50}&amp;#x27;\nDEBUG    app:__init__.py:33 Query Params: {}\nDEBUG    app:__init__.py:34 Route: POST /text/v1/compress/\nDEBUG    groq._base_client:_base_client.py:441 Request options: {&amp;#x27;method&amp;#x27;: &amp;#x27;post&amp;#x27;, &amp;#x27;url&amp;#x27;: &amp;#x27;/openai/v1/chat/completions&amp;#x27;, &amp;#x27;files&amp;#x27;: None, &amp;#x27;json_data&amp;#x27;: {&amp;#x27;messages&amp;#x27;: [{&amp;#x27;role&amp;#x27;: &amp;#x27;system&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate a JSON response following these rules:\\n1. Return exactly ONE compressed version:\\n   {&amp;quot;versions&amp;quot;: [{&amp;quot;text&amp;quot;: &amp;quot;compressed version&amp;quot;}]}\\n2. Target exactly the specified percentage of original length\\n3. Maintain core meaning while removing less essential details\\n4. Ensure complete sentences and proper punctuation\\n5. If task cannot be completed: {&amp;quot;error&amp;quot;: &amp;quot;specific reason&amp;quot;}&amp;#x27;}, {&amp;#x27;role&amp;#x27;: &amp;#x27;user&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate ONE compressed version at 50% length:\\n        Original length: 125 tokens\\n        Original text: AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA&amp;#x27;}], &amp;#x27;model&amp;#x27;: &amp;#x27;llama3-groq-70b-8192-tool-use-preview&amp;#x27;, &amp;#x27;max_tokens&amp;#x27;: 1000, &amp;#x27;temperature&amp;#x27;: 0.7}}\nDEBUG    httpcore.http11:_trace.py:45 send_request_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 send_request_headers.complete\nDEBUG    httpcore.http11:_trace.py:45 send_request_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 send_request_body.complete\nDEBUG    httpcore.http11:_trace.py:45 receive_response_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 receive_response_headers.complete return_value=(b&amp;#x27;HTTP/1.1&amp;#x27;, 200, b&amp;#x27;OK&amp;#x27;, [(b&amp;#x27;Date&amp;#x27;, b&amp;#x27;Wed, 30 Oct 2024 15:53:40 GMT&amp;#x27;), (b&amp;#x27;Content-Type&amp;#x27;, b&amp;#x27;application/json&amp;#x27;), (b&amp;#x27;Transfer-Encoding&amp;#x27;, b&amp;#x27;chunked&amp;#x27;), (b&amp;#x27;Connection&amp;#x27;, b&amp;#x27;keep-alive&amp;#x27;), (b&amp;#x27;Cache-Control&amp;#x27;, b&amp;#x27;private, max-age=0, no-store, no-cache, must-revalidate&amp;#x27;), (b&amp;#x27;vary&amp;#x27;, b&amp;#x27;Origin&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-requests&amp;#x27;, b&amp;#x27;14400&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-tokens&amp;#x27;, b&amp;#x27;15000&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-requests&amp;#x27;, b&amp;#x27;14375&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-tokens&amp;#x27;, b&amp;#x27;14615&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-requests&amp;#x27;, b&amp;#x27;2m29.123999999s&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-tokens&amp;#x27;, b&amp;#x27;1.538s&amp;#x27;), (b&amp;#x27;x-request-id&amp;#x27;, b&amp;#x27;req_01jbf23tb8f4cr3nm0efs3bcm8&amp;#x27;), (b&amp;#x27;via&amp;#x27;, b&amp;#x27;1.1 google&amp;#x27;), (b&amp;#x27;alt-svc&amp;#x27;, b&amp;#x27;h3=&amp;quot;:443&amp;quot;; ma=86400&amp;#x27;), (b&amp;#x27;CF-Cache-Status&amp;#x27;, b&amp;#x27;DYNAMIC&amp;#x27;), (b&amp;#x27;Server&amp;#x27;, b&amp;#x27;cloudflare&amp;#x27;), (b&amp;#x27;CF-RAY&amp;#x27;, b&amp;#x27;8dac9448196cca58-HAM&amp;#x27;), (b&amp;#x27;Content-Encoding&amp;#x27;, b&amp;#x27;gzip&amp;#x27;)])\nINFO     httpx:_client.py:1038 HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;HTTP/1.1 200 OK&amp;quot;\nDEBUG    httpcore.http11:_trace.py:45 receive_response_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 receive_response_body.complete\nDEBUG    httpcore.http11:_trace.py:45 response_closed.started\nDEBUG    httpcore.http11:_trace.py:45 response_closed.complete\nDEBUG    groq._base_client:_base_client.py:956 HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;200 OK&amp;quot;\n\n&#34;}], &#34;tests/performance/test_compress_performance.py::TestCompressPerformance::test_concurrent_requests&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Failed&#34;, &#34;testId&#34;: &#34;tests/performance/test_compress_performance.py::TestCompressPerformance::test_concurrent_requests&#34;, &#34;duration&#34;: &#34;00:00:06&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Failed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/performance/test_compress_performance.py::TestCompressPerformance::test_concurrent_requests&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:06&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;self = &amp;lt;tests.performance.test_compress_performance.TestCompressPerformance object at 0x106953da0&amp;gt;\nclient = &amp;lt;FlaskClient &amp;lt;Flask &amp;#x27;app&amp;#x27;&amp;gt;&amp;gt;\nauth_headers = {&amp;#x27;Authorization&amp;#x27;: &amp;#x27;Bearer test_key&amp;#x27;, &amp;#x27;Content-Type&amp;#x27;: &amp;#x27;application/json&amp;#x27;}\n\n    def test_concurrent_requests(self, client, auth_headers):\n        def make_request():\n            return client.post(self.ENDPOINTS[&amp;#x27;compress&amp;#x27;], json={\n                &amp;#x27;content&amp;#x27;: &amp;quot;Test content&amp;quot;,\n                &amp;#x27;target_percentage&amp;#x27;: 50\n            }, headers=auth_headers)\n    \n        with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:\n            futures = [executor.submit(make_request) for _ in range(10)]\n            responses = [f.result() for f in futures]\n    \n&amp;gt;       assert all(r.status_code == 200 for r in responses)\nE       assert False\nE        +  where False = all(&amp;lt;generator object TestCompressPerformance.test_concurrent_requests.&amp;lt;locals&amp;gt;.&amp;lt;genexpr&amp;gt; at 0x1091c7d30&amp;gt;)\n\ntests/performance/test_compress_performance.py:36: AssertionError\n\n---------------------------- Captured stderr setup -----------------------------\nDEBUG:app:Registering blueprints...\nDEBUG:app:Registered routes:\nDEBUG:app:static: /static/&amp;lt;path:filename&amp;gt; [GET, OPTIONS, HEAD]\nDEBUG:app:generate.create_text: /text/v1/generate/text [OPTIONS, POST]\nDEBUG:app:compress.compress_text: /text/v1/compress/ [OPTIONS, POST]\nDEBUG:app:expand.expand_text: /text/v1/expand/ [OPTIONS, POST]\n\n------------------------------ Captured log setup ------------------------------\nDEBUG    app:__init__.py:106 Registering blueprints...\nDEBUG    app:__init__.py:112 Registered routes:\nDEBUG    app:__init__.py:114 static: /static/&amp;lt;path:filename&amp;gt; [GET, OPTIONS, HEAD]\nDEBUG    app:__init__.py:114 generate.create_text: /text/v1/generate/text [OPTIONS, POST]\nDEBUG    app:__init__.py:114 compress.compress_text: /text/v1/compress/ [OPTIONS, POST]\nDEBUG    app:__init__.py:114 expand.expand_text: /text/v1/expand/ [OPTIONS, POST]\n\n----------------------------- Captured stderr call -----------------------------\nDEBUG:app:Headers: {&amp;#x27;User-Agent&amp;#x27;: &amp;#x27;Werkzeug/3.0.6&amp;#x27;, &amp;#x27;Host&amp;#x27;: &amp;#x27;localhost&amp;#x27;, &amp;#x27;Content-Type&amp;#x27;: &amp;#x27;application/json&amp;#x27;, &amp;#x27;Content-Length&amp;#x27;: &amp;#x27;52&amp;#x27;, &amp;#x27;Authorization&amp;#x27;: &amp;#x27;Bearer test_key&amp;#x27;}\nDEBUG:app:Headers: {&amp;#x27;User-Agent&amp;#x27;: &amp;#x27;Werkzeug/3.0.6&amp;#x27;, &amp;#x27;Host&amp;#x27;: &amp;#x27;localhost&amp;#x27;, &amp;#x27;Content-Type&amp;#x27;: &amp;#x27;application/json&amp;#x27;, &amp;#x27;Content-Length&amp;#x27;: &amp;#x27;52&amp;#x27;, &amp;#x27;Authorization&amp;#x27;: &amp;#x27;Bearer test_key&amp;#x27;}\nDEBUG:app:Body: b&amp;#x27;{&amp;quot;content&amp;quot;: &amp;quot;Test content&amp;quot;, &amp;quot;target_percentage&amp;quot;: 50}&amp;#x27;\nDEBUG:app:Headers: {&amp;#x27;User-Agent&amp;#x27;: &amp;#x27;Werkzeug/3.0.6&amp;#x27;, &amp;#x27;Host&amp;#x27;: &amp;#x27;localhost&amp;#x27;, &amp;#x27;Content-Type&amp;#x27;: &amp;#x27;application/json&amp;#x27;, &amp;#x27;Content-Length&amp;#x27;: &amp;#x27;52&amp;#x27;, &amp;#x27;Authorization&amp;#x27;: &amp;#x27;Bearer test_key&amp;#x27;}\nDEBUG:app:Body: b&amp;#x27;{&amp;quot;content&amp;quot;: &amp;quot;Test content&amp;quot;, &amp;quot;target_percentage&amp;quot;: 50}&amp;#x27;\nDEBUG:app:Headers: {&amp;#x27;User-Agent&amp;#x27;: &amp;#x27;Werkzeug/3.0.6&amp;#x27;, &amp;#x27;Host&amp;#x27;: &amp;#x27;localhost&amp;#x27;, &amp;#x27;Content-Type&amp;#x27;: &amp;#x27;application/json&amp;#x27;, &amp;#x27;Content-Length&amp;#x27;: &amp;#x27;52&amp;#x27;, &amp;#x27;Authorization&amp;#x27;: &amp;#x27;Bearer test_key&amp;#x27;}\nDEBUG:app:Query Params: {}\nDEBUG:app:Headers: {&amp;#x27;User-Agent&amp;#x27;: &amp;#x27;Werkzeug/3.0.6&amp;#x27;, &amp;#x27;Host&amp;#x27;: &amp;#x27;localhost&amp;#x27;, &amp;#x27;Content-Type&amp;#x27;: &amp;#x27;application/json&amp;#x27;, &amp;#x27;Content-Length&amp;#x27;: &amp;#x27;52&amp;#x27;, &amp;#x27;Authorization&amp;#x27;: &amp;#x27;Bearer test_key&amp;#x27;}\nDEBUG:app:Body: b&amp;#x27;{&amp;quot;content&amp;quot;: &amp;quot;Test content&amp;quot;, &amp;quot;target_percentage&amp;quot;: 50}&amp;#x27;\nDEBUG:app:Query Params: {}\nDEBUG:app:Headers: {&amp;#x27;User-Agent&amp;#x27;: &amp;#x27;Werkzeug/3.0.6&amp;#x27;, &amp;#x27;Host&amp;#x27;: &amp;#x27;localhost&amp;#x27;, &amp;#x27;Content-Type&amp;#x27;: &amp;#x27;application/json&amp;#x27;, &amp;#x27;Content-Length&amp;#x27;: &amp;#x27;52&amp;#x27;, &amp;#x27;Authorization&amp;#x27;: &amp;#x27;Bearer test_key&amp;#x27;}\nDEBUG:app:Body: b&amp;#x27;{&amp;quot;content&amp;quot;: &amp;quot;Test content&amp;quot;, &amp;quot;target_percentage&amp;quot;: 50}&amp;#x27;\nDEBUG:app:Route: POST /text/v1/compress/\nDEBUG:app:Headers: {&amp;#x27;User-Agent&amp;#x27;: &amp;#x27;Werkzeug/3.0.6&amp;#x27;, &amp;#x27;Host&amp;#x27;: &amp;#x27;localhost&amp;#x27;, &amp;#x27;Content-Type&amp;#x27;: &amp;#x27;application/json&amp;#x27;, &amp;#x27;Content-Length&amp;#x27;: &amp;#x27;52&amp;#x27;, &amp;#x27;Authorization&amp;#x27;: &amp;#x27;Bearer test_key&amp;#x27;}\nDEBUG:app:Body: b&amp;#x27;{&amp;quot;content&amp;quot;: &amp;quot;Test content&amp;quot;, &amp;quot;target_percentage&amp;quot;: 50}&amp;#x27;\nDEBUG:app:Query Params: {}\nDEBUG:app:Headers: {&amp;#x27;User-Agent&amp;#x27;: &amp;#x27;Werkzeug/3.0.6&amp;#x27;, &amp;#x27;Host&amp;#x27;: &amp;#x27;localhost&amp;#x27;, &amp;#x27;Content-Type&amp;#x27;: &amp;#x27;application/json&amp;#x27;, &amp;#x27;Content-Length&amp;#x27;: &amp;#x27;52&amp;#x27;, &amp;#x27;Authorization&amp;#x27;: &amp;#x27;Bearer test_key&amp;#x27;}\nDEBUG:app:Route: POST /text/v1/compress/\nDEBUG:app:Headers: {&amp;#x27;User-Agent&amp;#x27;: &amp;#x27;Werkzeug/3.0.6&amp;#x27;, &amp;#x27;Host&amp;#x27;: &amp;#x27;localhost&amp;#x27;, &amp;#x27;Content-Type&amp;#x27;: &amp;#x27;application/json&amp;#x27;, &amp;#x27;Content-Length&amp;#x27;: &amp;#x27;52&amp;#x27;, &amp;#x27;Authorization&amp;#x27;: &amp;#x27;Bearer test_key&amp;#x27;}\nDEBUG:app:Body: b&amp;#x27;{&amp;quot;content&amp;quot;: &amp;quot;Test content&amp;quot;, &amp;quot;target_percentage&amp;quot;: 50}&amp;#x27;\nDEBUG:app:Query Params: {}\nDEBUG:app:Headers: {&amp;#x27;User-Agent&amp;#x27;: &amp;#x27;Werkzeug/3.0.6&amp;#x27;, &amp;#x27;Host&amp;#x27;: &amp;#x27;localhost&amp;#x27;, &amp;#x27;Content-Type&amp;#x27;: &amp;#x27;application/json&amp;#x27;, &amp;#x27;Content-Length&amp;#x27;: &amp;#x27;52&amp;#x27;, &amp;#x27;Authorization&amp;#x27;: &amp;#x27;Bearer test_key&amp;#x27;}\nDEBUG:app:Body: b&amp;#x27;{&amp;quot;content&amp;quot;: &amp;quot;Test content&amp;quot;, &amp;quot;target_percentage&amp;quot;: 50}&amp;#x27;\nDEBUG:app:Query Params: {}\nDEBUG:groq._base_client:Request options: {&amp;#x27;method&amp;#x27;: &amp;#x27;post&amp;#x27;, &amp;#x27;url&amp;#x27;: &amp;#x27;/openai/v1/chat/completions&amp;#x27;, &amp;#x27;files&amp;#x27;: None, &amp;#x27;json_data&amp;#x27;: {&amp;#x27;messages&amp;#x27;: [{&amp;#x27;role&amp;#x27;: &amp;#x27;system&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate a JSON response following these rules:\\n1. Return exactly ONE compressed version:\\n   {&amp;quot;versions&amp;quot;: [{&amp;quot;text&amp;quot;: &amp;quot;compressed version&amp;quot;}]}\\n2. Target exactly the specified percentage of original length\\n3. Maintain core meaning while removing less essential details\\n4. Ensure complete sentences and proper punctuation\\n5. If task cannot be completed: {&amp;quot;error&amp;quot;: &amp;quot;specific reason&amp;quot;}&amp;#x27;}, {&amp;#x27;role&amp;#x27;: &amp;#x27;user&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate ONE compressed version at 50% length:\\n        Original length: 2 tokens\\n        Original text: Test content&amp;#x27;}], &amp;#x27;model&amp;#x27;: &amp;#x27;llama3-groq-70b-8192-tool-use-preview&amp;#x27;, &amp;#x27;max_tokens&amp;#x27;: 1000, &amp;#x27;temperature&amp;#x27;: 0.7}}\nDEBUG:app:Route: POST /text/v1/compress/\nDEBUG:app:Body: b&amp;#x27;{&amp;quot;content&amp;quot;: &amp;quot;Test content&amp;quot;, &amp;quot;target_percentage&amp;quot;: 50}&amp;#x27;\nDEBUG:app:Body: b&amp;#x27;{&amp;quot;content&amp;quot;: &amp;quot;Test content&amp;quot;, &amp;quot;target_percentage&amp;quot;: 50}&amp;#x27;\nDEBUG:app:Query Params: {}\nDEBUG:app:Route: POST /text/v1/compress/\nDEBUG:app:Body: b&amp;#x27;{&amp;quot;content&amp;quot;: &amp;quot;Test content&amp;quot;, &amp;quot;target_percentage&amp;quot;: 50}&amp;#x27;\nDEBUG:app:Query Params: {}\nDEBUG:app:Route: POST /text/v1/compress/\nDEBUG:groq._base_client:Request options: {&amp;#x27;method&amp;#x27;: &amp;#x27;post&amp;#x27;, &amp;#x27;url&amp;#x27;: &amp;#x27;/openai/v1/chat/completions&amp;#x27;, &amp;#x27;files&amp;#x27;: None, &amp;#x27;json_data&amp;#x27;: {&amp;#x27;messages&amp;#x27;: [{&amp;#x27;role&amp;#x27;: &amp;#x27;system&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate a JSON response following these rules:\\n1. Return exactly ONE compressed version:\\n   {&amp;quot;versions&amp;quot;: [{&amp;quot;text&amp;quot;: &amp;quot;compressed version&amp;quot;}]}\\n2. Target exactly the specified percentage of original length\\n3. Maintain core meaning while removing less essential details\\n4. Ensure complete sentences and proper punctuation\\n5. If task cannot be completed: {&amp;quot;error&amp;quot;: &amp;quot;specific reason&amp;quot;}&amp;#x27;}, {&amp;#x27;role&amp;#x27;: &amp;#x27;user&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate ONE compressed version at 50% length:\\n        Original length: 2 tokens\\n        Original text: Test content&amp;#x27;}], &amp;#x27;model&amp;#x27;: &amp;#x27;llama3-groq-70b-8192-tool-use-preview&amp;#x27;, &amp;#x27;max_tokens&amp;#x27;: 1000, &amp;#x27;temperature&amp;#x27;: 0.7}}\nDEBUG:httpcore.http11:send_request_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:app:Query Params: {}\nDEBUG:app:Query Params: {}\nDEBUG:app:Route: POST /text/v1/compress/\nDEBUG:app:Query Params: {}\nDEBUG:groq._base_client:Request options: {&amp;#x27;method&amp;#x27;: &amp;#x27;post&amp;#x27;, &amp;#x27;url&amp;#x27;: &amp;#x27;/openai/v1/chat/completions&amp;#x27;, &amp;#x27;files&amp;#x27;: None, &amp;#x27;json_data&amp;#x27;: {&amp;#x27;messages&amp;#x27;: [{&amp;#x27;role&amp;#x27;: &amp;#x27;system&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate a JSON response following these rules:\\n1. Return exactly ONE compressed version:\\n   {&amp;quot;versions&amp;quot;: [{&amp;quot;text&amp;quot;: &amp;quot;compressed version&amp;quot;}]}\\n2. Target exactly the specified percentage of original length\\n3. Maintain core meaning while removing less essential details\\n4. Ensure complete sentences and proper punctuation\\n5. If task cannot be completed: {&amp;quot;error&amp;quot;: &amp;quot;specific reason&amp;quot;}&amp;#x27;}, {&amp;#x27;role&amp;#x27;: &amp;#x27;user&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate ONE compressed version at 50% length:\\n        Original length: 2 tokens\\n        Original text: Test content&amp;#x27;}], &amp;#x27;model&amp;#x27;: &amp;#x27;llama3-groq-70b-8192-tool-use-preview&amp;#x27;, &amp;#x27;max_tokens&amp;#x27;: 1000, &amp;#x27;temperature&amp;#x27;: 0.7}}\nDEBUG:groq._base_client:Request options: {&amp;#x27;method&amp;#x27;: &amp;#x27;post&amp;#x27;, &amp;#x27;url&amp;#x27;: &amp;#x27;/openai/v1/chat/completions&amp;#x27;, &amp;#x27;files&amp;#x27;: None, &amp;#x27;json_data&amp;#x27;: {&amp;#x27;messages&amp;#x27;: [{&amp;#x27;role&amp;#x27;: &amp;#x27;system&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate a JSON response following these rules:\\n1. Return exactly ONE compressed version:\\n   {&amp;quot;versions&amp;quot;: [{&amp;quot;text&amp;quot;: &amp;quot;compressed version&amp;quot;}]}\\n2. Target exactly the specified percentage of original length\\n3. Maintain core meaning while removing less essential details\\n4. Ensure complete sentences and proper punctuation\\n5. If task cannot be completed: {&amp;quot;error&amp;quot;: &amp;quot;specific reason&amp;quot;}&amp;#x27;}, {&amp;#x27;role&amp;#x27;: &amp;#x27;user&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate ONE compressed version at 50% length:\\n        Original length: 2 tokens\\n        Original text: Test content&amp;#x27;}], &amp;#x27;model&amp;#x27;: &amp;#x27;llama3-groq-70b-8192-tool-use-preview&amp;#x27;, &amp;#x27;max_tokens&amp;#x27;: 1000, &amp;#x27;temperature&amp;#x27;: 0.7}}\nDEBUG:app:Route: POST /text/v1/compress/\nDEBUG:httpcore.connection:connect_tcp.started host=&amp;#x27;api.groq.com&amp;#x27; port=443 local_address=None timeout=5.0 socket_options=None\nDEBUG:groq._base_client:Request options: {&amp;#x27;method&amp;#x27;: &amp;#x27;post&amp;#x27;, &amp;#x27;url&amp;#x27;: &amp;#x27;/openai/v1/chat/completions&amp;#x27;, &amp;#x27;files&amp;#x27;: None, &amp;#x27;json_data&amp;#x27;: {&amp;#x27;messages&amp;#x27;: [{&amp;#x27;role&amp;#x27;: &amp;#x27;system&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate a JSON response following these rules:\\n1. Return exactly ONE compressed version:\\n   {&amp;quot;versions&amp;quot;: [{&amp;quot;text&amp;quot;: &amp;quot;compressed version&amp;quot;}]}\\n2. Target exactly the specified percentage of original length\\n3. Maintain core meaning while removing less essential details\\n4. Ensure complete sentences and proper punctuation\\n5. If task cannot be completed: {&amp;quot;error&amp;quot;: &amp;quot;specific reason&amp;quot;}&amp;#x27;}, {&amp;#x27;role&amp;#x27;: &amp;#x27;user&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate ONE compressed version at 50% length:\\n        Original length: 2 tokens\\n        Original text: Test content&amp;#x27;}], &amp;#x27;model&amp;#x27;: &amp;#x27;llama3-groq-70b-8192-tool-use-preview&amp;#x27;, &amp;#x27;max_tokens&amp;#x27;: 1000, &amp;#x27;temperature&amp;#x27;: 0.7}}\nDEBUG:app:Route: POST /text/v1/compress/\nDEBUG:app:Route: POST /text/v1/compress/\nDEBUG:httpcore.http11:send_request_headers.complete\nDEBUG:app:Route: POST /text/v1/compress/\nDEBUG:groq._base_client:Request options: {&amp;#x27;method&amp;#x27;: &amp;#x27;post&amp;#x27;, &amp;#x27;url&amp;#x27;: &amp;#x27;/openai/v1/chat/completions&amp;#x27;, &amp;#x27;files&amp;#x27;: None, &amp;#x27;json_data&amp;#x27;: {&amp;#x27;messages&amp;#x27;: [{&amp;#x27;role&amp;#x27;: &amp;#x27;system&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate a JSON response following these rules:\\n1. Return exactly ONE compressed version:\\n   {&amp;quot;versions&amp;quot;: [{&amp;quot;text&amp;quot;: &amp;quot;compressed version&amp;quot;}]}\\n2. Target exactly the specified percentage of original length\\n3. Maintain core meaning while removing less essential details\\n4. Ensure complete sentences and proper punctuation\\n5. If task cannot be completed: {&amp;quot;error&amp;quot;: &amp;quot;specific reason&amp;quot;}&amp;#x27;}, {&amp;#x27;role&amp;#x27;: &amp;#x27;user&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate ONE compressed version at 50% length:\\n        Original length: 2 tokens\\n        Original text: Test content&amp;#x27;}], &amp;#x27;model&amp;#x27;: &amp;#x27;llama3-groq-70b-8192-tool-use-preview&amp;#x27;, &amp;#x27;max_tokens&amp;#x27;: 1000, &amp;#x27;temperature&amp;#x27;: 0.7}}\nDEBUG:httpcore.connection:connect_tcp.started host=&amp;#x27;api.groq.com&amp;#x27; port=443 local_address=None timeout=5.0 socket_options=None\nDEBUG:httpcore.connection:connect_tcp.started host=&amp;#x27;api.groq.com&amp;#x27; port=443 local_address=None timeout=5.0 socket_options=None\nDEBUG:httpcore.connection:connect_tcp.started host=&amp;#x27;api.groq.com&amp;#x27; port=443 local_address=None timeout=5.0 socket_options=None\nDEBUG:groq._base_client:Request options: {&amp;#x27;method&amp;#x27;: &amp;#x27;post&amp;#x27;, &amp;#x27;url&amp;#x27;: &amp;#x27;/openai/v1/chat/completions&amp;#x27;, &amp;#x27;files&amp;#x27;: None, &amp;#x27;json_data&amp;#x27;: {&amp;#x27;messages&amp;#x27;: [{&amp;#x27;role&amp;#x27;: &amp;#x27;system&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate a JSON response following these rules:\\n1. Return exactly ONE compressed version:\\n   {&amp;quot;versions&amp;quot;: [{&amp;quot;text&amp;quot;: &amp;quot;compressed version&amp;quot;}]}\\n2. Target exactly the specified percentage of original length\\n3. Maintain core meaning while removing less essential details\\n4. Ensure complete sentences and proper punctuation\\n5. If task cannot be completed: {&amp;quot;error&amp;quot;: &amp;quot;specific reason&amp;quot;}&amp;#x27;}, {&amp;#x27;role&amp;#x27;: &amp;#x27;user&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate ONE compressed version at 50% length:\\n        Original length: 2 tokens\\n        Original text: Test content&amp;#x27;}], &amp;#x27;model&amp;#x27;: &amp;#x27;llama3-groq-70b-8192-tool-use-preview&amp;#x27;, &amp;#x27;max_tokens&amp;#x27;: 1000, &amp;#x27;temperature&amp;#x27;: 0.7}}\nDEBUG:groq._base_client:Request options: {&amp;#x27;method&amp;#x27;: &amp;#x27;post&amp;#x27;, &amp;#x27;url&amp;#x27;: &amp;#x27;/openai/v1/chat/completions&amp;#x27;, &amp;#x27;files&amp;#x27;: None, &amp;#x27;json_data&amp;#x27;: {&amp;#x27;messages&amp;#x27;: [{&amp;#x27;role&amp;#x27;: &amp;#x27;system&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate a JSON response following these rules:\\n1. Return exactly ONE compressed version:\\n   {&amp;quot;versions&amp;quot;: [{&amp;quot;text&amp;quot;: &amp;quot;compressed version&amp;quot;}]}\\n2. Target exactly the specified percentage of original length\\n3. Maintain core meaning while removing less essential details\\n4. Ensure complete sentences and proper punctuation\\n5. If task cannot be completed: {&amp;quot;error&amp;quot;: &amp;quot;specific reason&amp;quot;}&amp;#x27;}, {&amp;#x27;role&amp;#x27;: &amp;#x27;user&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate ONE compressed version at 50% length:\\n        Original length: 2 tokens\\n        Original text: Test content&amp;#x27;}], &amp;#x27;model&amp;#x27;: &amp;#x27;llama3-groq-70b-8192-tool-use-preview&amp;#x27;, &amp;#x27;max_tokens&amp;#x27;: 1000, &amp;#x27;temperature&amp;#x27;: 0.7}}\nDEBUG:httpcore.http11:send_request_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:groq._base_client:Request options: {&amp;#x27;method&amp;#x27;: &amp;#x27;post&amp;#x27;, &amp;#x27;url&amp;#x27;: &amp;#x27;/openai/v1/chat/completions&amp;#x27;, &amp;#x27;files&amp;#x27;: None, &amp;#x27;json_data&amp;#x27;: {&amp;#x27;messages&amp;#x27;: [{&amp;#x27;role&amp;#x27;: &amp;#x27;system&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate a JSON response following these rules:\\n1. Return exactly ONE compressed version:\\n   {&amp;quot;versions&amp;quot;: [{&amp;quot;text&amp;quot;: &amp;quot;compressed version&amp;quot;}]}\\n2. Target exactly the specified percentage of original length\\n3. Maintain core meaning while removing less essential details\\n4. Ensure complete sentences and proper punctuation\\n5. If task cannot be completed: {&amp;quot;error&amp;quot;: &amp;quot;specific reason&amp;quot;}&amp;#x27;}, {&amp;#x27;role&amp;#x27;: &amp;#x27;user&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate ONE compressed version at 50% length:\\n        Original length: 2 tokens\\n        Original text: Test content&amp;#x27;}], &amp;#x27;model&amp;#x27;: &amp;#x27;llama3-groq-70b-8192-tool-use-preview&amp;#x27;, &amp;#x27;max_tokens&amp;#x27;: 1000, &amp;#x27;temperature&amp;#x27;: 0.7}}\nDEBUG:groq._base_client:Request options: {&amp;#x27;method&amp;#x27;: &amp;#x27;post&amp;#x27;, &amp;#x27;url&amp;#x27;: &amp;#x27;/openai/v1/chat/completions&amp;#x27;, &amp;#x27;files&amp;#x27;: None, &amp;#x27;json_data&amp;#x27;: {&amp;#x27;messages&amp;#x27;: [{&amp;#x27;role&amp;#x27;: &amp;#x27;system&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate a JSON response following these rules:\\n1. Return exactly ONE compressed version:\\n   {&amp;quot;versions&amp;quot;: [{&amp;quot;text&amp;quot;: &amp;quot;compressed version&amp;quot;}]}\\n2. Target exactly the specified percentage of original length\\n3. Maintain core meaning while removing less essential details\\n4. Ensure complete sentences and proper punctuation\\n5. If task cannot be completed: {&amp;quot;error&amp;quot;: &amp;quot;specific reason&amp;quot;}&amp;#x27;}, {&amp;#x27;role&amp;#x27;: &amp;#x27;user&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate ONE compressed version at 50% length:\\n        Original length: 2 tokens\\n        Original text: Test content&amp;#x27;}], &amp;#x27;model&amp;#x27;: &amp;#x27;llama3-groq-70b-8192-tool-use-preview&amp;#x27;, &amp;#x27;max_tokens&amp;#x27;: 1000, &amp;#x27;temperature&amp;#x27;: 0.7}}\nDEBUG:httpcore.connection:connect_tcp.started host=&amp;#x27;api.groq.com&amp;#x27; port=443 local_address=None timeout=5.0 socket_options=None\nDEBUG:httpcore.connection:connect_tcp.started host=&amp;#x27;api.groq.com&amp;#x27; port=443 local_address=None timeout=5.0 socket_options=None\nDEBUG:httpcore.connection:connect_tcp.started host=&amp;#x27;api.groq.com&amp;#x27; port=443 local_address=None timeout=5.0 socket_options=None\nDEBUG:httpcore.http11:send_request_body.complete\nDEBUG:httpcore.connection:connect_tcp.started host=&amp;#x27;api.groq.com&amp;#x27; port=443 local_address=None timeout=5.0 socket_options=None\nDEBUG:httpcore.connection:connect_tcp.started host=&amp;#x27;api.groq.com&amp;#x27; port=443 local_address=None timeout=5.0 socket_options=None\nDEBUG:httpcore.http11:receive_response_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.connection:connect_tcp.complete return_value=&amp;lt;httpcore._backends.sync.SyncStream object at 0x108959850&amp;gt;\nDEBUG:httpcore.connection:start_tls.started ssl_context=&amp;lt;ssl.SSLContext object at 0x107bb3b50&amp;gt; server_hostname=&amp;#x27;api.groq.com&amp;#x27; timeout=5.0\nDEBUG:httpcore.connection:connect_tcp.complete return_value=&amp;lt;httpcore._backends.sync.SyncStream object at 0x109178050&amp;gt;\nDEBUG:httpcore.connection:connect_tcp.complete return_value=&amp;lt;httpcore._backends.sync.SyncStream object at 0x109178170&amp;gt;\nDEBUG:httpcore.connection:start_tls.started ssl_context=&amp;lt;ssl.SSLContext object at 0x107bb3b50&amp;gt; server_hostname=&amp;#x27;api.groq.com&amp;#x27; timeout=5.0\nDEBUG:httpcore.connection:connect_tcp.complete return_value=&amp;lt;httpcore._backends.sync.SyncStream object at 0x1091585c0&amp;gt;\nDEBUG:httpcore.connection:start_tls.started ssl_context=&amp;lt;ssl.SSLContext object at 0x107bb3b50&amp;gt; server_hostname=&amp;#x27;api.groq.com&amp;#x27; timeout=5.0\nDEBUG:httpcore.connection:start_tls.started ssl_context=&amp;lt;ssl.SSLContext object at 0x107bb3b50&amp;gt; server_hostname=&amp;#x27;api.groq.com&amp;#x27; timeout=5.0\nDEBUG:httpcore.connection:connect_tcp.complete return_value=&amp;lt;httpcore._backends.sync.SyncStream object at 0x108959130&amp;gt;\nDEBUG:httpcore.connection:start_tls.started ssl_context=&amp;lt;ssl.SSLContext object at 0x107bb3b50&amp;gt; server_hostname=&amp;#x27;api.groq.com&amp;#x27; timeout=5.0\nDEBUG:httpcore.connection:connect_tcp.complete return_value=&amp;lt;httpcore._backends.sync.SyncStream object at 0x1091786b0&amp;gt;\nDEBUG:httpcore.connection:connect_tcp.complete return_value=&amp;lt;httpcore._backends.sync.SyncStream object at 0x109178110&amp;gt;\nDEBUG:httpcore.connection:start_tls.started ssl_context=&amp;lt;ssl.SSLContext object at 0x107bb3b50&amp;gt; server_hostname=&amp;#x27;api.groq.com&amp;#x27; timeout=5.0\nDEBUG:httpcore.connection:connect_tcp.complete return_value=&amp;lt;httpcore._backends.sync.SyncStream object at 0x109158560&amp;gt;\nDEBUG:httpcore.connection:start_tls.started ssl_context=&amp;lt;ssl.SSLContext object at 0x107bb3b50&amp;gt; server_hostname=&amp;#x27;api.groq.com&amp;#x27; timeout=5.0\nDEBUG:httpcore.connection:start_tls.started ssl_context=&amp;lt;ssl.SSLContext object at 0x107bb3b50&amp;gt; server_hostname=&amp;#x27;api.groq.com&amp;#x27; timeout=5.0\nDEBUG:httpcore.connection:connect_tcp.complete return_value=&amp;lt;httpcore._backends.sync.SyncStream object at 0x1091583e0&amp;gt;\nDEBUG:httpcore.connection:start_tls.started ssl_context=&amp;lt;ssl.SSLContext object at 0x107bb3b50&amp;gt; server_hostname=&amp;#x27;api.groq.com&amp;#x27; timeout=5.0\nDEBUG:httpcore.connection:start_tls.complete return_value=&amp;lt;httpcore._backends.sync.SyncStream object at 0x1089882c0&amp;gt;\nDEBUG:httpcore.http11:send_request_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.http11:send_request_headers.complete\nDEBUG:httpcore.http11:send_request_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.http11:send_request_body.complete\nDEBUG:httpcore.http11:receive_response_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.connection:start_tls.complete return_value=&amp;lt;httpcore._backends.sync.SyncStream object at 0x10917bfb0&amp;gt;\nDEBUG:httpcore.connection:start_tls.complete return_value=&amp;lt;httpcore._backends.sync.SyncStream object at 0x10917a6c0&amp;gt;\nDEBUG:httpcore.http11:send_request_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.http11:send_request_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.http11:send_request_headers.complete\nDEBUG:httpcore.connection:start_tls.complete return_value=&amp;lt;httpcore._backends.sync.SyncStream object at 0x10895b860&amp;gt;\nDEBUG:httpcore.http11:send_request_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.http11:send_request_headers.complete\nDEBUG:httpcore.http11:send_request_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.http11:send_request_body.complete\nDEBUG:httpcore.http11:send_request_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.http11:receive_response_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.http11:send_request_headers.complete\nDEBUG:httpcore.http11:send_request_body.complete\nDEBUG:httpcore.http11:send_request_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.http11:receive_response_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.http11:send_request_body.complete\nDEBUG:httpcore.http11:receive_response_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.connection:start_tls.complete return_value=&amp;lt;httpcore._backends.sync.SyncStream object at 0x1091791c0&amp;gt;\nDEBUG:httpcore.http11:send_request_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.http11:send_request_headers.complete\nDEBUG:httpcore.http11:send_request_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.http11:send_request_body.complete\nDEBUG:httpcore.http11:receive_response_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.connection:start_tls.complete return_value=&amp;lt;httpcore._backends.sync.SyncStream object at 0x1084c4470&amp;gt;\nDEBUG:httpcore.http11:send_request_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.http11:send_request_headers.complete\nDEBUG:httpcore.http11:send_request_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.http11:send_request_body.complete\nDEBUG:httpcore.http11:receive_response_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.connection:start_tls.complete return_value=&amp;lt;httpcore._backends.sync.SyncStream object at 0x10917b530&amp;gt;\nDEBUG:httpcore.http11:send_request_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.http11:send_request_headers.complete\nDEBUG:httpcore.http11:send_request_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.http11:send_request_body.complete\nDEBUG:httpcore.http11:receive_response_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.connection:start_tls.complete return_value=&amp;lt;httpcore._backends.sync.SyncStream object at 0x10917aa50&amp;gt;\nDEBUG:httpcore.http11:send_request_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.connection:start_tls.complete return_value=&amp;lt;httpcore._backends.sync.SyncStream object at 0x108959b20&amp;gt;\nDEBUG:httpcore.http11:send_request_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.http11:send_request_headers.complete\nDEBUG:httpcore.http11:send_request_headers.complete\nDEBUG:httpcore.http11:send_request_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.http11:send_request_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.http11:send_request_body.complete\nDEBUG:httpcore.http11:receive_response_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.http11:send_request_body.complete\nDEBUG:httpcore.http11:receive_response_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.http11:receive_response_headers.complete return_value=(b&amp;#x27;HTTP/1.1&amp;#x27;, 200, b&amp;#x27;OK&amp;#x27;, [(b&amp;#x27;Date&amp;#x27;, b&amp;#x27;Wed, 30 Oct 2024 15:53:41 GMT&amp;#x27;), (b&amp;#x27;Content-Type&amp;#x27;, b&amp;#x27;application/json&amp;#x27;), (b&amp;#x27;Transfer-Encoding&amp;#x27;, b&amp;#x27;chunked&amp;#x27;), (b&amp;#x27;Connection&amp;#x27;, b&amp;#x27;keep-alive&amp;#x27;), (b&amp;#x27;Cache-Control&amp;#x27;, b&amp;#x27;private, max-age=0, no-store, no-cache, must-revalidate&amp;#x27;), (b&amp;#x27;vary&amp;#x27;, b&amp;#x27;Origin&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-requests&amp;#x27;, b&amp;#x27;14400&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-tokens&amp;#x27;, b&amp;#x27;15000&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-requests&amp;#x27;, b&amp;#x27;14374&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-tokens&amp;#x27;, b&amp;#x27;13816&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-requests&amp;#x27;, b&amp;#x27;2m31.955999999s&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-tokens&amp;#x27;, b&amp;#x27;4.734s&amp;#x27;), (b&amp;#x27;x-request-id&amp;#x27;, b&amp;#x27;req_01jbf23y9pe408b9578bshcyga&amp;#x27;), (b&amp;#x27;via&amp;#x27;, b&amp;#x27;1.1 google&amp;#x27;), (b&amp;#x27;alt-svc&amp;#x27;, b&amp;#x27;h3=&amp;quot;:443&amp;quot;; ma=86400&amp;#x27;), (b&amp;#x27;CF-Cache-Status&amp;#x27;, b&amp;#x27;DYNAMIC&amp;#x27;), (b&amp;#x27;Server&amp;#x27;, b&amp;#x27;cloudflare&amp;#x27;), (b&amp;#x27;CF-RAY&amp;#x27;, b&amp;#x27;8dac94615821ca58-HAM&amp;#x27;), (b&amp;#x27;Content-Encoding&amp;#x27;, b&amp;#x27;gzip&amp;#x27;)])\nINFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;HTTP/1.1 200 OK&amp;quot;\nDEBUG:httpcore.http11:receive_response_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.http11:receive_response_body.complete\nDEBUG:httpcore.http11:response_closed.started\nDEBUG:httpcore.http11:response_closed.complete\nDEBUG:groq._base_client:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;200 OK&amp;quot;\nDEBUG:httpcore.http11:receive_response_headers.complete return_value=(b&amp;#x27;HTTP/1.1&amp;#x27;, 429, b&amp;#x27;Too Many Requests&amp;#x27;, [(b&amp;#x27;Date&amp;#x27;, b&amp;#x27;Wed, 30 Oct 2024 15:53:41 GMT&amp;#x27;), (b&amp;#x27;Content-Type&amp;#x27;, b&amp;#x27;application/json&amp;#x27;), (b&amp;#x27;Content-Length&amp;#x27;, b&amp;#x27;349&amp;#x27;), (b&amp;#x27;Connection&amp;#x27;, b&amp;#x27;keep-alive&amp;#x27;), (b&amp;#x27;Cache-Control&amp;#x27;, b&amp;#x27;private, max-age=0, no-store, no-cache, must-revalidate&amp;#x27;), (b&amp;#x27;retry-after&amp;#x27;, b&amp;#x27;2&amp;#x27;), (b&amp;#x27;vary&amp;#x27;, b&amp;#x27;Origin&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-requests&amp;#x27;, b&amp;#x27;14400&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-tokens&amp;#x27;, b&amp;#x27;15000&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-requests&amp;#x27;, b&amp;#x27;14368&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-tokens&amp;#x27;, b&amp;#x27;13862&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-requests&amp;#x27;, b&amp;#x27;3m11.997999999s&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-tokens&amp;#x27;, b&amp;#x27;4.552s&amp;#x27;), (b&amp;#x27;x-request-id&amp;#x27;, b&amp;#x27;req_01jbf23yeffsnt50w7zpvw4xha&amp;#x27;), (b&amp;#x27;via&amp;#x27;, b&amp;#x27;1.1 google&amp;#x27;), (b&amp;#x27;alt-svc&amp;#x27;, b&amp;#x27;h3=&amp;quot;:443&amp;quot;; ma=86400&amp;#x27;), (b&amp;#x27;CF-Cache-Status&amp;#x27;, b&amp;#x27;DYNAMIC&amp;#x27;), (b&amp;#x27;Server&amp;#x27;, b&amp;#x27;cloudflare&amp;#x27;), (b&amp;#x27;CF-RAY&amp;#x27;, b&amp;#x27;8dac94623c6b62ce-HAM&amp;#x27;)])\nINFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;HTTP/1.1 429 Too Many Requests&amp;quot;\nDEBUG:httpcore.http11:receive_response_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.http11:receive_response_body.complete\nDEBUG:httpcore.http11:response_closed.started\nDEBUG:httpcore.http11:response_closed.complete\nDEBUG:groq._base_client:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;429 Too Many Requests&amp;quot;\nDEBUG:groq._base_client:Encountered httpx.HTTPStatusError\nTraceback (most recent call last):\n  File &amp;quot;/Users/julian/Tresors/Privat/Code/fragment-editor-api/.venv-test/lib/python3.12/site-packages/groq/_base_client.py&amp;quot;, line 961, in _request\n    response.raise_for_status()\n  File &amp;quot;/Users/julian/Tresors/Privat/Code/fragment-editor-api/.venv-test/lib/python3.12/site-packages/httpx/_models.py&amp;quot;, line 763, in raise_for_status\n    raise HTTPStatusError(message, request=request, response=self)\nhttpx.HTTPStatusError: Client error &amp;#x27;429 Too Many Requests&amp;#x27; for url &amp;#x27;https://api.groq.com/openai/v1/chat/completions&amp;#x27;\nFor more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\nDEBUG:groq._base_client:Retrying due to status code 429\nDEBUG:groq._base_client:1 retry left\nINFO:groq._base_client:Retrying request to /openai/v1/chat/completions in 2.000000 seconds\nDEBUG:httpcore.http11:receive_response_headers.complete return_value=(b&amp;#x27;HTTP/1.1&amp;#x27;, 200, b&amp;#x27;OK&amp;#x27;, [(b&amp;#x27;Date&amp;#x27;, b&amp;#x27;Wed, 30 Oct 2024 15:53:41 GMT&amp;#x27;), (b&amp;#x27;Content-Type&amp;#x27;, b&amp;#x27;application/json&amp;#x27;), (b&amp;#x27;Transfer-Encoding&amp;#x27;, b&amp;#x27;chunked&amp;#x27;), (b&amp;#x27;Connection&amp;#x27;, b&amp;#x27;keep-alive&amp;#x27;), (b&amp;#x27;Cache-Control&amp;#x27;, b&amp;#x27;private, max-age=0, no-store, no-cache, must-revalidate&amp;#x27;), (b&amp;#x27;vary&amp;#x27;, b&amp;#x27;Origin&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-requests&amp;#x27;, b&amp;#x27;14400&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-tokens&amp;#x27;, b&amp;#x27;15000&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-requests&amp;#x27;, b&amp;#x27;14373&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-tokens&amp;#x27;, b&amp;#x27;13723&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-requests&amp;#x27;, b&amp;#x27;2m41.870999999s&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-tokens&amp;#x27;, b&amp;#x27;5.106s&amp;#x27;), (b&amp;#x27;x-request-id&amp;#x27;, b&amp;#x27;req_01jbf23ydrfb29a048m5zbyppa&amp;#x27;), (b&amp;#x27;via&amp;#x27;, b&amp;#x27;1.1 google&amp;#x27;), (b&amp;#x27;alt-svc&amp;#x27;, b&amp;#x27;h3=&amp;quot;:443&amp;quot;; ma=86400&amp;#x27;), (b&amp;#x27;CF-Cache-Status&amp;#x27;, b&amp;#x27;DYNAMIC&amp;#x27;), (b&amp;#x27;Server&amp;#x27;, b&amp;#x27;cloudflare&amp;#x27;), (b&amp;#x27;CF-RAY&amp;#x27;, b&amp;#x27;8dac94623cfdd2b7-FRA&amp;#x27;), (b&amp;#x27;Content-Encoding&amp;#x27;, b&amp;#x27;gzip&amp;#x27;)])\nINFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;HTTP/1.1 200 OK&amp;quot;\nDEBUG:httpcore.http11:receive_response_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.http11:receive_response_body.complete\nDEBUG:httpcore.http11:response_closed.started\nDEBUG:httpcore.http11:response_closed.complete\nDEBUG:groq._base_client:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;200 OK&amp;quot;\nDEBUG:httpcore.http11:receive_response_headers.complete return_value=(b&amp;#x27;HTTP/1.1&amp;#x27;, 200, b&amp;#x27;OK&amp;#x27;, [(b&amp;#x27;Date&amp;#x27;, b&amp;#x27;Wed, 30 Oct 2024 15:53:41 GMT&amp;#x27;), (b&amp;#x27;Content-Type&amp;#x27;, b&amp;#x27;application/json&amp;#x27;), (b&amp;#x27;Transfer-Encoding&amp;#x27;, b&amp;#x27;chunked&amp;#x27;), (b&amp;#x27;Connection&amp;#x27;, b&amp;#x27;keep-alive&amp;#x27;), (b&amp;#x27;Cache-Control&amp;#x27;, b&amp;#x27;private, max-age=0, no-store, no-cache, must-revalidate&amp;#x27;), (b&amp;#x27;vary&amp;#x27;, b&amp;#x27;Origin&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-requests&amp;#x27;, b&amp;#x27;14400&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-tokens&amp;#x27;, b&amp;#x27;15000&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-requests&amp;#x27;, b&amp;#x27;14371&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-tokens&amp;#x27;, b&amp;#x27;13725&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-requests&amp;#x27;, b&amp;#x27;2m53.996999999s&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-tokens&amp;#x27;, b&amp;#x27;5.099s&amp;#x27;), (b&amp;#x27;x-request-id&amp;#x27;, b&amp;#x27;req_01jbf23ydzf1hs0ehsjdkmvpx5&amp;#x27;), (b&amp;#x27;via&amp;#x27;, b&amp;#x27;1.1 google&amp;#x27;), (b&amp;#x27;alt-svc&amp;#x27;, b&amp;#x27;h3=&amp;quot;:443&amp;quot;; ma=86400&amp;#x27;), (b&amp;#x27;CF-Cache-Status&amp;#x27;, b&amp;#x27;DYNAMIC&amp;#x27;), (b&amp;#x27;Server&amp;#x27;, b&amp;#x27;cloudflare&amp;#x27;), (b&amp;#x27;CF-RAY&amp;#x27;, b&amp;#x27;8dac94622af67267-HAM&amp;#x27;), (b&amp;#x27;Content-Encoding&amp;#x27;, b&amp;#x27;gzip&amp;#x27;)])\nINFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;HTTP/1.1 200 OK&amp;quot;\nDEBUG:httpcore.http11:receive_response_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.http11:receive_response_body.complete\nDEBUG:httpcore.http11:response_closed.started\nDEBUG:httpcore.http11:response_closed.complete\nDEBUG:groq._base_client:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;200 OK&amp;quot;\nDEBUG:httpcore.http11:receive_response_headers.complete return_value=(b&amp;#x27;HTTP/1.1&amp;#x27;, 200, b&amp;#x27;OK&amp;#x27;, [(b&amp;#x27;Date&amp;#x27;, b&amp;#x27;Wed, 30 Oct 2024 15:53:41 GMT&amp;#x27;), (b&amp;#x27;Content-Type&amp;#x27;, b&amp;#x27;application/json&amp;#x27;), (b&amp;#x27;Transfer-Encoding&amp;#x27;, b&amp;#x27;chunked&amp;#x27;), (b&amp;#x27;Connection&amp;#x27;, b&amp;#x27;keep-alive&amp;#x27;), (b&amp;#x27;Cache-Control&amp;#x27;, b&amp;#x27;private, max-age=0, no-store, no-cache, must-revalidate&amp;#x27;), (b&amp;#x27;vary&amp;#x27;, b&amp;#x27;Origin&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-requests&amp;#x27;, b&amp;#x27;14400&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-tokens&amp;#x27;, b&amp;#x27;15000&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-requests&amp;#x27;, b&amp;#x27;14372&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-tokens&amp;#x27;, b&amp;#x27;13724&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-requests&amp;#x27;, b&amp;#x27;2m47.997999999s&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-tokens&amp;#x27;, b&amp;#x27;5.103s&amp;#x27;), (b&amp;#x27;x-request-id&amp;#x27;, b&amp;#x27;req_01jbf23ydvfdmvh2v7matd573v&amp;#x27;), (b&amp;#x27;via&amp;#x27;, b&amp;#x27;1.1 google&amp;#x27;), (b&amp;#x27;alt-svc&amp;#x27;, b&amp;#x27;h3=&amp;quot;:443&amp;quot;; ma=86400&amp;#x27;), (b&amp;#x27;CF-Cache-Status&amp;#x27;, b&amp;#x27;DYNAMIC&amp;#x27;), (b&amp;#x27;Server&amp;#x27;, b&amp;#x27;cloudflare&amp;#x27;), (b&amp;#x27;CF-RAY&amp;#x27;, b&amp;#x27;8dac94622befcaad-HAM&amp;#x27;), (b&amp;#x27;Content-Encoding&amp;#x27;, b&amp;#x27;gzip&amp;#x27;)])\nINFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;HTTP/1.1 200 OK&amp;quot;\nDEBUG:httpcore.http11:receive_response_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.http11:receive_response_body.complete\nDEBUG:httpcore.http11:response_closed.started\nDEBUG:httpcore.http11:response_closed.complete\nDEBUG:groq._base_client:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;200 OK&amp;quot;\nDEBUG:httpcore.http11:receive_response_headers.complete return_value=(b&amp;#x27;HTTP/1.1&amp;#x27;, 200, b&amp;#x27;OK&amp;#x27;, [(b&amp;#x27;Date&amp;#x27;, b&amp;#x27;Wed, 30 Oct 2024 15:53:41 GMT&amp;#x27;), (b&amp;#x27;Content-Type&amp;#x27;, b&amp;#x27;application/json&amp;#x27;), (b&amp;#x27;Transfer-Encoding&amp;#x27;, b&amp;#x27;chunked&amp;#x27;), (b&amp;#x27;Connection&amp;#x27;, b&amp;#x27;keep-alive&amp;#x27;), (b&amp;#x27;Cache-Control&amp;#x27;, b&amp;#x27;private, max-age=0, no-store, no-cache, must-revalidate&amp;#x27;), (b&amp;#x27;vary&amp;#x27;, b&amp;#x27;Origin&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-requests&amp;#x27;, b&amp;#x27;14400&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-tokens&amp;#x27;, b&amp;#x27;15000&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-requests&amp;#x27;, b&amp;#x27;14370&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-tokens&amp;#x27;, b&amp;#x27;13726&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-requests&amp;#x27;, b&amp;#x27;2m59.997999999s&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-tokens&amp;#x27;, b&amp;#x27;5.096s&amp;#x27;), (b&amp;#x27;x-request-id&amp;#x27;, b&amp;#x27;req_01jbf23ye1er4vqfnx30xtqxcj&amp;#x27;), (b&amp;#x27;via&amp;#x27;, b&amp;#x27;1.1 google&amp;#x27;), (b&amp;#x27;alt-svc&amp;#x27;, b&amp;#x27;h3=&amp;quot;:443&amp;quot;; ma=86400&amp;#x27;), (b&amp;#x27;CF-Cache-Status&amp;#x27;, b&amp;#x27;DYNAMIC&amp;#x27;), (b&amp;#x27;Server&amp;#x27;, b&amp;#x27;cloudflare&amp;#x27;), (b&amp;#x27;CF-RAY&amp;#x27;, b&amp;#x27;8dac94622d3e4156-HAM&amp;#x27;), (b&amp;#x27;Content-Encoding&amp;#x27;, b&amp;#x27;gzip&amp;#x27;)])\nINFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;HTTP/1.1 200 OK&amp;quot;\nDEBUG:httpcore.http11:receive_response_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.http11:receive_response_body.complete\nDEBUG:httpcore.http11:response_closed.started\nDEBUG:httpcore.http11:response_closed.complete\nDEBUG:groq._base_client:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;200 OK&amp;quot;\nDEBUG:httpcore.http11:receive_response_headers.complete return_value=(b&amp;#x27;HTTP/1.1&amp;#x27;, 200, b&amp;#x27;OK&amp;#x27;, [(b&amp;#x27;Date&amp;#x27;, b&amp;#x27;Wed, 30 Oct 2024 15:53:41 GMT&amp;#x27;), (b&amp;#x27;Content-Type&amp;#x27;, b&amp;#x27;application/json&amp;#x27;), (b&amp;#x27;Transfer-Encoding&amp;#x27;, b&amp;#x27;chunked&amp;#x27;), (b&amp;#x27;Connection&amp;#x27;, b&amp;#x27;keep-alive&amp;#x27;), (b&amp;#x27;Cache-Control&amp;#x27;, b&amp;#x27;private, max-age=0, no-store, no-cache, must-revalidate&amp;#x27;), (b&amp;#x27;vary&amp;#x27;, b&amp;#x27;Origin&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-requests&amp;#x27;, b&amp;#x27;14400&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-tokens&amp;#x27;, b&amp;#x27;15000&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-requests&amp;#x27;, b&amp;#x27;14369&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-tokens&amp;#x27;, b&amp;#x27;13726&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-requests&amp;#x27;, b&amp;#x27;3m5.998999999s&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-tokens&amp;#x27;, b&amp;#x27;5.094s&amp;#x27;), (b&amp;#x27;x-request-id&amp;#x27;, b&amp;#x27;req_01jbf23ye4ec1rd23ah00qx7sc&amp;#x27;), (b&amp;#x27;via&amp;#x27;, b&amp;#x27;1.1 google&amp;#x27;), (b&amp;#x27;alt-svc&amp;#x27;, b&amp;#x27;h3=&amp;quot;:443&amp;quot;; ma=86400&amp;#x27;), (b&amp;#x27;CF-Cache-Status&amp;#x27;, b&amp;#x27;DYNAMIC&amp;#x27;), (b&amp;#x27;Server&amp;#x27;, b&amp;#x27;cloudflare&amp;#x27;), (b&amp;#x27;CF-RAY&amp;#x27;, b&amp;#x27;8dac946229fa62da-HAM&amp;#x27;), (b&amp;#x27;Content-Encoding&amp;#x27;, b&amp;#x27;gzip&amp;#x27;)])\nINFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;HTTP/1.1 200 OK&amp;quot;\nDEBUG:httpcore.http11:receive_response_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.http11:receive_response_body.complete\nDEBUG:httpcore.http11:response_closed.started\nDEBUG:httpcore.http11:response_closed.complete\nDEBUG:groq._base_client:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;200 OK&amp;quot;\nDEBUG:httpcore.http11:receive_response_headers.complete return_value=(b&amp;#x27;HTTP/1.1&amp;#x27;, 200, b&amp;#x27;OK&amp;#x27;, [(b&amp;#x27;Date&amp;#x27;, b&amp;#x27;Wed, 30 Oct 2024 15:53:41 GMT&amp;#x27;), (b&amp;#x27;Content-Type&amp;#x27;, b&amp;#x27;application/json&amp;#x27;), (b&amp;#x27;Transfer-Encoding&amp;#x27;, b&amp;#x27;chunked&amp;#x27;), (b&amp;#x27;Connection&amp;#x27;, b&amp;#x27;keep-alive&amp;#x27;), (b&amp;#x27;Cache-Control&amp;#x27;, b&amp;#x27;private, max-age=0, no-store, no-cache, must-revalidate&amp;#x27;), (b&amp;#x27;vary&amp;#x27;, b&amp;#x27;Origin&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-requests&amp;#x27;, b&amp;#x27;14400&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-tokens&amp;#x27;, b&amp;#x27;15000&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-requests&amp;#x27;, b&amp;#x27;14368&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-tokens&amp;#x27;, b&amp;#x27;13728&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-requests&amp;#x27;, b&amp;#x27;3m11.993999999s&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-tokens&amp;#x27;, b&amp;#x27;5.086s&amp;#x27;), (b&amp;#x27;x-request-id&amp;#x27;, b&amp;#x27;req_01jbf23yecfdms12a4rtfh3k87&amp;#x27;), (b&amp;#x27;via&amp;#x27;, b&amp;#x27;1.1 google&amp;#x27;), (b&amp;#x27;alt-svc&amp;#x27;, b&amp;#x27;h3=&amp;quot;:443&amp;quot;; ma=86400&amp;#x27;), (b&amp;#x27;CF-Cache-Status&amp;#x27;, b&amp;#x27;DYNAMIC&amp;#x27;), (b&amp;#x27;Server&amp;#x27;, b&amp;#x27;cloudflare&amp;#x27;), (b&amp;#x27;CF-RAY&amp;#x27;, b&amp;#x27;8dac94623b5f6301-HAM&amp;#x27;), (b&amp;#x27;Content-Encoding&amp;#x27;, b&amp;#x27;gzip&amp;#x27;)])\nINFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;HTTP/1.1 200 OK&amp;quot;\nDEBUG:httpcore.http11:receive_response_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.http11:receive_response_body.complete\nDEBUG:httpcore.http11:response_closed.started\nDEBUG:httpcore.http11:response_closed.complete\nDEBUG:groq._base_client:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;200 OK&amp;quot;\nDEBUG:httpcore.http11:receive_response_headers.complete return_value=(b&amp;#x27;HTTP/1.1&amp;#x27;, 429, b&amp;#x27;Too Many Requests&amp;#x27;, [(b&amp;#x27;Date&amp;#x27;, b&amp;#x27;Wed, 30 Oct 2024 15:53:42 GMT&amp;#x27;), (b&amp;#x27;Content-Type&amp;#x27;, b&amp;#x27;application/json&amp;#x27;), (b&amp;#x27;Content-Length&amp;#x27;, b&amp;#x27;349&amp;#x27;), (b&amp;#x27;Connection&amp;#x27;, b&amp;#x27;keep-alive&amp;#x27;), (b&amp;#x27;Cache-Control&amp;#x27;, b&amp;#x27;private, max-age=0, no-store, no-cache, must-revalidate&amp;#x27;), (b&amp;#x27;retry-after&amp;#x27;, b&amp;#x27;2&amp;#x27;), (b&amp;#x27;vary&amp;#x27;, b&amp;#x27;Origin&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-requests&amp;#x27;, b&amp;#x27;14400&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-tokens&amp;#x27;, b&amp;#x27;15000&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-requests&amp;#x27;, b&amp;#x27;14368&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-tokens&amp;#x27;, b&amp;#x27;13206&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-requests&amp;#x27;, b&amp;#x27;3m11.606999999s&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-tokens&amp;#x27;, b&amp;#x27;7.173s&amp;#x27;), (b&amp;#x27;x-request-id&amp;#x27;, b&amp;#x27;req_01jbf23ytqfsnty25gr3p2rhde&amp;#x27;), (b&amp;#x27;via&amp;#x27;, b&amp;#x27;1.1 google&amp;#x27;), (b&amp;#x27;alt-svc&amp;#x27;, b&amp;#x27;h3=&amp;quot;:443&amp;quot;; ma=86400&amp;#x27;), (b&amp;#x27;CF-Cache-Status&amp;#x27;, b&amp;#x27;DYNAMIC&amp;#x27;), (b&amp;#x27;Server&amp;#x27;, b&amp;#x27;cloudflare&amp;#x27;), (b&amp;#x27;CF-RAY&amp;#x27;, b&amp;#x27;8dac94621a424168-HAM&amp;#x27;)])\nINFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;HTTP/1.1 429 Too Many Requests&amp;quot;\nDEBUG:httpcore.http11:receive_response_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.http11:receive_response_body.complete\nDEBUG:httpcore.http11:response_closed.started\nDEBUG:httpcore.http11:response_closed.complete\nDEBUG:groq._base_client:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;429 Too Many Requests&amp;quot;\nDEBUG:groq._base_client:Encountered httpx.HTTPStatusError\nTraceback (most recent call last):\n  File &amp;quot;/Users/julian/Tresors/Privat/Code/fragment-editor-api/.venv-test/lib/python3.12/site-packages/groq/_base_client.py&amp;quot;, line 961, in _request\n    response.raise_for_status()\n  File &amp;quot;/Users/julian/Tresors/Privat/Code/fragment-editor-api/.venv-test/lib/python3.12/site-packages/httpx/_models.py&amp;quot;, line 763, in raise_for_status\n    raise HTTPStatusError(message, request=request, response=self)\nhttpx.HTTPStatusError: Client error &amp;#x27;429 Too Many Requests&amp;#x27; for url &amp;#x27;https://api.groq.com/openai/v1/chat/completions&amp;#x27;\nFor more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\nDEBUG:groq._base_client:Retrying due to status code 429\nDEBUG:groq._base_client:1 retry left\nINFO:groq._base_client:Retrying request to /openai/v1/chat/completions in 2.000000 seconds\nDEBUG:httpcore.http11:receive_response_headers.complete return_value=(b&amp;#x27;HTTP/1.1&amp;#x27;, 429, b&amp;#x27;Too Many Requests&amp;#x27;, [(b&amp;#x27;Date&amp;#x27;, b&amp;#x27;Wed, 30 Oct 2024 15:53:42 GMT&amp;#x27;), (b&amp;#x27;Content-Type&amp;#x27;, b&amp;#x27;application/json&amp;#x27;), (b&amp;#x27;Content-Length&amp;#x27;, b&amp;#x27;355&amp;#x27;), (b&amp;#x27;Connection&amp;#x27;, b&amp;#x27;keep-alive&amp;#x27;), (b&amp;#x27;Cache-Control&amp;#x27;, b&amp;#x27;private, max-age=0, no-store, no-cache, must-revalidate&amp;#x27;), (b&amp;#x27;retry-after&amp;#x27;, b&amp;#x27;2&amp;#x27;), (b&amp;#x27;vary&amp;#x27;, b&amp;#x27;Origin&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-requests&amp;#x27;, b&amp;#x27;14400&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-tokens&amp;#x27;, b&amp;#x27;15000&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-requests&amp;#x27;, b&amp;#x27;14368&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-tokens&amp;#x27;, b&amp;#x27;13208&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-requests&amp;#x27;, b&amp;#x27;3m11.600999999s&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-tokens&amp;#x27;, b&amp;#x27;7.167s&amp;#x27;), (b&amp;#x27;x-request-id&amp;#x27;, b&amp;#x27;req_01jbf23ytxe6dt2xcq2vsrb4m2&amp;#x27;), (b&amp;#x27;via&amp;#x27;, b&amp;#x27;1.1 google&amp;#x27;), (b&amp;#x27;alt-svc&amp;#x27;, b&amp;#x27;h3=&amp;quot;:443&amp;quot;; ma=86400&amp;#x27;), (b&amp;#x27;CF-Cache-Status&amp;#x27;, b&amp;#x27;DYNAMIC&amp;#x27;), (b&amp;#x27;Server&amp;#x27;, b&amp;#x27;cloudflare&amp;#x27;), (b&amp;#x27;CF-RAY&amp;#x27;, b&amp;#x27;8dac946229826311-HAM&amp;#x27;)])\nINFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;HTTP/1.1 429 Too Many Requests&amp;quot;\nDEBUG:httpcore.http11:receive_response_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.http11:receive_response_body.complete\nDEBUG:httpcore.http11:response_closed.started\nDEBUG:httpcore.http11:response_closed.complete\nDEBUG:groq._base_client:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;429 Too Many Requests&amp;quot;\nDEBUG:groq._base_client:Encountered httpx.HTTPStatusError\nTraceback (most recent call last):\n  File &amp;quot;/Users/julian/Tresors/Privat/Code/fragment-editor-api/.venv-test/lib/python3.12/site-packages/groq/_base_client.py&amp;quot;, line 961, in _request\n    response.raise_for_status()\n  File &amp;quot;/Users/julian/Tresors/Privat/Code/fragment-editor-api/.venv-test/lib/python3.12/site-packages/httpx/_models.py&amp;quot;, line 763, in raise_for_status\n    raise HTTPStatusError(message, request=request, response=self)\nhttpx.HTTPStatusError: Client error &amp;#x27;429 Too Many Requests&amp;#x27; for url &amp;#x27;https://api.groq.com/openai/v1/chat/completions&amp;#x27;\nFor more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\nDEBUG:groq._base_client:Retrying due to status code 429\nDEBUG:groq._base_client:1 retry left\nINFO:groq._base_client:Retrying request to /openai/v1/chat/completions in 2.000000 seconds\nDEBUG:groq._base_client:Request options: {&amp;#x27;method&amp;#x27;: &amp;#x27;post&amp;#x27;, &amp;#x27;url&amp;#x27;: &amp;#x27;/openai/v1/chat/completions&amp;#x27;, &amp;#x27;files&amp;#x27;: None, &amp;#x27;json_data&amp;#x27;: {&amp;#x27;messages&amp;#x27;: [{&amp;#x27;role&amp;#x27;: &amp;#x27;system&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate a JSON response following these rules:\\n1. Return exactly ONE compressed version:\\n   {&amp;quot;versions&amp;quot;: [{&amp;quot;text&amp;quot;: &amp;quot;compressed version&amp;quot;}]}\\n2. Target exactly the specified percentage of original length\\n3. Maintain core meaning while removing less essential details\\n4. Ensure complete sentences and proper punctuation\\n5. If task cannot be completed: {&amp;quot;error&amp;quot;: &amp;quot;specific reason&amp;quot;}&amp;#x27;}, {&amp;#x27;role&amp;#x27;: &amp;#x27;user&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate ONE compressed version at 50% length:\\n        Original length: 2 tokens\\n        Original text: Test content&amp;#x27;}], &amp;#x27;model&amp;#x27;: &amp;#x27;llama3-groq-70b-8192-tool-use-preview&amp;#x27;, &amp;#x27;max_tokens&amp;#x27;: 1000, &amp;#x27;temperature&amp;#x27;: 0.7}}\nDEBUG:httpcore.http11:send_request_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.http11:send_request_headers.complete\nDEBUG:httpcore.http11:send_request_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.http11:send_request_body.complete\nDEBUG:httpcore.http11:receive_response_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.http11:receive_response_headers.complete return_value=(b&amp;#x27;HTTP/1.1&amp;#x27;, 200, b&amp;#x27;OK&amp;#x27;, [(b&amp;#x27;Date&amp;#x27;, b&amp;#x27;Wed, 30 Oct 2024 15:53:43 GMT&amp;#x27;), (b&amp;#x27;Content-Type&amp;#x27;, b&amp;#x27;application/json&amp;#x27;), (b&amp;#x27;Transfer-Encoding&amp;#x27;, b&amp;#x27;chunked&amp;#x27;), (b&amp;#x27;Connection&amp;#x27;, b&amp;#x27;keep-alive&amp;#x27;), (b&amp;#x27;Cache-Control&amp;#x27;, b&amp;#x27;private, max-age=0, no-store, no-cache, must-revalidate&amp;#x27;), (b&amp;#x27;vary&amp;#x27;, b&amp;#x27;Origin&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-requests&amp;#x27;, b&amp;#x27;14400&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-tokens&amp;#x27;, b&amp;#x27;15000&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-requests&amp;#x27;, b&amp;#x27;14367&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-tokens&amp;#x27;, b&amp;#x27;13525&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-requests&amp;#x27;, b&amp;#x27;3m15.798999999s&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-tokens&amp;#x27;, b&amp;#x27;5.897s&amp;#x27;), (b&amp;#x27;x-request-id&amp;#x27;, b&amp;#x27;req_01jbf240k5f4av0c7bqcqzrywx&amp;#x27;), (b&amp;#x27;via&amp;#x27;, b&amp;#x27;1.1 google&amp;#x27;), (b&amp;#x27;alt-svc&amp;#x27;, b&amp;#x27;h3=&amp;quot;:443&amp;quot;; ma=86400&amp;#x27;), (b&amp;#x27;CF-Cache-Status&amp;#x27;, b&amp;#x27;DYNAMIC&amp;#x27;), (b&amp;#x27;Server&amp;#x27;, b&amp;#x27;cloudflare&amp;#x27;), (b&amp;#x27;CF-RAY&amp;#x27;, b&amp;#x27;8dac9470087bca58-HAM&amp;#x27;), (b&amp;#x27;Content-Encoding&amp;#x27;, b&amp;#x27;gzip&amp;#x27;)])\nINFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;HTTP/1.1 200 OK&amp;quot;\nDEBUG:httpcore.http11:receive_response_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.http11:receive_response_body.complete\nDEBUG:httpcore.http11:response_closed.started\nDEBUG:httpcore.http11:response_closed.complete\nDEBUG:groq._base_client:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;200 OK&amp;quot;\nDEBUG:groq._base_client:Request options: {&amp;#x27;method&amp;#x27;: &amp;#x27;post&amp;#x27;, &amp;#x27;url&amp;#x27;: &amp;#x27;/openai/v1/chat/completions&amp;#x27;, &amp;#x27;files&amp;#x27;: None, &amp;#x27;json_data&amp;#x27;: {&amp;#x27;messages&amp;#x27;: [{&amp;#x27;role&amp;#x27;: &amp;#x27;system&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate a JSON response following these rules:\\n1. Return exactly ONE compressed version:\\n   {&amp;quot;versions&amp;quot;: [{&amp;quot;text&amp;quot;: &amp;quot;compressed version&amp;quot;}]}\\n2. Target exactly the specified percentage of original length\\n3. Maintain core meaning while removing less essential details\\n4. Ensure complete sentences and proper punctuation\\n5. If task cannot be completed: {&amp;quot;error&amp;quot;: &amp;quot;specific reason&amp;quot;}&amp;#x27;}, {&amp;#x27;role&amp;#x27;: &amp;#x27;user&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate ONE compressed version at 50% length:\\n        Original length: 2 tokens\\n        Original text: Test content&amp;#x27;}], &amp;#x27;model&amp;#x27;: &amp;#x27;llama3-groq-70b-8192-tool-use-preview&amp;#x27;, &amp;#x27;max_tokens&amp;#x27;: 1000, &amp;#x27;temperature&amp;#x27;: 0.7}}\nDEBUG:httpcore.http11:send_request_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:groq._base_client:Request options: {&amp;#x27;method&amp;#x27;: &amp;#x27;post&amp;#x27;, &amp;#x27;url&amp;#x27;: &amp;#x27;/openai/v1/chat/completions&amp;#x27;, &amp;#x27;files&amp;#x27;: None, &amp;#x27;json_data&amp;#x27;: {&amp;#x27;messages&amp;#x27;: [{&amp;#x27;role&amp;#x27;: &amp;#x27;system&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate a JSON response following these rules:\\n1. Return exactly ONE compressed version:\\n   {&amp;quot;versions&amp;quot;: [{&amp;quot;text&amp;quot;: &amp;quot;compressed version&amp;quot;}]}\\n2. Target exactly the specified percentage of original length\\n3. Maintain core meaning while removing less essential details\\n4. Ensure complete sentences and proper punctuation\\n5. If task cannot be completed: {&amp;quot;error&amp;quot;: &amp;quot;specific reason&amp;quot;}&amp;#x27;}, {&amp;#x27;role&amp;#x27;: &amp;#x27;user&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate ONE compressed version at 50% length:\\n        Original length: 2 tokens\\n        Original text: Test content&amp;#x27;}], &amp;#x27;model&amp;#x27;: &amp;#x27;llama3-groq-70b-8192-tool-use-preview&amp;#x27;, &amp;#x27;max_tokens&amp;#x27;: 1000, &amp;#x27;temperature&amp;#x27;: 0.7}}\nDEBUG:httpcore.http11:send_request_headers.complete\nDEBUG:httpcore.http11:send_request_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.http11:send_request_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.http11:send_request_body.complete\nDEBUG:httpcore.http11:receive_response_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.http11:send_request_headers.complete\nDEBUG:httpcore.http11:send_request_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.http11:send_request_body.complete\nDEBUG:httpcore.http11:receive_response_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.http11:receive_response_headers.complete return_value=(b&amp;#x27;HTTP/1.1&amp;#x27;, 429, b&amp;#x27;Too Many Requests&amp;#x27;, [(b&amp;#x27;Date&amp;#x27;, b&amp;#x27;Wed, 30 Oct 2024 15:53:44 GMT&amp;#x27;), (b&amp;#x27;Content-Type&amp;#x27;, b&amp;#x27;application/json&amp;#x27;), (b&amp;#x27;Content-Length&amp;#x27;, b&amp;#x27;349&amp;#x27;), (b&amp;#x27;Connection&amp;#x27;, b&amp;#x27;keep-alive&amp;#x27;), (b&amp;#x27;Cache-Control&amp;#x27;, b&amp;#x27;private, max-age=0, no-store, no-cache, must-revalidate&amp;#x27;), (b&amp;#x27;retry-after&amp;#x27;, b&amp;#x27;2&amp;#x27;), (b&amp;#x27;vary&amp;#x27;, b&amp;#x27;Origin&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-requests&amp;#x27;, b&amp;#x27;14400&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-tokens&amp;#x27;, b&amp;#x27;15000&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-requests&amp;#x27;, b&amp;#x27;14367&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-tokens&amp;#x27;, b&amp;#x27;13628&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-requests&amp;#x27;, b&amp;#x27;3m17.621999999s&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-tokens&amp;#x27;, b&amp;#x27;5.488s&amp;#x27;), (b&amp;#x27;x-request-id&amp;#x27;, b&amp;#x27;req_01jbf240z1ej9bj0th02egg5kp&amp;#x27;), (b&amp;#x27;via&amp;#x27;, b&amp;#x27;1.1 google&amp;#x27;), (b&amp;#x27;alt-svc&amp;#x27;, b&amp;#x27;h3=&amp;quot;:443&amp;quot;; ma=86400&amp;#x27;), (b&amp;#x27;CF-Cache-Status&amp;#x27;, b&amp;#x27;DYNAMIC&amp;#x27;), (b&amp;#x27;Server&amp;#x27;, b&amp;#x27;cloudflare&amp;#x27;), (b&amp;#x27;CF-RAY&amp;#x27;, b&amp;#x27;8dac94727afeca58-HAM&amp;#x27;)])\nINFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;HTTP/1.1 429 Too Many Requests&amp;quot;\nDEBUG:httpcore.http11:receive_response_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.http11:receive_response_body.complete\nDEBUG:httpcore.http11:response_closed.started\nDEBUG:httpcore.http11:response_closed.complete\nDEBUG:groq._base_client:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;429 Too Many Requests&amp;quot;\nDEBUG:groq._base_client:Encountered httpx.HTTPStatusError\nTraceback (most recent call last):\n  File &amp;quot;/Users/julian/Tresors/Privat/Code/fragment-editor-api/.venv-test/lib/python3.12/site-packages/groq/_base_client.py&amp;quot;, line 961, in _request\n    response.raise_for_status()\n  File &amp;quot;/Users/julian/Tresors/Privat/Code/fragment-editor-api/.venv-test/lib/python3.12/site-packages/httpx/_models.py&amp;quot;, line 763, in raise_for_status\n    raise HTTPStatusError(message, request=request, response=self)\nhttpx.HTTPStatusError: Client error &amp;#x27;429 Too Many Requests&amp;#x27; for url &amp;#x27;https://api.groq.com/openai/v1/chat/completions&amp;#x27;\nFor more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File &amp;quot;/Users/julian/Tresors/Privat/Code/fragment-editor-api/.venv-test/lib/python3.12/site-packages/groq/_base_client.py&amp;quot;, line 961, in _request\n    response.raise_for_status()\n  File &amp;quot;/Users/julian/Tresors/Privat/Code/fragment-editor-api/.venv-test/lib/python3.12/site-packages/httpx/_models.py&amp;quot;, line 763, in raise_for_status\n    raise HTTPStatusError(message, request=request, response=self)\nhttpx.HTTPStatusError: Client error &amp;#x27;429 Too Many Requests&amp;#x27; for url &amp;#x27;https://api.groq.com/openai/v1/chat/completions&amp;#x27;\nFor more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\nDEBUG:groq._base_client:Retrying due to status code 429\nDEBUG:groq._base_client:0 retries left\nINFO:groq._base_client:Retrying request to /openai/v1/chat/completions in 2.000000 seconds\nDEBUG:httpcore.http11:receive_response_headers.complete return_value=(b&amp;#x27;HTTP/1.1&amp;#x27;, 429, b&amp;#x27;Too Many Requests&amp;#x27;, [(b&amp;#x27;Date&amp;#x27;, b&amp;#x27;Wed, 30 Oct 2024 15:53:44 GMT&amp;#x27;), (b&amp;#x27;Content-Type&amp;#x27;, b&amp;#x27;application/json&amp;#x27;), (b&amp;#x27;Content-Length&amp;#x27;, b&amp;#x27;355&amp;#x27;), (b&amp;#x27;Connection&amp;#x27;, b&amp;#x27;keep-alive&amp;#x27;), (b&amp;#x27;Cache-Control&amp;#x27;, b&amp;#x27;private, max-age=0, no-store, no-cache, must-revalidate&amp;#x27;), (b&amp;#x27;retry-after&amp;#x27;, b&amp;#x27;2&amp;#x27;), (b&amp;#x27;vary&amp;#x27;, b&amp;#x27;Origin&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-requests&amp;#x27;, b&amp;#x27;14400&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-tokens&amp;#x27;, b&amp;#x27;15000&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-requests&amp;#x27;, b&amp;#x27;14367&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-tokens&amp;#x27;, b&amp;#x27;13732&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-requests&amp;#x27;, b&amp;#x27;3m17.203s&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-tokens&amp;#x27;, b&amp;#x27;5.069s&amp;#x27;), (b&amp;#x27;x-request-id&amp;#x27;, b&amp;#x27;req_01jbf241c4fj3an42r6ft43kc1&amp;#x27;), (b&amp;#x27;via&amp;#x27;, b&amp;#x27;1.1 google&amp;#x27;), (b&amp;#x27;alt-svc&amp;#x27;, b&amp;#x27;h3=&amp;quot;:443&amp;quot;; ma=86400&amp;#x27;), (b&amp;#x27;CF-Cache-Status&amp;#x27;, b&amp;#x27;DYNAMIC&amp;#x27;), (b&amp;#x27;Server&amp;#x27;, b&amp;#x27;cloudflare&amp;#x27;), (b&amp;#x27;CF-RAY&amp;#x27;, b&amp;#x27;8dac947289e04168-HAM&amp;#x27;)])\nINFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;HTTP/1.1 429 Too Many Requests&amp;quot;\nDEBUG:httpcore.http11:receive_response_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.http11:receive_response_body.complete\nDEBUG:httpcore.http11:response_closed.started\nDEBUG:httpcore.http11:response_closed.complete\nDEBUG:groq._base_client:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;429 Too Many Requests&amp;quot;\nDEBUG:groq._base_client:Encountered httpx.HTTPStatusError\nTraceback (most recent call last):\n  File &amp;quot;/Users/julian/Tresors/Privat/Code/fragment-editor-api/.venv-test/lib/python3.12/site-packages/groq/_base_client.py&amp;quot;, line 961, in _request\n    response.raise_for_status()\n  File &amp;quot;/Users/julian/Tresors/Privat/Code/fragment-editor-api/.venv-test/lib/python3.12/site-packages/httpx/_models.py&amp;quot;, line 763, in raise_for_status\n    raise HTTPStatusError(message, request=request, response=self)\nhttpx.HTTPStatusError: Client error &amp;#x27;429 Too Many Requests&amp;#x27; for url &amp;#x27;https://api.groq.com/openai/v1/chat/completions&amp;#x27;\nFor more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File &amp;quot;/Users/julian/Tresors/Privat/Code/fragment-editor-api/.venv-test/lib/python3.12/site-packages/groq/_base_client.py&amp;quot;, line 961, in _request\n    response.raise_for_status()\n  File &amp;quot;/Users/julian/Tresors/Privat/Code/fragment-editor-api/.venv-test/lib/python3.12/site-packages/httpx/_models.py&amp;quot;, line 763, in raise_for_status\n    raise HTTPStatusError(message, request=request, response=self)\nhttpx.HTTPStatusError: Client error &amp;#x27;429 Too Many Requests&amp;#x27; for url &amp;#x27;https://api.groq.com/openai/v1/chat/completions&amp;#x27;\nFor more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\nDEBUG:groq._base_client:Retrying due to status code 429\nDEBUG:groq._base_client:0 retries left\nINFO:groq._base_client:Retrying request to /openai/v1/chat/completions in 2.000000 seconds\nDEBUG:groq._base_client:Request options: {&amp;#x27;method&amp;#x27;: &amp;#x27;post&amp;#x27;, &amp;#x27;url&amp;#x27;: &amp;#x27;/openai/v1/chat/completions&amp;#x27;, &amp;#x27;files&amp;#x27;: None, &amp;#x27;json_data&amp;#x27;: {&amp;#x27;messages&amp;#x27;: [{&amp;#x27;role&amp;#x27;: &amp;#x27;system&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate a JSON response following these rules:\\n1. Return exactly ONE compressed version:\\n   {&amp;quot;versions&amp;quot;: [{&amp;quot;text&amp;quot;: &amp;quot;compressed version&amp;quot;}]}\\n2. Target exactly the specified percentage of original length\\n3. Maintain core meaning while removing less essential details\\n4. Ensure complete sentences and proper punctuation\\n5. If task cannot be completed: {&amp;quot;error&amp;quot;: &amp;quot;specific reason&amp;quot;}&amp;#x27;}, {&amp;#x27;role&amp;#x27;: &amp;#x27;user&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate ONE compressed version at 50% length:\\n        Original length: 2 tokens\\n        Original text: Test content&amp;#x27;}], &amp;#x27;model&amp;#x27;: &amp;#x27;llama3-groq-70b-8192-tool-use-preview&amp;#x27;, &amp;#x27;max_tokens&amp;#x27;: 1000, &amp;#x27;temperature&amp;#x27;: 0.7}}\nDEBUG:httpcore.http11:send_request_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.http11:send_request_headers.complete\nDEBUG:httpcore.http11:send_request_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.http11:send_request_body.complete\nDEBUG:httpcore.http11:receive_response_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.http11:receive_response_headers.complete return_value=(b&amp;#x27;HTTP/1.1&amp;#x27;, 200, b&amp;#x27;OK&amp;#x27;, [(b&amp;#x27;Date&amp;#x27;, b&amp;#x27;Wed, 30 Oct 2024 15:53:46 GMT&amp;#x27;), (b&amp;#x27;Content-Type&amp;#x27;, b&amp;#x27;application/json&amp;#x27;), (b&amp;#x27;Transfer-Encoding&amp;#x27;, b&amp;#x27;chunked&amp;#x27;), (b&amp;#x27;Connection&amp;#x27;, b&amp;#x27;keep-alive&amp;#x27;), (b&amp;#x27;Cache-Control&amp;#x27;, b&amp;#x27;private, max-age=0, no-store, no-cache, must-revalidate&amp;#x27;), (b&amp;#x27;vary&amp;#x27;, b&amp;#x27;Origin&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-requests&amp;#x27;, b&amp;#x27;14400&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-tokens&amp;#x27;, b&amp;#x27;15000&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-requests&amp;#x27;, b&amp;#x27;14366&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-tokens&amp;#x27;, b&amp;#x27;14041&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-requests&amp;#x27;, b&amp;#x27;3m21.435s&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-tokens&amp;#x27;, b&amp;#x27;3.834s&amp;#x27;), (b&amp;#x27;x-request-id&amp;#x27;, b&amp;#x27;req_01jbf2433bebpbtfzsv2ccmjca&amp;#x27;), (b&amp;#x27;via&amp;#x27;, b&amp;#x27;1.1 google&amp;#x27;), (b&amp;#x27;alt-svc&amp;#x27;, b&amp;#x27;h3=&amp;quot;:443&amp;quot;; ma=86400&amp;#x27;), (b&amp;#x27;CF-Cache-Status&amp;#x27;, b&amp;#x27;DYNAMIC&amp;#x27;), (b&amp;#x27;Server&amp;#x27;, b&amp;#x27;cloudflare&amp;#x27;), (b&amp;#x27;CF-RAY&amp;#x27;, b&amp;#x27;8dac94801a6fca58-HAM&amp;#x27;), (b&amp;#x27;Content-Encoding&amp;#x27;, b&amp;#x27;gzip&amp;#x27;)])\nINFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;HTTP/1.1 200 OK&amp;quot;\nDEBUG:httpcore.http11:receive_response_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.http11:receive_response_body.complete\nDEBUG:httpcore.http11:response_closed.started\nDEBUG:httpcore.http11:response_closed.complete\nDEBUG:groq._base_client:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;200 OK&amp;quot;\nDEBUG:groq._base_client:Request options: {&amp;#x27;method&amp;#x27;: &amp;#x27;post&amp;#x27;, &amp;#x27;url&amp;#x27;: &amp;#x27;/openai/v1/chat/completions&amp;#x27;, &amp;#x27;files&amp;#x27;: None, &amp;#x27;json_data&amp;#x27;: {&amp;#x27;messages&amp;#x27;: [{&amp;#x27;role&amp;#x27;: &amp;#x27;system&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate a JSON response following these rules:\\n1. Return exactly ONE compressed version:\\n   {&amp;quot;versions&amp;quot;: [{&amp;quot;text&amp;quot;: &amp;quot;compressed version&amp;quot;}]}\\n2. Target exactly the specified percentage of original length\\n3. Maintain core meaning while removing less essential details\\n4. Ensure complete sentences and proper punctuation\\n5. If task cannot be completed: {&amp;quot;error&amp;quot;: &amp;quot;specific reason&amp;quot;}&amp;#x27;}, {&amp;#x27;role&amp;#x27;: &amp;#x27;user&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate ONE compressed version at 50% length:\\n        Original length: 2 tokens\\n        Original text: Test content&amp;#x27;}], &amp;#x27;model&amp;#x27;: &amp;#x27;llama3-groq-70b-8192-tool-use-preview&amp;#x27;, &amp;#x27;max_tokens&amp;#x27;: 1000, &amp;#x27;temperature&amp;#x27;: 0.7}}\nDEBUG:httpcore.http11:send_request_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.http11:send_request_headers.complete\nDEBUG:httpcore.http11:send_request_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.http11:send_request_body.complete\nDEBUG:httpcore.http11:receive_response_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.http11:receive_response_headers.complete return_value=(b&amp;#x27;HTTP/1.1&amp;#x27;, 429, b&amp;#x27;Too Many Requests&amp;#x27;, [(b&amp;#x27;Date&amp;#x27;, b&amp;#x27;Wed, 30 Oct 2024 15:53:46 GMT&amp;#x27;), (b&amp;#x27;Content-Type&amp;#x27;, b&amp;#x27;application/json&amp;#x27;), (b&amp;#x27;Content-Length&amp;#x27;, b&amp;#x27;349&amp;#x27;), (b&amp;#x27;Connection&amp;#x27;, b&amp;#x27;keep-alive&amp;#x27;), (b&amp;#x27;Cache-Control&amp;#x27;, b&amp;#x27;private, max-age=0, no-store, no-cache, must-revalidate&amp;#x27;), (b&amp;#x27;retry-after&amp;#x27;, b&amp;#x27;2&amp;#x27;), (b&amp;#x27;vary&amp;#x27;, b&amp;#x27;Origin&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-requests&amp;#x27;, b&amp;#x27;14400&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-tokens&amp;#x27;, b&amp;#x27;15000&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-requests&amp;#x27;, b&amp;#x27;14366&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-tokens&amp;#x27;, b&amp;#x27;14152&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-requests&amp;#x27;, b&amp;#x27;3m23.587s&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-tokens&amp;#x27;, b&amp;#x27;3.389s&amp;#x27;), (b&amp;#x27;x-request-id&amp;#x27;, b&amp;#x27;req_01jbf243g9e40vrha3xsxg5qkj&amp;#x27;), (b&amp;#x27;via&amp;#x27;, b&amp;#x27;1.1 google&amp;#x27;), (b&amp;#x27;alt-svc&amp;#x27;, b&amp;#x27;h3=&amp;quot;:443&amp;quot;; ma=86400&amp;#x27;), (b&amp;#x27;CF-Cache-Status&amp;#x27;, b&amp;#x27;DYNAMIC&amp;#x27;), (b&amp;#x27;Server&amp;#x27;, b&amp;#x27;cloudflare&amp;#x27;), (b&amp;#x27;CF-RAY&amp;#x27;, b&amp;#x27;8dac9482bd39ca58-HAM&amp;#x27;)])\nINFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;HTTP/1.1 429 Too Many Requests&amp;quot;\nDEBUG:httpcore.http11:receive_response_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG:httpcore.http11:receive_response_body.complete\nDEBUG:httpcore.http11:response_closed.started\nDEBUG:httpcore.http11:response_closed.complete\nDEBUG:httpcore.connection:close.started\nDEBUG:httpcore.connection:close.complete\nDEBUG:httpcore.connection:close.started\nDEBUG:httpcore.connection:close.complete\nDEBUG:httpcore.connection:close.started\nDEBUG:httpcore.connection:close.complete\nDEBUG:httpcore.connection:close.started\nDEBUG:httpcore.connection:close.complete\nDEBUG:httpcore.connection:close.started\nDEBUG:httpcore.connection:close.complete\nDEBUG:httpcore.connection:close.started\nDEBUG:httpcore.connection:close.complete\nDEBUG:httpcore.connection:close.started\nDEBUG:httpcore.connection:close.complete\nDEBUG:groq._base_client:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;429 Too Many Requests&amp;quot;\nDEBUG:groq._base_client:Encountered httpx.HTTPStatusError\nTraceback (most recent call last):\n  File &amp;quot;/Users/julian/Tresors/Privat/Code/fragment-editor-api/.venv-test/lib/python3.12/site-packages/groq/_base_client.py&amp;quot;, line 961, in _request\n    response.raise_for_status()\n  File &amp;quot;/Users/julian/Tresors/Privat/Code/fragment-editor-api/.venv-test/lib/python3.12/site-packages/httpx/_models.py&amp;quot;, line 763, in raise_for_status\n    raise HTTPStatusError(message, request=request, response=self)\nhttpx.HTTPStatusError: Client error &amp;#x27;429 Too Many Requests&amp;#x27; for url &amp;#x27;https://api.groq.com/openai/v1/chat/completions&amp;#x27;\nFor more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File &amp;quot;/Users/julian/Tresors/Privat/Code/fragment-editor-api/.venv-test/lib/python3.12/site-packages/groq/_base_client.py&amp;quot;, line 961, in _request\n    response.raise_for_status()\n  File &amp;quot;/Users/julian/Tresors/Privat/Code/fragment-editor-api/.venv-test/lib/python3.12/site-packages/httpx/_models.py&amp;quot;, line 763, in raise_for_status\n    raise HTTPStatusError(message, request=request, response=self)\nhttpx.HTTPStatusError: Client error &amp;#x27;429 Too Many Requests&amp;#x27; for url &amp;#x27;https://api.groq.com/openai/v1/chat/completions&amp;#x27;\nFor more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File &amp;quot;/Users/julian/Tresors/Privat/Code/fragment-editor-api/.venv-test/lib/python3.12/site-packages/groq/_base_client.py&amp;quot;, line 961, in _request\n    response.raise_for_status()\n  File &amp;quot;/Users/julian/Tresors/Privat/Code/fragment-editor-api/.venv-test/lib/python3.12/site-packages/httpx/_models.py&amp;quot;, line 763, in raise_for_status\n    raise HTTPStatusError(message, request=request, response=self)\nhttpx.HTTPStatusError: Client error &amp;#x27;429 Too Many Requests&amp;#x27; for url &amp;#x27;https://api.groq.com/openai/v1/chat/completions&amp;#x27;\nFor more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\nDEBUG:groq._base_client:Re-raising status error\n\n------------------------------ Captured log call -------------------------------\nDEBUG    app:__init__.py:31 Headers: {&amp;#x27;User-Agent&amp;#x27;: &amp;#x27;Werkzeug/3.0.6&amp;#x27;, &amp;#x27;Host&amp;#x27;: &amp;#x27;localhost&amp;#x27;, &amp;#x27;Content-Type&amp;#x27;: &amp;#x27;application/json&amp;#x27;, &amp;#x27;Content-Length&amp;#x27;: &amp;#x27;52&amp;#x27;, &amp;#x27;Authorization&amp;#x27;: &amp;#x27;Bearer test_key&amp;#x27;}\nDEBUG    app:__init__.py:31 Headers: {&amp;#x27;User-Agent&amp;#x27;: &amp;#x27;Werkzeug/3.0.6&amp;#x27;, &amp;#x27;Host&amp;#x27;: &amp;#x27;localhost&amp;#x27;, &amp;#x27;Content-Type&amp;#x27;: &amp;#x27;application/json&amp;#x27;, &amp;#x27;Content-Length&amp;#x27;: &amp;#x27;52&amp;#x27;, &amp;#x27;Authorization&amp;#x27;: &amp;#x27;Bearer test_key&amp;#x27;}\nDEBUG    app:__init__.py:32 Body: b&amp;#x27;{&amp;quot;content&amp;quot;: &amp;quot;Test content&amp;quot;, &amp;quot;target_percentage&amp;quot;: 50}&amp;#x27;\nDEBUG    app:__init__.py:31 Headers: {&amp;#x27;User-Agent&amp;#x27;: &amp;#x27;Werkzeug/3.0.6&amp;#x27;, &amp;#x27;Host&amp;#x27;: &amp;#x27;localhost&amp;#x27;, &amp;#x27;Content-Type&amp;#x27;: &amp;#x27;application/json&amp;#x27;, &amp;#x27;Content-Length&amp;#x27;: &amp;#x27;52&amp;#x27;, &amp;#x27;Authorization&amp;#x27;: &amp;#x27;Bearer test_key&amp;#x27;}\nDEBUG    app:__init__.py:32 Body: b&amp;#x27;{&amp;quot;content&amp;quot;: &amp;quot;Test content&amp;quot;, &amp;quot;target_percentage&amp;quot;: 50}&amp;#x27;\nDEBUG    app:__init__.py:31 Headers: {&amp;#x27;User-Agent&amp;#x27;: &amp;#x27;Werkzeug/3.0.6&amp;#x27;, &amp;#x27;Host&amp;#x27;: &amp;#x27;localhost&amp;#x27;, &amp;#x27;Content-Type&amp;#x27;: &amp;#x27;application/json&amp;#x27;, &amp;#x27;Content-Length&amp;#x27;: &amp;#x27;52&amp;#x27;, &amp;#x27;Authorization&amp;#x27;: &amp;#x27;Bearer test_key&amp;#x27;}\nDEBUG    app:__init__.py:33 Query Params: {}\nDEBUG    app:__init__.py:31 Headers: {&amp;#x27;User-Agent&amp;#x27;: &amp;#x27;Werkzeug/3.0.6&amp;#x27;, &amp;#x27;Host&amp;#x27;: &amp;#x27;localhost&amp;#x27;, &amp;#x27;Content-Type&amp;#x27;: &amp;#x27;application/json&amp;#x27;, &amp;#x27;Content-Length&amp;#x27;: &amp;#x27;52&amp;#x27;, &amp;#x27;Authorization&amp;#x27;: &amp;#x27;Bearer test_key&amp;#x27;}\nDEBUG    app:__init__.py:32 Body: b&amp;#x27;{&amp;quot;content&amp;quot;: &amp;quot;Test content&amp;quot;, &amp;quot;target_percentage&amp;quot;: 50}&amp;#x27;\nDEBUG    app:__init__.py:33 Query Params: {}\nDEBUG    app:__init__.py:31 Headers: {&amp;#x27;User-Agent&amp;#x27;: &amp;#x27;Werkzeug/3.0.6&amp;#x27;, &amp;#x27;Host&amp;#x27;: &amp;#x27;localhost&amp;#x27;, &amp;#x27;Content-Type&amp;#x27;: &amp;#x27;application/json&amp;#x27;, &amp;#x27;Content-Length&amp;#x27;: &amp;#x27;52&amp;#x27;, &amp;#x27;Authorization&amp;#x27;: &amp;#x27;Bearer test_key&amp;#x27;}\nDEBUG    app:__init__.py:32 Body: b&amp;#x27;{&amp;quot;content&amp;quot;: &amp;quot;Test content&amp;quot;, &amp;quot;target_percentage&amp;quot;: 50}&amp;#x27;\nDEBUG    app:__init__.py:34 Route: POST /text/v1/compress/\nDEBUG    app:__init__.py:31 Headers: {&amp;#x27;User-Agent&amp;#x27;: &amp;#x27;Werkzeug/3.0.6&amp;#x27;, &amp;#x27;Host&amp;#x27;: &amp;#x27;localhost&amp;#x27;, &amp;#x27;Content-Type&amp;#x27;: &amp;#x27;application/json&amp;#x27;, &amp;#x27;Content-Length&amp;#x27;: &amp;#x27;52&amp;#x27;, &amp;#x27;Authorization&amp;#x27;: &amp;#x27;Bearer test_key&amp;#x27;}\nDEBUG    app:__init__.py:32 Body: b&amp;#x27;{&amp;quot;content&amp;quot;: &amp;quot;Test content&amp;quot;, &amp;quot;target_percentage&amp;quot;: 50}&amp;#x27;\nDEBUG    app:__init__.py:33 Query Params: {}\nDEBUG    app:__init__.py:31 Headers: {&amp;#x27;User-Agent&amp;#x27;: &amp;#x27;Werkzeug/3.0.6&amp;#x27;, &amp;#x27;Host&amp;#x27;: &amp;#x27;localhost&amp;#x27;, &amp;#x27;Content-Type&amp;#x27;: &amp;#x27;application/json&amp;#x27;, &amp;#x27;Content-Length&amp;#x27;: &amp;#x27;52&amp;#x27;, &amp;#x27;Authorization&amp;#x27;: &amp;#x27;Bearer test_key&amp;#x27;}\nDEBUG    app:__init__.py:34 Route: POST /text/v1/compress/\nDEBUG    app:__init__.py:31 Headers: {&amp;#x27;User-Agent&amp;#x27;: &amp;#x27;Werkzeug/3.0.6&amp;#x27;, &amp;#x27;Host&amp;#x27;: &amp;#x27;localhost&amp;#x27;, &amp;#x27;Content-Type&amp;#x27;: &amp;#x27;application/json&amp;#x27;, &amp;#x27;Content-Length&amp;#x27;: &amp;#x27;52&amp;#x27;, &amp;#x27;Authorization&amp;#x27;: &amp;#x27;Bearer test_key&amp;#x27;}\nDEBUG    app:__init__.py:32 Body: b&amp;#x27;{&amp;quot;content&amp;quot;: &amp;quot;Test content&amp;quot;, &amp;quot;target_percentage&amp;quot;: 50}&amp;#x27;\nDEBUG    app:__init__.py:33 Query Params: {}\nDEBUG    app:__init__.py:31 Headers: {&amp;#x27;User-Agent&amp;#x27;: &amp;#x27;Werkzeug/3.0.6&amp;#x27;, &amp;#x27;Host&amp;#x27;: &amp;#x27;localhost&amp;#x27;, &amp;#x27;Content-Type&amp;#x27;: &amp;#x27;application/json&amp;#x27;, &amp;#x27;Content-Length&amp;#x27;: &amp;#x27;52&amp;#x27;, &amp;#x27;Authorization&amp;#x27;: &amp;#x27;Bearer test_key&amp;#x27;}\nDEBUG    app:__init__.py:32 Body: b&amp;#x27;{&amp;quot;content&amp;quot;: &amp;quot;Test content&amp;quot;, &amp;quot;target_percentage&amp;quot;: 50}&amp;#x27;\nDEBUG    app:__init__.py:33 Query Params: {}\nDEBUG    groq._base_client:_base_client.py:441 Request options: {&amp;#x27;method&amp;#x27;: &amp;#x27;post&amp;#x27;, &amp;#x27;url&amp;#x27;: &amp;#x27;/openai/v1/chat/completions&amp;#x27;, &amp;#x27;files&amp;#x27;: None, &amp;#x27;json_data&amp;#x27;: {&amp;#x27;messages&amp;#x27;: [{&amp;#x27;role&amp;#x27;: &amp;#x27;system&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate a JSON response following these rules:\\n1. Return exactly ONE compressed version:\\n   {&amp;quot;versions&amp;quot;: [{&amp;quot;text&amp;quot;: &amp;quot;compressed version&amp;quot;}]}\\n2. Target exactly the specified percentage of original length\\n3. Maintain core meaning while removing less essential details\\n4. Ensure complete sentences and proper punctuation\\n5. If task cannot be completed: {&amp;quot;error&amp;quot;: &amp;quot;specific reason&amp;quot;}&amp;#x27;}, {&amp;#x27;role&amp;#x27;: &amp;#x27;user&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate ONE compressed version at 50% length:\\n        Original length: 2 tokens\\n        Original text: Test content&amp;#x27;}], &amp;#x27;model&amp;#x27;: &amp;#x27;llama3-groq-70b-8192-tool-use-preview&amp;#x27;, &amp;#x27;max_tokens&amp;#x27;: 1000, &amp;#x27;temperature&amp;#x27;: 0.7}}\nDEBUG    app:__init__.py:34 Route: POST /text/v1/compress/\nDEBUG    app:__init__.py:32 Body: b&amp;#x27;{&amp;quot;content&amp;quot;: &amp;quot;Test content&amp;quot;, &amp;quot;target_percentage&amp;quot;: 50}&amp;#x27;\nDEBUG    app:__init__.py:32 Body: b&amp;#x27;{&amp;quot;content&amp;quot;: &amp;quot;Test content&amp;quot;, &amp;quot;target_percentage&amp;quot;: 50}&amp;#x27;\nDEBUG    app:__init__.py:33 Query Params: {}\nDEBUG    app:__init__.py:34 Route: POST /text/v1/compress/\nDEBUG    app:__init__.py:32 Body: b&amp;#x27;{&amp;quot;content&amp;quot;: &amp;quot;Test content&amp;quot;, &amp;quot;target_percentage&amp;quot;: 50}&amp;#x27;\nDEBUG    app:__init__.py:33 Query Params: {}\nDEBUG    app:__init__.py:34 Route: POST /text/v1/compress/\nDEBUG    groq._base_client:_base_client.py:441 Request options: {&amp;#x27;method&amp;#x27;: &amp;#x27;post&amp;#x27;, &amp;#x27;url&amp;#x27;: &amp;#x27;/openai/v1/chat/completions&amp;#x27;, &amp;#x27;files&amp;#x27;: None, &amp;#x27;json_data&amp;#x27;: {&amp;#x27;messages&amp;#x27;: [{&amp;#x27;role&amp;#x27;: &amp;#x27;system&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate a JSON response following these rules:\\n1. Return exactly ONE compressed version:\\n   {&amp;quot;versions&amp;quot;: [{&amp;quot;text&amp;quot;: &amp;quot;compressed version&amp;quot;}]}\\n2. Target exactly the specified percentage of original length\\n3. Maintain core meaning while removing less essential details\\n4. Ensure complete sentences and proper punctuation\\n5. If task cannot be completed: {&amp;quot;error&amp;quot;: &amp;quot;specific reason&amp;quot;}&amp;#x27;}, {&amp;#x27;role&amp;#x27;: &amp;#x27;user&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate ONE compressed version at 50% length:\\n        Original length: 2 tokens\\n        Original text: Test content&amp;#x27;}], &amp;#x27;model&amp;#x27;: &amp;#x27;llama3-groq-70b-8192-tool-use-preview&amp;#x27;, &amp;#x27;max_tokens&amp;#x27;: 1000, &amp;#x27;temperature&amp;#x27;: 0.7}}\nDEBUG    httpcore.http11:_trace.py:45 send_request_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    app:__init__.py:33 Query Params: {}\nDEBUG    app:__init__.py:33 Query Params: {}\nDEBUG    app:__init__.py:34 Route: POST /text/v1/compress/\nDEBUG    app:__init__.py:33 Query Params: {}\nDEBUG    groq._base_client:_base_client.py:441 Request options: {&amp;#x27;method&amp;#x27;: &amp;#x27;post&amp;#x27;, &amp;#x27;url&amp;#x27;: &amp;#x27;/openai/v1/chat/completions&amp;#x27;, &amp;#x27;files&amp;#x27;: None, &amp;#x27;json_data&amp;#x27;: {&amp;#x27;messages&amp;#x27;: [{&amp;#x27;role&amp;#x27;: &amp;#x27;system&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate a JSON response following these rules:\\n1. Return exactly ONE compressed version:\\n   {&amp;quot;versions&amp;quot;: [{&amp;quot;text&amp;quot;: &amp;quot;compressed version&amp;quot;}]}\\n2. Target exactly the specified percentage of original length\\n3. Maintain core meaning while removing less essential details\\n4. Ensure complete sentences and proper punctuation\\n5. If task cannot be completed: {&amp;quot;error&amp;quot;: &amp;quot;specific reason&amp;quot;}&amp;#x27;}, {&amp;#x27;role&amp;#x27;: &amp;#x27;user&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate ONE compressed version at 50% length:\\n        Original length: 2 tokens\\n        Original text: Test content&amp;#x27;}], &amp;#x27;model&amp;#x27;: &amp;#x27;llama3-groq-70b-8192-tool-use-preview&amp;#x27;, &amp;#x27;max_tokens&amp;#x27;: 1000, &amp;#x27;temperature&amp;#x27;: 0.7}}\nDEBUG    groq._base_client:_base_client.py:441 Request options: {&amp;#x27;method&amp;#x27;: &amp;#x27;post&amp;#x27;, &amp;#x27;url&amp;#x27;: &amp;#x27;/openai/v1/chat/completions&amp;#x27;, &amp;#x27;files&amp;#x27;: None, &amp;#x27;json_data&amp;#x27;: {&amp;#x27;messages&amp;#x27;: [{&amp;#x27;role&amp;#x27;: &amp;#x27;system&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate a JSON response following these rules:\\n1. Return exactly ONE compressed version:\\n   {&amp;quot;versions&amp;quot;: [{&amp;quot;text&amp;quot;: &amp;quot;compressed version&amp;quot;}]}\\n2. Target exactly the specified percentage of original length\\n3. Maintain core meaning while removing less essential details\\n4. Ensure complete sentences and proper punctuation\\n5. If task cannot be completed: {&amp;quot;error&amp;quot;: &amp;quot;specific reason&amp;quot;}&amp;#x27;}, {&amp;#x27;role&amp;#x27;: &amp;#x27;user&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate ONE compressed version at 50% length:\\n        Original length: 2 tokens\\n        Original text: Test content&amp;#x27;}], &amp;#x27;model&amp;#x27;: &amp;#x27;llama3-groq-70b-8192-tool-use-preview&amp;#x27;, &amp;#x27;max_tokens&amp;#x27;: 1000, &amp;#x27;temperature&amp;#x27;: 0.7}}\nDEBUG    app:__init__.py:34 Route: POST /text/v1/compress/\nDEBUG    httpcore.connection:_trace.py:45 connect_tcp.started host=&amp;#x27;api.groq.com&amp;#x27; port=443 local_address=None timeout=5.0 socket_options=None\nDEBUG    groq._base_client:_base_client.py:441 Request options: {&amp;#x27;method&amp;#x27;: &amp;#x27;post&amp;#x27;, &amp;#x27;url&amp;#x27;: &amp;#x27;/openai/v1/chat/completions&amp;#x27;, &amp;#x27;files&amp;#x27;: None, &amp;#x27;json_data&amp;#x27;: {&amp;#x27;messages&amp;#x27;: [{&amp;#x27;role&amp;#x27;: &amp;#x27;system&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate a JSON response following these rules:\\n1. Return exactly ONE compressed version:\\n   {&amp;quot;versions&amp;quot;: [{&amp;quot;text&amp;quot;: &amp;quot;compressed version&amp;quot;}]}\\n2. Target exactly the specified percentage of original length\\n3. Maintain core meaning while removing less essential details\\n4. Ensure complete sentences and proper punctuation\\n5. If task cannot be completed: {&amp;quot;error&amp;quot;: &amp;quot;specific reason&amp;quot;}&amp;#x27;}, {&amp;#x27;role&amp;#x27;: &amp;#x27;user&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate ONE compressed version at 50% length:\\n        Original length: 2 tokens\\n        Original text: Test content&amp;#x27;}], &amp;#x27;model&amp;#x27;: &amp;#x27;llama3-groq-70b-8192-tool-use-preview&amp;#x27;, &amp;#x27;max_tokens&amp;#x27;: 1000, &amp;#x27;temperature&amp;#x27;: 0.7}}\nDEBUG    app:__init__.py:34 Route: POST /text/v1/compress/\nDEBUG    app:__init__.py:34 Route: POST /text/v1/compress/\nDEBUG    httpcore.http11:_trace.py:45 send_request_headers.complete\nDEBUG    app:__init__.py:34 Route: POST /text/v1/compress/\nDEBUG    groq._base_client:_base_client.py:441 Request options: {&amp;#x27;method&amp;#x27;: &amp;#x27;post&amp;#x27;, &amp;#x27;url&amp;#x27;: &amp;#x27;/openai/v1/chat/completions&amp;#x27;, &amp;#x27;files&amp;#x27;: None, &amp;#x27;json_data&amp;#x27;: {&amp;#x27;messages&amp;#x27;: [{&amp;#x27;role&amp;#x27;: &amp;#x27;system&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate a JSON response following these rules:\\n1. Return exactly ONE compressed version:\\n   {&amp;quot;versions&amp;quot;: [{&amp;quot;text&amp;quot;: &amp;quot;compressed version&amp;quot;}]}\\n2. Target exactly the specified percentage of original length\\n3. Maintain core meaning while removing less essential details\\n4. Ensure complete sentences and proper punctuation\\n5. If task cannot be completed: {&amp;quot;error&amp;quot;: &amp;quot;specific reason&amp;quot;}&amp;#x27;}, {&amp;#x27;role&amp;#x27;: &amp;#x27;user&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate ONE compressed version at 50% length:\\n        Original length: 2 tokens\\n        Original text: Test content&amp;#x27;}], &amp;#x27;model&amp;#x27;: &amp;#x27;llama3-groq-70b-8192-tool-use-preview&amp;#x27;, &amp;#x27;max_tokens&amp;#x27;: 1000, &amp;#x27;temperature&amp;#x27;: 0.7}}\nDEBUG    httpcore.connection:_trace.py:45 connect_tcp.started host=&amp;#x27;api.groq.com&amp;#x27; port=443 local_address=None timeout=5.0 socket_options=None\nDEBUG    httpcore.connection:_trace.py:45 connect_tcp.started host=&amp;#x27;api.groq.com&amp;#x27; port=443 local_address=None timeout=5.0 socket_options=None\nDEBUG    httpcore.connection:_trace.py:45 connect_tcp.started host=&amp;#x27;api.groq.com&amp;#x27; port=443 local_address=None timeout=5.0 socket_options=None\nDEBUG    groq._base_client:_base_client.py:441 Request options: {&amp;#x27;method&amp;#x27;: &amp;#x27;post&amp;#x27;, &amp;#x27;url&amp;#x27;: &amp;#x27;/openai/v1/chat/completions&amp;#x27;, &amp;#x27;files&amp;#x27;: None, &amp;#x27;json_data&amp;#x27;: {&amp;#x27;messages&amp;#x27;: [{&amp;#x27;role&amp;#x27;: &amp;#x27;system&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate a JSON response following these rules:\\n1. Return exactly ONE compressed version:\\n   {&amp;quot;versions&amp;quot;: [{&amp;quot;text&amp;quot;: &amp;quot;compressed version&amp;quot;}]}\\n2. Target exactly the specified percentage of original length\\n3. Maintain core meaning while removing less essential details\\n4. Ensure complete sentences and proper punctuation\\n5. If task cannot be completed: {&amp;quot;error&amp;quot;: &amp;quot;specific reason&amp;quot;}&amp;#x27;}, {&amp;#x27;role&amp;#x27;: &amp;#x27;user&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate ONE compressed version at 50% length:\\n        Original length: 2 tokens\\n        Original text: Test content&amp;#x27;}], &amp;#x27;model&amp;#x27;: &amp;#x27;llama3-groq-70b-8192-tool-use-preview&amp;#x27;, &amp;#x27;max_tokens&amp;#x27;: 1000, &amp;#x27;temperature&amp;#x27;: 0.7}}\nDEBUG    groq._base_client:_base_client.py:441 Request options: {&amp;#x27;method&amp;#x27;: &amp;#x27;post&amp;#x27;, &amp;#x27;url&amp;#x27;: &amp;#x27;/openai/v1/chat/completions&amp;#x27;, &amp;#x27;files&amp;#x27;: None, &amp;#x27;json_data&amp;#x27;: {&amp;#x27;messages&amp;#x27;: [{&amp;#x27;role&amp;#x27;: &amp;#x27;system&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate a JSON response following these rules:\\n1. Return exactly ONE compressed version:\\n   {&amp;quot;versions&amp;quot;: [{&amp;quot;text&amp;quot;: &amp;quot;compressed version&amp;quot;}]}\\n2. Target exactly the specified percentage of original length\\n3. Maintain core meaning while removing less essential details\\n4. Ensure complete sentences and proper punctuation\\n5. If task cannot be completed: {&amp;quot;error&amp;quot;: &amp;quot;specific reason&amp;quot;}&amp;#x27;}, {&amp;#x27;role&amp;#x27;: &amp;#x27;user&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate ONE compressed version at 50% length:\\n        Original length: 2 tokens\\n        Original text: Test content&amp;#x27;}], &amp;#x27;model&amp;#x27;: &amp;#x27;llama3-groq-70b-8192-tool-use-preview&amp;#x27;, &amp;#x27;max_tokens&amp;#x27;: 1000, &amp;#x27;temperature&amp;#x27;: 0.7}}\nDEBUG    httpcore.http11:_trace.py:45 send_request_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    groq._base_client:_base_client.py:441 Request options: {&amp;#x27;method&amp;#x27;: &amp;#x27;post&amp;#x27;, &amp;#x27;url&amp;#x27;: &amp;#x27;/openai/v1/chat/completions&amp;#x27;, &amp;#x27;files&amp;#x27;: None, &amp;#x27;json_data&amp;#x27;: {&amp;#x27;messages&amp;#x27;: [{&amp;#x27;role&amp;#x27;: &amp;#x27;system&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate a JSON response following these rules:\\n1. Return exactly ONE compressed version:\\n   {&amp;quot;versions&amp;quot;: [{&amp;quot;text&amp;quot;: &amp;quot;compressed version&amp;quot;}]}\\n2. Target exactly the specified percentage of original length\\n3. Maintain core meaning while removing less essential details\\n4. Ensure complete sentences and proper punctuation\\n5. If task cannot be completed: {&amp;quot;error&amp;quot;: &amp;quot;specific reason&amp;quot;}&amp;#x27;}, {&amp;#x27;role&amp;#x27;: &amp;#x27;user&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate ONE compressed version at 50% length:\\n        Original length: 2 tokens\\n        Original text: Test content&amp;#x27;}], &amp;#x27;model&amp;#x27;: &amp;#x27;llama3-groq-70b-8192-tool-use-preview&amp;#x27;, &amp;#x27;max_tokens&amp;#x27;: 1000, &amp;#x27;temperature&amp;#x27;: 0.7}}\nDEBUG    groq._base_client:_base_client.py:441 Request options: {&amp;#x27;method&amp;#x27;: &amp;#x27;post&amp;#x27;, &amp;#x27;url&amp;#x27;: &amp;#x27;/openai/v1/chat/completions&amp;#x27;, &amp;#x27;files&amp;#x27;: None, &amp;#x27;json_data&amp;#x27;: {&amp;#x27;messages&amp;#x27;: [{&amp;#x27;role&amp;#x27;: &amp;#x27;system&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate a JSON response following these rules:\\n1. Return exactly ONE compressed version:\\n   {&amp;quot;versions&amp;quot;: [{&amp;quot;text&amp;quot;: &amp;quot;compressed version&amp;quot;}]}\\n2. Target exactly the specified percentage of original length\\n3. Maintain core meaning while removing less essential details\\n4. Ensure complete sentences and proper punctuation\\n5. If task cannot be completed: {&amp;quot;error&amp;quot;: &amp;quot;specific reason&amp;quot;}&amp;#x27;}, {&amp;#x27;role&amp;#x27;: &amp;#x27;user&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate ONE compressed version at 50% length:\\n        Original length: 2 tokens\\n        Original text: Test content&amp;#x27;}], &amp;#x27;model&amp;#x27;: &amp;#x27;llama3-groq-70b-8192-tool-use-preview&amp;#x27;, &amp;#x27;max_tokens&amp;#x27;: 1000, &amp;#x27;temperature&amp;#x27;: 0.7}}\nDEBUG    httpcore.connection:_trace.py:45 connect_tcp.started host=&amp;#x27;api.groq.com&amp;#x27; port=443 local_address=None timeout=5.0 socket_options=None\nDEBUG    httpcore.connection:_trace.py:45 connect_tcp.started host=&amp;#x27;api.groq.com&amp;#x27; port=443 local_address=None timeout=5.0 socket_options=None\nDEBUG    httpcore.connection:_trace.py:45 connect_tcp.started host=&amp;#x27;api.groq.com&amp;#x27; port=443 local_address=None timeout=5.0 socket_options=None\nDEBUG    httpcore.http11:_trace.py:45 send_request_body.complete\nDEBUG    httpcore.connection:_trace.py:45 connect_tcp.started host=&amp;#x27;api.groq.com&amp;#x27; port=443 local_address=None timeout=5.0 socket_options=None\nDEBUG    httpcore.connection:_trace.py:45 connect_tcp.started host=&amp;#x27;api.groq.com&amp;#x27; port=443 local_address=None timeout=5.0 socket_options=None\nDEBUG    httpcore.http11:_trace.py:45 receive_response_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.connection:_trace.py:45 connect_tcp.complete return_value=&amp;lt;httpcore._backends.sync.SyncStream object at 0x108959850&amp;gt;\nDEBUG    httpcore.connection:_trace.py:45 start_tls.started ssl_context=&amp;lt;ssl.SSLContext object at 0x107bb3b50&amp;gt; server_hostname=&amp;#x27;api.groq.com&amp;#x27; timeout=5.0\nDEBUG    httpcore.connection:_trace.py:45 connect_tcp.complete return_value=&amp;lt;httpcore._backends.sync.SyncStream object at 0x109178050&amp;gt;\nDEBUG    httpcore.connection:_trace.py:45 connect_tcp.complete return_value=&amp;lt;httpcore._backends.sync.SyncStream object at 0x109178170&amp;gt;\nDEBUG    httpcore.connection:_trace.py:45 start_tls.started ssl_context=&amp;lt;ssl.SSLContext object at 0x107bb3b50&amp;gt; server_hostname=&amp;#x27;api.groq.com&amp;#x27; timeout=5.0\nDEBUG    httpcore.connection:_trace.py:45 connect_tcp.complete return_value=&amp;lt;httpcore._backends.sync.SyncStream object at 0x1091585c0&amp;gt;\nDEBUG    httpcore.connection:_trace.py:45 start_tls.started ssl_context=&amp;lt;ssl.SSLContext object at 0x107bb3b50&amp;gt; server_hostname=&amp;#x27;api.groq.com&amp;#x27; timeout=5.0\nDEBUG    httpcore.connection:_trace.py:45 start_tls.started ssl_context=&amp;lt;ssl.SSLContext object at 0x107bb3b50&amp;gt; server_hostname=&amp;#x27;api.groq.com&amp;#x27; timeout=5.0\nDEBUG    httpcore.connection:_trace.py:45 connect_tcp.complete return_value=&amp;lt;httpcore._backends.sync.SyncStream object at 0x108959130&amp;gt;\nDEBUG    httpcore.connection:_trace.py:45 start_tls.started ssl_context=&amp;lt;ssl.SSLContext object at 0x107bb3b50&amp;gt; server_hostname=&amp;#x27;api.groq.com&amp;#x27; timeout=5.0\nDEBUG    httpcore.connection:_trace.py:45 connect_tcp.complete return_value=&amp;lt;httpcore._backends.sync.SyncStream object at 0x1091786b0&amp;gt;\nDEBUG    httpcore.connection:_trace.py:45 connect_tcp.complete return_value=&amp;lt;httpcore._backends.sync.SyncStream object at 0x109178110&amp;gt;\nDEBUG    httpcore.connection:_trace.py:45 start_tls.started ssl_context=&amp;lt;ssl.SSLContext object at 0x107bb3b50&amp;gt; server_hostname=&amp;#x27;api.groq.com&amp;#x27; timeout=5.0\nDEBUG    httpcore.connection:_trace.py:45 connect_tcp.complete return_value=&amp;lt;httpcore._backends.sync.SyncStream object at 0x109158560&amp;gt;\nDEBUG    httpcore.connection:_trace.py:45 start_tls.started ssl_context=&amp;lt;ssl.SSLContext object at 0x107bb3b50&amp;gt; server_hostname=&amp;#x27;api.groq.com&amp;#x27; timeout=5.0\nDEBUG    httpcore.connection:_trace.py:45 start_tls.started ssl_context=&amp;lt;ssl.SSLContext object at 0x107bb3b50&amp;gt; server_hostname=&amp;#x27;api.groq.com&amp;#x27; timeout=5.0\nDEBUG    httpcore.connection:_trace.py:45 connect_tcp.complete return_value=&amp;lt;httpcore._backends.sync.SyncStream object at 0x1091583e0&amp;gt;\nDEBUG    httpcore.connection:_trace.py:45 start_tls.started ssl_context=&amp;lt;ssl.SSLContext object at 0x107bb3b50&amp;gt; server_hostname=&amp;#x27;api.groq.com&amp;#x27; timeout=5.0\nDEBUG    httpcore.connection:_trace.py:45 start_tls.complete return_value=&amp;lt;httpcore._backends.sync.SyncStream object at 0x1089882c0&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 send_request_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 send_request_headers.complete\nDEBUG    httpcore.http11:_trace.py:45 send_request_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 send_request_body.complete\nDEBUG    httpcore.http11:_trace.py:45 receive_response_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.connection:_trace.py:45 start_tls.complete return_value=&amp;lt;httpcore._backends.sync.SyncStream object at 0x10917bfb0&amp;gt;\nDEBUG    httpcore.connection:_trace.py:45 start_tls.complete return_value=&amp;lt;httpcore._backends.sync.SyncStream object at 0x10917a6c0&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 send_request_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 send_request_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 send_request_headers.complete\nDEBUG    httpcore.connection:_trace.py:45 start_tls.complete return_value=&amp;lt;httpcore._backends.sync.SyncStream object at 0x10895b860&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 send_request_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 send_request_headers.complete\nDEBUG    httpcore.http11:_trace.py:45 send_request_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 send_request_body.complete\nDEBUG    httpcore.http11:_trace.py:45 send_request_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 receive_response_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 send_request_headers.complete\nDEBUG    httpcore.http11:_trace.py:45 send_request_body.complete\nDEBUG    httpcore.http11:_trace.py:45 send_request_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 receive_response_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 send_request_body.complete\nDEBUG    httpcore.http11:_trace.py:45 receive_response_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.connection:_trace.py:45 start_tls.complete return_value=&amp;lt;httpcore._backends.sync.SyncStream object at 0x1091791c0&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 send_request_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 send_request_headers.complete\nDEBUG    httpcore.http11:_trace.py:45 send_request_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 send_request_body.complete\nDEBUG    httpcore.http11:_trace.py:45 receive_response_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.connection:_trace.py:45 start_tls.complete return_value=&amp;lt;httpcore._backends.sync.SyncStream object at 0x1084c4470&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 send_request_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 send_request_headers.complete\nDEBUG    httpcore.http11:_trace.py:45 send_request_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 send_request_body.complete\nDEBUG    httpcore.http11:_trace.py:45 receive_response_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.connection:_trace.py:45 start_tls.complete return_value=&amp;lt;httpcore._backends.sync.SyncStream object at 0x10917b530&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 send_request_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 send_request_headers.complete\nDEBUG    httpcore.http11:_trace.py:45 send_request_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 send_request_body.complete\nDEBUG    httpcore.http11:_trace.py:45 receive_response_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.connection:_trace.py:45 start_tls.complete return_value=&amp;lt;httpcore._backends.sync.SyncStream object at 0x10917aa50&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 send_request_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.connection:_trace.py:45 start_tls.complete return_value=&amp;lt;httpcore._backends.sync.SyncStream object at 0x108959b20&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 send_request_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 send_request_headers.complete\nDEBUG    httpcore.http11:_trace.py:45 send_request_headers.complete\nDEBUG    httpcore.http11:_trace.py:45 send_request_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 send_request_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 send_request_body.complete\nDEBUG    httpcore.http11:_trace.py:45 receive_response_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 send_request_body.complete\nDEBUG    httpcore.http11:_trace.py:45 receive_response_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 receive_response_headers.complete return_value=(b&amp;#x27;HTTP/1.1&amp;#x27;, 200, b&amp;#x27;OK&amp;#x27;, [(b&amp;#x27;Date&amp;#x27;, b&amp;#x27;Wed, 30 Oct 2024 15:53:41 GMT&amp;#x27;), (b&amp;#x27;Content-Type&amp;#x27;, b&amp;#x27;application/json&amp;#x27;), (b&amp;#x27;Transfer-Encoding&amp;#x27;, b&amp;#x27;chunked&amp;#x27;), (b&amp;#x27;Connection&amp;#x27;, b&amp;#x27;keep-alive&amp;#x27;), (b&amp;#x27;Cache-Control&amp;#x27;, b&amp;#x27;private, max-age=0, no-store, no-cache, must-revalidate&amp;#x27;), (b&amp;#x27;vary&amp;#x27;, b&amp;#x27;Origin&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-requests&amp;#x27;, b&amp;#x27;14400&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-tokens&amp;#x27;, b&amp;#x27;15000&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-requests&amp;#x27;, b&amp;#x27;14374&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-tokens&amp;#x27;, b&amp;#x27;13816&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-requests&amp;#x27;, b&amp;#x27;2m31.955999999s&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-tokens&amp;#x27;, b&amp;#x27;4.734s&amp;#x27;), (b&amp;#x27;x-request-id&amp;#x27;, b&amp;#x27;req_01jbf23y9pe408b9578bshcyga&amp;#x27;), (b&amp;#x27;via&amp;#x27;, b&amp;#x27;1.1 google&amp;#x27;), (b&amp;#x27;alt-svc&amp;#x27;, b&amp;#x27;h3=&amp;quot;:443&amp;quot;; ma=86400&amp;#x27;), (b&amp;#x27;CF-Cache-Status&amp;#x27;, b&amp;#x27;DYNAMIC&amp;#x27;), (b&amp;#x27;Server&amp;#x27;, b&amp;#x27;cloudflare&amp;#x27;), (b&amp;#x27;CF-RAY&amp;#x27;, b&amp;#x27;8dac94615821ca58-HAM&amp;#x27;), (b&amp;#x27;Content-Encoding&amp;#x27;, b&amp;#x27;gzip&amp;#x27;)])\nINFO     httpx:_client.py:1038 HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;HTTP/1.1 200 OK&amp;quot;\nDEBUG    httpcore.http11:_trace.py:45 receive_response_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 receive_response_body.complete\nDEBUG    httpcore.http11:_trace.py:45 response_closed.started\nDEBUG    httpcore.http11:_trace.py:45 response_closed.complete\nDEBUG    groq._base_client:_base_client.py:956 HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;200 OK&amp;quot;\nDEBUG    httpcore.http11:_trace.py:45 receive_response_headers.complete return_value=(b&amp;#x27;HTTP/1.1&amp;#x27;, 429, b&amp;#x27;Too Many Requests&amp;#x27;, [(b&amp;#x27;Date&amp;#x27;, b&amp;#x27;Wed, 30 Oct 2024 15:53:41 GMT&amp;#x27;), (b&amp;#x27;Content-Type&amp;#x27;, b&amp;#x27;application/json&amp;#x27;), (b&amp;#x27;Content-Length&amp;#x27;, b&amp;#x27;349&amp;#x27;), (b&amp;#x27;Connection&amp;#x27;, b&amp;#x27;keep-alive&amp;#x27;), (b&amp;#x27;Cache-Control&amp;#x27;, b&amp;#x27;private, max-age=0, no-store, no-cache, must-revalidate&amp;#x27;), (b&amp;#x27;retry-after&amp;#x27;, b&amp;#x27;2&amp;#x27;), (b&amp;#x27;vary&amp;#x27;, b&amp;#x27;Origin&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-requests&amp;#x27;, b&amp;#x27;14400&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-tokens&amp;#x27;, b&amp;#x27;15000&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-requests&amp;#x27;, b&amp;#x27;14368&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-tokens&amp;#x27;, b&amp;#x27;13862&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-requests&amp;#x27;, b&amp;#x27;3m11.997999999s&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-tokens&amp;#x27;, b&amp;#x27;4.552s&amp;#x27;), (b&amp;#x27;x-request-id&amp;#x27;, b&amp;#x27;req_01jbf23yeffsnt50w7zpvw4xha&amp;#x27;), (b&amp;#x27;via&amp;#x27;, b&amp;#x27;1.1 google&amp;#x27;), (b&amp;#x27;alt-svc&amp;#x27;, b&amp;#x27;h3=&amp;quot;:443&amp;quot;; ma=86400&amp;#x27;), (b&amp;#x27;CF-Cache-Status&amp;#x27;, b&amp;#x27;DYNAMIC&amp;#x27;), (b&amp;#x27;Server&amp;#x27;, b&amp;#x27;cloudflare&amp;#x27;), (b&amp;#x27;CF-RAY&amp;#x27;, b&amp;#x27;8dac94623c6b62ce-HAM&amp;#x27;)])\nINFO     httpx:_client.py:1038 HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;HTTP/1.1 429 Too Many Requests&amp;quot;\nDEBUG    httpcore.http11:_trace.py:45 receive_response_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 receive_response_body.complete\nDEBUG    httpcore.http11:_trace.py:45 response_closed.started\nDEBUG    httpcore.http11:_trace.py:45 response_closed.complete\nDEBUG    groq._base_client:_base_client.py:956 HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;429 Too Many Requests&amp;quot;\nDEBUG    groq._base_client:_base_client.py:963 Encountered httpx.HTTPStatusError\nTraceback (most recent call last):\n  File &amp;quot;/Users/julian/Tresors/Privat/Code/fragment-editor-api/.venv-test/lib/python3.12/site-packages/groq/_base_client.py&amp;quot;, line 961, in _request\n    response.raise_for_status()\n  File &amp;quot;/Users/julian/Tresors/Privat/Code/fragment-editor-api/.venv-test/lib/python3.12/site-packages/httpx/_models.py&amp;quot;, line 763, in raise_for_status\n    raise HTTPStatusError(message, request=request, response=self)\nhttpx.HTTPStatusError: Client error &amp;#x27;429 Too Many Requests&amp;#x27; for url &amp;#x27;https://api.groq.com/openai/v1/chat/completions&amp;#x27;\nFor more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\nDEBUG    groq._base_client:_base_client.py:698 Retrying due to status code 429\nDEBUG    groq._base_client:_base_client.py:1004 1 retry left\nINFO     groq._base_client:_base_client.py:1009 Retrying request to /openai/v1/chat/completions in 2.000000 seconds\nDEBUG    httpcore.http11:_trace.py:45 receive_response_headers.complete return_value=(b&amp;#x27;HTTP/1.1&amp;#x27;, 200, b&amp;#x27;OK&amp;#x27;, [(b&amp;#x27;Date&amp;#x27;, b&amp;#x27;Wed, 30 Oct 2024 15:53:41 GMT&amp;#x27;), (b&amp;#x27;Content-Type&amp;#x27;, b&amp;#x27;application/json&amp;#x27;), (b&amp;#x27;Transfer-Encoding&amp;#x27;, b&amp;#x27;chunked&amp;#x27;), (b&amp;#x27;Connection&amp;#x27;, b&amp;#x27;keep-alive&amp;#x27;), (b&amp;#x27;Cache-Control&amp;#x27;, b&amp;#x27;private, max-age=0, no-store, no-cache, must-revalidate&amp;#x27;), (b&amp;#x27;vary&amp;#x27;, b&amp;#x27;Origin&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-requests&amp;#x27;, b&amp;#x27;14400&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-tokens&amp;#x27;, b&amp;#x27;15000&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-requests&amp;#x27;, b&amp;#x27;14373&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-tokens&amp;#x27;, b&amp;#x27;13723&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-requests&amp;#x27;, b&amp;#x27;2m41.870999999s&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-tokens&amp;#x27;, b&amp;#x27;5.106s&amp;#x27;), (b&amp;#x27;x-request-id&amp;#x27;, b&amp;#x27;req_01jbf23ydrfb29a048m5zbyppa&amp;#x27;), (b&amp;#x27;via&amp;#x27;, b&amp;#x27;1.1 google&amp;#x27;), (b&amp;#x27;alt-svc&amp;#x27;, b&amp;#x27;h3=&amp;quot;:443&amp;quot;; ma=86400&amp;#x27;), (b&amp;#x27;CF-Cache-Status&amp;#x27;, b&amp;#x27;DYNAMIC&amp;#x27;), (b&amp;#x27;Server&amp;#x27;, b&amp;#x27;cloudflare&amp;#x27;), (b&amp;#x27;CF-RAY&amp;#x27;, b&amp;#x27;8dac94623cfdd2b7-FRA&amp;#x27;), (b&amp;#x27;Content-Encoding&amp;#x27;, b&amp;#x27;gzip&amp;#x27;)])\nINFO     httpx:_client.py:1038 HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;HTTP/1.1 200 OK&amp;quot;\nDEBUG    httpcore.http11:_trace.py:45 receive_response_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 receive_response_body.complete\nDEBUG    httpcore.http11:_trace.py:45 response_closed.started\nDEBUG    httpcore.http11:_trace.py:45 response_closed.complete\nDEBUG    groq._base_client:_base_client.py:956 HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;200 OK&amp;quot;\nDEBUG    httpcore.http11:_trace.py:45 receive_response_headers.complete return_value=(b&amp;#x27;HTTP/1.1&amp;#x27;, 200, b&amp;#x27;OK&amp;#x27;, [(b&amp;#x27;Date&amp;#x27;, b&amp;#x27;Wed, 30 Oct 2024 15:53:41 GMT&amp;#x27;), (b&amp;#x27;Content-Type&amp;#x27;, b&amp;#x27;application/json&amp;#x27;), (b&amp;#x27;Transfer-Encoding&amp;#x27;, b&amp;#x27;chunked&amp;#x27;), (b&amp;#x27;Connection&amp;#x27;, b&amp;#x27;keep-alive&amp;#x27;), (b&amp;#x27;Cache-Control&amp;#x27;, b&amp;#x27;private, max-age=0, no-store, no-cache, must-revalidate&amp;#x27;), (b&amp;#x27;vary&amp;#x27;, b&amp;#x27;Origin&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-requests&amp;#x27;, b&amp;#x27;14400&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-tokens&amp;#x27;, b&amp;#x27;15000&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-requests&amp;#x27;, b&amp;#x27;14371&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-tokens&amp;#x27;, b&amp;#x27;13725&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-requests&amp;#x27;, b&amp;#x27;2m53.996999999s&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-tokens&amp;#x27;, b&amp;#x27;5.099s&amp;#x27;), (b&amp;#x27;x-request-id&amp;#x27;, b&amp;#x27;req_01jbf23ydzf1hs0ehsjdkmvpx5&amp;#x27;), (b&amp;#x27;via&amp;#x27;, b&amp;#x27;1.1 google&amp;#x27;), (b&amp;#x27;alt-svc&amp;#x27;, b&amp;#x27;h3=&amp;quot;:443&amp;quot;; ma=86400&amp;#x27;), (b&amp;#x27;CF-Cache-Status&amp;#x27;, b&amp;#x27;DYNAMIC&amp;#x27;), (b&amp;#x27;Server&amp;#x27;, b&amp;#x27;cloudflare&amp;#x27;), (b&amp;#x27;CF-RAY&amp;#x27;, b&amp;#x27;8dac94622af67267-HAM&amp;#x27;), (b&amp;#x27;Content-Encoding&amp;#x27;, b&amp;#x27;gzip&amp;#x27;)])\nINFO     httpx:_client.py:1038 HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;HTTP/1.1 200 OK&amp;quot;\nDEBUG    httpcore.http11:_trace.py:45 receive_response_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 receive_response_body.complete\nDEBUG    httpcore.http11:_trace.py:45 response_closed.started\nDEBUG    httpcore.http11:_trace.py:45 response_closed.complete\nDEBUG    groq._base_client:_base_client.py:956 HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;200 OK&amp;quot;\nDEBUG    httpcore.http11:_trace.py:45 receive_response_headers.complete return_value=(b&amp;#x27;HTTP/1.1&amp;#x27;, 200, b&amp;#x27;OK&amp;#x27;, [(b&amp;#x27;Date&amp;#x27;, b&amp;#x27;Wed, 30 Oct 2024 15:53:41 GMT&amp;#x27;), (b&amp;#x27;Content-Type&amp;#x27;, b&amp;#x27;application/json&amp;#x27;), (b&amp;#x27;Transfer-Encoding&amp;#x27;, b&amp;#x27;chunked&amp;#x27;), (b&amp;#x27;Connection&amp;#x27;, b&amp;#x27;keep-alive&amp;#x27;), (b&amp;#x27;Cache-Control&amp;#x27;, b&amp;#x27;private, max-age=0, no-store, no-cache, must-revalidate&amp;#x27;), (b&amp;#x27;vary&amp;#x27;, b&amp;#x27;Origin&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-requests&amp;#x27;, b&amp;#x27;14400&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-tokens&amp;#x27;, b&amp;#x27;15000&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-requests&amp;#x27;, b&amp;#x27;14372&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-tokens&amp;#x27;, b&amp;#x27;13724&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-requests&amp;#x27;, b&amp;#x27;2m47.997999999s&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-tokens&amp;#x27;, b&amp;#x27;5.103s&amp;#x27;), (b&amp;#x27;x-request-id&amp;#x27;, b&amp;#x27;req_01jbf23ydvfdmvh2v7matd573v&amp;#x27;), (b&amp;#x27;via&amp;#x27;, b&amp;#x27;1.1 google&amp;#x27;), (b&amp;#x27;alt-svc&amp;#x27;, b&amp;#x27;h3=&amp;quot;:443&amp;quot;; ma=86400&amp;#x27;), (b&amp;#x27;CF-Cache-Status&amp;#x27;, b&amp;#x27;DYNAMIC&amp;#x27;), (b&amp;#x27;Server&amp;#x27;, b&amp;#x27;cloudflare&amp;#x27;), (b&amp;#x27;CF-RAY&amp;#x27;, b&amp;#x27;8dac94622befcaad-HAM&amp;#x27;), (b&amp;#x27;Content-Encoding&amp;#x27;, b&amp;#x27;gzip&amp;#x27;)])\nINFO     httpx:_client.py:1038 HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;HTTP/1.1 200 OK&amp;quot;\nDEBUG    httpcore.http11:_trace.py:45 receive_response_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 receive_response_body.complete\nDEBUG    httpcore.http11:_trace.py:45 response_closed.started\nDEBUG    httpcore.http11:_trace.py:45 response_closed.complete\nDEBUG    groq._base_client:_base_client.py:956 HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;200 OK&amp;quot;\nDEBUG    httpcore.http11:_trace.py:45 receive_response_headers.complete return_value=(b&amp;#x27;HTTP/1.1&amp;#x27;, 200, b&amp;#x27;OK&amp;#x27;, [(b&amp;#x27;Date&amp;#x27;, b&amp;#x27;Wed, 30 Oct 2024 15:53:41 GMT&amp;#x27;), (b&amp;#x27;Content-Type&amp;#x27;, b&amp;#x27;application/json&amp;#x27;), (b&amp;#x27;Transfer-Encoding&amp;#x27;, b&amp;#x27;chunked&amp;#x27;), (b&amp;#x27;Connection&amp;#x27;, b&amp;#x27;keep-alive&amp;#x27;), (b&amp;#x27;Cache-Control&amp;#x27;, b&amp;#x27;private, max-age=0, no-store, no-cache, must-revalidate&amp;#x27;), (b&amp;#x27;vary&amp;#x27;, b&amp;#x27;Origin&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-requests&amp;#x27;, b&amp;#x27;14400&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-tokens&amp;#x27;, b&amp;#x27;15000&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-requests&amp;#x27;, b&amp;#x27;14370&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-tokens&amp;#x27;, b&amp;#x27;13726&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-requests&amp;#x27;, b&amp;#x27;2m59.997999999s&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-tokens&amp;#x27;, b&amp;#x27;5.096s&amp;#x27;), (b&amp;#x27;x-request-id&amp;#x27;, b&amp;#x27;req_01jbf23ye1er4vqfnx30xtqxcj&amp;#x27;), (b&amp;#x27;via&amp;#x27;, b&amp;#x27;1.1 google&amp;#x27;), (b&amp;#x27;alt-svc&amp;#x27;, b&amp;#x27;h3=&amp;quot;:443&amp;quot;; ma=86400&amp;#x27;), (b&amp;#x27;CF-Cache-Status&amp;#x27;, b&amp;#x27;DYNAMIC&amp;#x27;), (b&amp;#x27;Server&amp;#x27;, b&amp;#x27;cloudflare&amp;#x27;), (b&amp;#x27;CF-RAY&amp;#x27;, b&amp;#x27;8dac94622d3e4156-HAM&amp;#x27;), (b&amp;#x27;Content-Encoding&amp;#x27;, b&amp;#x27;gzip&amp;#x27;)])\nINFO     httpx:_client.py:1038 HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;HTTP/1.1 200 OK&amp;quot;\nDEBUG    httpcore.http11:_trace.py:45 receive_response_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 receive_response_body.complete\nDEBUG    httpcore.http11:_trace.py:45 response_closed.started\nDEBUG    httpcore.http11:_trace.py:45 response_closed.complete\nDEBUG    groq._base_client:_base_client.py:956 HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;200 OK&amp;quot;\nDEBUG    httpcore.http11:_trace.py:45 receive_response_headers.complete return_value=(b&amp;#x27;HTTP/1.1&amp;#x27;, 200, b&amp;#x27;OK&amp;#x27;, [(b&amp;#x27;Date&amp;#x27;, b&amp;#x27;Wed, 30 Oct 2024 15:53:41 GMT&amp;#x27;), (b&amp;#x27;Content-Type&amp;#x27;, b&amp;#x27;application/json&amp;#x27;), (b&amp;#x27;Transfer-Encoding&amp;#x27;, b&amp;#x27;chunked&amp;#x27;), (b&amp;#x27;Connection&amp;#x27;, b&amp;#x27;keep-alive&amp;#x27;), (b&amp;#x27;Cache-Control&amp;#x27;, b&amp;#x27;private, max-age=0, no-store, no-cache, must-revalidate&amp;#x27;), (b&amp;#x27;vary&amp;#x27;, b&amp;#x27;Origin&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-requests&amp;#x27;, b&amp;#x27;14400&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-tokens&amp;#x27;, b&amp;#x27;15000&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-requests&amp;#x27;, b&amp;#x27;14369&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-tokens&amp;#x27;, b&amp;#x27;13726&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-requests&amp;#x27;, b&amp;#x27;3m5.998999999s&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-tokens&amp;#x27;, b&amp;#x27;5.094s&amp;#x27;), (b&amp;#x27;x-request-id&amp;#x27;, b&amp;#x27;req_01jbf23ye4ec1rd23ah00qx7sc&amp;#x27;), (b&amp;#x27;via&amp;#x27;, b&amp;#x27;1.1 google&amp;#x27;), (b&amp;#x27;alt-svc&amp;#x27;, b&amp;#x27;h3=&amp;quot;:443&amp;quot;; ma=86400&amp;#x27;), (b&amp;#x27;CF-Cache-Status&amp;#x27;, b&amp;#x27;DYNAMIC&amp;#x27;), (b&amp;#x27;Server&amp;#x27;, b&amp;#x27;cloudflare&amp;#x27;), (b&amp;#x27;CF-RAY&amp;#x27;, b&amp;#x27;8dac946229fa62da-HAM&amp;#x27;), (b&amp;#x27;Content-Encoding&amp;#x27;, b&amp;#x27;gzip&amp;#x27;)])\nINFO     httpx:_client.py:1038 HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;HTTP/1.1 200 OK&amp;quot;\nDEBUG    httpcore.http11:_trace.py:45 receive_response_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 receive_response_body.complete\nDEBUG    httpcore.http11:_trace.py:45 response_closed.started\nDEBUG    httpcore.http11:_trace.py:45 response_closed.complete\nDEBUG    groq._base_client:_base_client.py:956 HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;200 OK&amp;quot;\nDEBUG    httpcore.http11:_trace.py:45 receive_response_headers.complete return_value=(b&amp;#x27;HTTP/1.1&amp;#x27;, 200, b&amp;#x27;OK&amp;#x27;, [(b&amp;#x27;Date&amp;#x27;, b&amp;#x27;Wed, 30 Oct 2024 15:53:41 GMT&amp;#x27;), (b&amp;#x27;Content-Type&amp;#x27;, b&amp;#x27;application/json&amp;#x27;), (b&amp;#x27;Transfer-Encoding&amp;#x27;, b&amp;#x27;chunked&amp;#x27;), (b&amp;#x27;Connection&amp;#x27;, b&amp;#x27;keep-alive&amp;#x27;), (b&amp;#x27;Cache-Control&amp;#x27;, b&amp;#x27;private, max-age=0, no-store, no-cache, must-revalidate&amp;#x27;), (b&amp;#x27;vary&amp;#x27;, b&amp;#x27;Origin&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-requests&amp;#x27;, b&amp;#x27;14400&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-tokens&amp;#x27;, b&amp;#x27;15000&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-requests&amp;#x27;, b&amp;#x27;14368&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-tokens&amp;#x27;, b&amp;#x27;13728&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-requests&amp;#x27;, b&amp;#x27;3m11.993999999s&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-tokens&amp;#x27;, b&amp;#x27;5.086s&amp;#x27;), (b&amp;#x27;x-request-id&amp;#x27;, b&amp;#x27;req_01jbf23yecfdms12a4rtfh3k87&amp;#x27;), (b&amp;#x27;via&amp;#x27;, b&amp;#x27;1.1 google&amp;#x27;), (b&amp;#x27;alt-svc&amp;#x27;, b&amp;#x27;h3=&amp;quot;:443&amp;quot;; ma=86400&amp;#x27;), (b&amp;#x27;CF-Cache-Status&amp;#x27;, b&amp;#x27;DYNAMIC&amp;#x27;), (b&amp;#x27;Server&amp;#x27;, b&amp;#x27;cloudflare&amp;#x27;), (b&amp;#x27;CF-RAY&amp;#x27;, b&amp;#x27;8dac94623b5f6301-HAM&amp;#x27;), (b&amp;#x27;Content-Encoding&amp;#x27;, b&amp;#x27;gzip&amp;#x27;)])\nINFO     httpx:_client.py:1038 HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;HTTP/1.1 200 OK&amp;quot;\nDEBUG    httpcore.http11:_trace.py:45 receive_response_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 receive_response_body.complete\nDEBUG    httpcore.http11:_trace.py:45 response_closed.started\nDEBUG    httpcore.http11:_trace.py:45 response_closed.complete\nDEBUG    groq._base_client:_base_client.py:956 HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;200 OK&amp;quot;\nDEBUG    httpcore.http11:_trace.py:45 receive_response_headers.complete return_value=(b&amp;#x27;HTTP/1.1&amp;#x27;, 429, b&amp;#x27;Too Many Requests&amp;#x27;, [(b&amp;#x27;Date&amp;#x27;, b&amp;#x27;Wed, 30 Oct 2024 15:53:42 GMT&amp;#x27;), (b&amp;#x27;Content-Type&amp;#x27;, b&amp;#x27;application/json&amp;#x27;), (b&amp;#x27;Content-Length&amp;#x27;, b&amp;#x27;349&amp;#x27;), (b&amp;#x27;Connection&amp;#x27;, b&amp;#x27;keep-alive&amp;#x27;), (b&amp;#x27;Cache-Control&amp;#x27;, b&amp;#x27;private, max-age=0, no-store, no-cache, must-revalidate&amp;#x27;), (b&amp;#x27;retry-after&amp;#x27;, b&amp;#x27;2&amp;#x27;), (b&amp;#x27;vary&amp;#x27;, b&amp;#x27;Origin&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-requests&amp;#x27;, b&amp;#x27;14400&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-tokens&amp;#x27;, b&amp;#x27;15000&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-requests&amp;#x27;, b&amp;#x27;14368&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-tokens&amp;#x27;, b&amp;#x27;13206&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-requests&amp;#x27;, b&amp;#x27;3m11.606999999s&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-tokens&amp;#x27;, b&amp;#x27;7.173s&amp;#x27;), (b&amp;#x27;x-request-id&amp;#x27;, b&amp;#x27;req_01jbf23ytqfsnty25gr3p2rhde&amp;#x27;), (b&amp;#x27;via&amp;#x27;, b&amp;#x27;1.1 google&amp;#x27;), (b&amp;#x27;alt-svc&amp;#x27;, b&amp;#x27;h3=&amp;quot;:443&amp;quot;; ma=86400&amp;#x27;), (b&amp;#x27;CF-Cache-Status&amp;#x27;, b&amp;#x27;DYNAMIC&amp;#x27;), (b&amp;#x27;Server&amp;#x27;, b&amp;#x27;cloudflare&amp;#x27;), (b&amp;#x27;CF-RAY&amp;#x27;, b&amp;#x27;8dac94621a424168-HAM&amp;#x27;)])\nINFO     httpx:_client.py:1038 HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;HTTP/1.1 429 Too Many Requests&amp;quot;\nDEBUG    httpcore.http11:_trace.py:45 receive_response_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 receive_response_body.complete\nDEBUG    httpcore.http11:_trace.py:45 response_closed.started\nDEBUG    httpcore.http11:_trace.py:45 response_closed.complete\nDEBUG    groq._base_client:_base_client.py:956 HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;429 Too Many Requests&amp;quot;\nDEBUG    groq._base_client:_base_client.py:963 Encountered httpx.HTTPStatusError\nTraceback (most recent call last):\n  File &amp;quot;/Users/julian/Tresors/Privat/Code/fragment-editor-api/.venv-test/lib/python3.12/site-packages/groq/_base_client.py&amp;quot;, line 961, in _request\n    response.raise_for_status()\n  File &amp;quot;/Users/julian/Tresors/Privat/Code/fragment-editor-api/.venv-test/lib/python3.12/site-packages/httpx/_models.py&amp;quot;, line 763, in raise_for_status\n    raise HTTPStatusError(message, request=request, response=self)\nhttpx.HTTPStatusError: Client error &amp;#x27;429 Too Many Requests&amp;#x27; for url &amp;#x27;https://api.groq.com/openai/v1/chat/completions&amp;#x27;\nFor more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\nDEBUG    groq._base_client:_base_client.py:698 Retrying due to status code 429\nDEBUG    groq._base_client:_base_client.py:1004 1 retry left\nINFO     groq._base_client:_base_client.py:1009 Retrying request to /openai/v1/chat/completions in 2.000000 seconds\nDEBUG    httpcore.http11:_trace.py:45 receive_response_headers.complete return_value=(b&amp;#x27;HTTP/1.1&amp;#x27;, 429, b&amp;#x27;Too Many Requests&amp;#x27;, [(b&amp;#x27;Date&amp;#x27;, b&amp;#x27;Wed, 30 Oct 2024 15:53:42 GMT&amp;#x27;), (b&amp;#x27;Content-Type&amp;#x27;, b&amp;#x27;application/json&amp;#x27;), (b&amp;#x27;Content-Length&amp;#x27;, b&amp;#x27;355&amp;#x27;), (b&amp;#x27;Connection&amp;#x27;, b&amp;#x27;keep-alive&amp;#x27;), (b&amp;#x27;Cache-Control&amp;#x27;, b&amp;#x27;private, max-age=0, no-store, no-cache, must-revalidate&amp;#x27;), (b&amp;#x27;retry-after&amp;#x27;, b&amp;#x27;2&amp;#x27;), (b&amp;#x27;vary&amp;#x27;, b&amp;#x27;Origin&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-requests&amp;#x27;, b&amp;#x27;14400&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-tokens&amp;#x27;, b&amp;#x27;15000&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-requests&amp;#x27;, b&amp;#x27;14368&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-tokens&amp;#x27;, b&amp;#x27;13208&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-requests&amp;#x27;, b&amp;#x27;3m11.600999999s&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-tokens&amp;#x27;, b&amp;#x27;7.167s&amp;#x27;), (b&amp;#x27;x-request-id&amp;#x27;, b&amp;#x27;req_01jbf23ytxe6dt2xcq2vsrb4m2&amp;#x27;), (b&amp;#x27;via&amp;#x27;, b&amp;#x27;1.1 google&amp;#x27;), (b&amp;#x27;alt-svc&amp;#x27;, b&amp;#x27;h3=&amp;quot;:443&amp;quot;; ma=86400&amp;#x27;), (b&amp;#x27;CF-Cache-Status&amp;#x27;, b&amp;#x27;DYNAMIC&amp;#x27;), (b&amp;#x27;Server&amp;#x27;, b&amp;#x27;cloudflare&amp;#x27;), (b&amp;#x27;CF-RAY&amp;#x27;, b&amp;#x27;8dac946229826311-HAM&amp;#x27;)])\nINFO     httpx:_client.py:1038 HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;HTTP/1.1 429 Too Many Requests&amp;quot;\nDEBUG    httpcore.http11:_trace.py:45 receive_response_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 receive_response_body.complete\nDEBUG    httpcore.http11:_trace.py:45 response_closed.started\nDEBUG    httpcore.http11:_trace.py:45 response_closed.complete\nDEBUG    groq._base_client:_base_client.py:956 HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;429 Too Many Requests&amp;quot;\nDEBUG    groq._base_client:_base_client.py:963 Encountered httpx.HTTPStatusError\nTraceback (most recent call last):\n  File &amp;quot;/Users/julian/Tresors/Privat/Code/fragment-editor-api/.venv-test/lib/python3.12/site-packages/groq/_base_client.py&amp;quot;, line 961, in _request\n    response.raise_for_status()\n  File &amp;quot;/Users/julian/Tresors/Privat/Code/fragment-editor-api/.venv-test/lib/python3.12/site-packages/httpx/_models.py&amp;quot;, line 763, in raise_for_status\n    raise HTTPStatusError(message, request=request, response=self)\nhttpx.HTTPStatusError: Client error &amp;#x27;429 Too Many Requests&amp;#x27; for url &amp;#x27;https://api.groq.com/openai/v1/chat/completions&amp;#x27;\nFor more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\nDEBUG    groq._base_client:_base_client.py:698 Retrying due to status code 429\nDEBUG    groq._base_client:_base_client.py:1004 1 retry left\nINFO     groq._base_client:_base_client.py:1009 Retrying request to /openai/v1/chat/completions in 2.000000 seconds\nDEBUG    groq._base_client:_base_client.py:441 Request options: {&amp;#x27;method&amp;#x27;: &amp;#x27;post&amp;#x27;, &amp;#x27;url&amp;#x27;: &amp;#x27;/openai/v1/chat/completions&amp;#x27;, &amp;#x27;files&amp;#x27;: None, &amp;#x27;json_data&amp;#x27;: {&amp;#x27;messages&amp;#x27;: [{&amp;#x27;role&amp;#x27;: &amp;#x27;system&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate a JSON response following these rules:\\n1. Return exactly ONE compressed version:\\n   {&amp;quot;versions&amp;quot;: [{&amp;quot;text&amp;quot;: &amp;quot;compressed version&amp;quot;}]}\\n2. Target exactly the specified percentage of original length\\n3. Maintain core meaning while removing less essential details\\n4. Ensure complete sentences and proper punctuation\\n5. If task cannot be completed: {&amp;quot;error&amp;quot;: &amp;quot;specific reason&amp;quot;}&amp;#x27;}, {&amp;#x27;role&amp;#x27;: &amp;#x27;user&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate ONE compressed version at 50% length:\\n        Original length: 2 tokens\\n        Original text: Test content&amp;#x27;}], &amp;#x27;model&amp;#x27;: &amp;#x27;llama3-groq-70b-8192-tool-use-preview&amp;#x27;, &amp;#x27;max_tokens&amp;#x27;: 1000, &amp;#x27;temperature&amp;#x27;: 0.7}}\nDEBUG    httpcore.http11:_trace.py:45 send_request_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 send_request_headers.complete\nDEBUG    httpcore.http11:_trace.py:45 send_request_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 send_request_body.complete\nDEBUG    httpcore.http11:_trace.py:45 receive_response_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 receive_response_headers.complete return_value=(b&amp;#x27;HTTP/1.1&amp;#x27;, 200, b&amp;#x27;OK&amp;#x27;, [(b&amp;#x27;Date&amp;#x27;, b&amp;#x27;Wed, 30 Oct 2024 15:53:43 GMT&amp;#x27;), (b&amp;#x27;Content-Type&amp;#x27;, b&amp;#x27;application/json&amp;#x27;), (b&amp;#x27;Transfer-Encoding&amp;#x27;, b&amp;#x27;chunked&amp;#x27;), (b&amp;#x27;Connection&amp;#x27;, b&amp;#x27;keep-alive&amp;#x27;), (b&amp;#x27;Cache-Control&amp;#x27;, b&amp;#x27;private, max-age=0, no-store, no-cache, must-revalidate&amp;#x27;), (b&amp;#x27;vary&amp;#x27;, b&amp;#x27;Origin&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-requests&amp;#x27;, b&amp;#x27;14400&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-tokens&amp;#x27;, b&amp;#x27;15000&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-requests&amp;#x27;, b&amp;#x27;14367&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-tokens&amp;#x27;, b&amp;#x27;13525&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-requests&amp;#x27;, b&amp;#x27;3m15.798999999s&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-tokens&amp;#x27;, b&amp;#x27;5.897s&amp;#x27;), (b&amp;#x27;x-request-id&amp;#x27;, b&amp;#x27;req_01jbf240k5f4av0c7bqcqzrywx&amp;#x27;), (b&amp;#x27;via&amp;#x27;, b&amp;#x27;1.1 google&amp;#x27;), (b&amp;#x27;alt-svc&amp;#x27;, b&amp;#x27;h3=&amp;quot;:443&amp;quot;; ma=86400&amp;#x27;), (b&amp;#x27;CF-Cache-Status&amp;#x27;, b&amp;#x27;DYNAMIC&amp;#x27;), (b&amp;#x27;Server&amp;#x27;, b&amp;#x27;cloudflare&amp;#x27;), (b&amp;#x27;CF-RAY&amp;#x27;, b&amp;#x27;8dac9470087bca58-HAM&amp;#x27;), (b&amp;#x27;Content-Encoding&amp;#x27;, b&amp;#x27;gzip&amp;#x27;)])\nINFO     httpx:_client.py:1038 HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;HTTP/1.1 200 OK&amp;quot;\nDEBUG    httpcore.http11:_trace.py:45 receive_response_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 receive_response_body.complete\nDEBUG    httpcore.http11:_trace.py:45 response_closed.started\nDEBUG    httpcore.http11:_trace.py:45 response_closed.complete\nDEBUG    groq._base_client:_base_client.py:956 HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;200 OK&amp;quot;\nDEBUG    groq._base_client:_base_client.py:441 Request options: {&amp;#x27;method&amp;#x27;: &amp;#x27;post&amp;#x27;, &amp;#x27;url&amp;#x27;: &amp;#x27;/openai/v1/chat/completions&amp;#x27;, &amp;#x27;files&amp;#x27;: None, &amp;#x27;json_data&amp;#x27;: {&amp;#x27;messages&amp;#x27;: [{&amp;#x27;role&amp;#x27;: &amp;#x27;system&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate a JSON response following these rules:\\n1. Return exactly ONE compressed version:\\n   {&amp;quot;versions&amp;quot;: [{&amp;quot;text&amp;quot;: &amp;quot;compressed version&amp;quot;}]}\\n2. Target exactly the specified percentage of original length\\n3. Maintain core meaning while removing less essential details\\n4. Ensure complete sentences and proper punctuation\\n5. If task cannot be completed: {&amp;quot;error&amp;quot;: &amp;quot;specific reason&amp;quot;}&amp;#x27;}, {&amp;#x27;role&amp;#x27;: &amp;#x27;user&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate ONE compressed version at 50% length:\\n        Original length: 2 tokens\\n        Original text: Test content&amp;#x27;}], &amp;#x27;model&amp;#x27;: &amp;#x27;llama3-groq-70b-8192-tool-use-preview&amp;#x27;, &amp;#x27;max_tokens&amp;#x27;: 1000, &amp;#x27;temperature&amp;#x27;: 0.7}}\nDEBUG    httpcore.http11:_trace.py:45 send_request_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    groq._base_client:_base_client.py:441 Request options: {&amp;#x27;method&amp;#x27;: &amp;#x27;post&amp;#x27;, &amp;#x27;url&amp;#x27;: &amp;#x27;/openai/v1/chat/completions&amp;#x27;, &amp;#x27;files&amp;#x27;: None, &amp;#x27;json_data&amp;#x27;: {&amp;#x27;messages&amp;#x27;: [{&amp;#x27;role&amp;#x27;: &amp;#x27;system&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate a JSON response following these rules:\\n1. Return exactly ONE compressed version:\\n   {&amp;quot;versions&amp;quot;: [{&amp;quot;text&amp;quot;: &amp;quot;compressed version&amp;quot;}]}\\n2. Target exactly the specified percentage of original length\\n3. Maintain core meaning while removing less essential details\\n4. Ensure complete sentences and proper punctuation\\n5. If task cannot be completed: {&amp;quot;error&amp;quot;: &amp;quot;specific reason&amp;quot;}&amp;#x27;}, {&amp;#x27;role&amp;#x27;: &amp;#x27;user&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate ONE compressed version at 50% length:\\n        Original length: 2 tokens\\n        Original text: Test content&amp;#x27;}], &amp;#x27;model&amp;#x27;: &amp;#x27;llama3-groq-70b-8192-tool-use-preview&amp;#x27;, &amp;#x27;max_tokens&amp;#x27;: 1000, &amp;#x27;temperature&amp;#x27;: 0.7}}\nDEBUG    httpcore.http11:_trace.py:45 send_request_headers.complete\nDEBUG    httpcore.http11:_trace.py:45 send_request_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 send_request_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 send_request_body.complete\nDEBUG    httpcore.http11:_trace.py:45 receive_response_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 send_request_headers.complete\nDEBUG    httpcore.http11:_trace.py:45 send_request_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 send_request_body.complete\nDEBUG    httpcore.http11:_trace.py:45 receive_response_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 receive_response_headers.complete return_value=(b&amp;#x27;HTTP/1.1&amp;#x27;, 429, b&amp;#x27;Too Many Requests&amp;#x27;, [(b&amp;#x27;Date&amp;#x27;, b&amp;#x27;Wed, 30 Oct 2024 15:53:44 GMT&amp;#x27;), (b&amp;#x27;Content-Type&amp;#x27;, b&amp;#x27;application/json&amp;#x27;), (b&amp;#x27;Content-Length&amp;#x27;, b&amp;#x27;349&amp;#x27;), (b&amp;#x27;Connection&amp;#x27;, b&amp;#x27;keep-alive&amp;#x27;), (b&amp;#x27;Cache-Control&amp;#x27;, b&amp;#x27;private, max-age=0, no-store, no-cache, must-revalidate&amp;#x27;), (b&amp;#x27;retry-after&amp;#x27;, b&amp;#x27;2&amp;#x27;), (b&amp;#x27;vary&amp;#x27;, b&amp;#x27;Origin&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-requests&amp;#x27;, b&amp;#x27;14400&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-tokens&amp;#x27;, b&amp;#x27;15000&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-requests&amp;#x27;, b&amp;#x27;14367&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-tokens&amp;#x27;, b&amp;#x27;13628&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-requests&amp;#x27;, b&amp;#x27;3m17.621999999s&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-tokens&amp;#x27;, b&amp;#x27;5.488s&amp;#x27;), (b&amp;#x27;x-request-id&amp;#x27;, b&amp;#x27;req_01jbf240z1ej9bj0th02egg5kp&amp;#x27;), (b&amp;#x27;via&amp;#x27;, b&amp;#x27;1.1 google&amp;#x27;), (b&amp;#x27;alt-svc&amp;#x27;, b&amp;#x27;h3=&amp;quot;:443&amp;quot;; ma=86400&amp;#x27;), (b&amp;#x27;CF-Cache-Status&amp;#x27;, b&amp;#x27;DYNAMIC&amp;#x27;), (b&amp;#x27;Server&amp;#x27;, b&amp;#x27;cloudflare&amp;#x27;), (b&amp;#x27;CF-RAY&amp;#x27;, b&amp;#x27;8dac94727afeca58-HAM&amp;#x27;)])\nINFO     httpx:_client.py:1038 HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;HTTP/1.1 429 Too Many Requests&amp;quot;\nDEBUG    httpcore.http11:_trace.py:45 receive_response_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 receive_response_body.complete\nDEBUG    httpcore.http11:_trace.py:45 response_closed.started\nDEBUG    httpcore.http11:_trace.py:45 response_closed.complete\nDEBUG    groq._base_client:_base_client.py:956 HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;429 Too Many Requests&amp;quot;\nDEBUG    groq._base_client:_base_client.py:963 Encountered httpx.HTTPStatusError\nTraceback (most recent call last):\n  File &amp;quot;/Users/julian/Tresors/Privat/Code/fragment-editor-api/.venv-test/lib/python3.12/site-packages/groq/_base_client.py&amp;quot;, line 961, in _request\n    response.raise_for_status()\n  File &amp;quot;/Users/julian/Tresors/Privat/Code/fragment-editor-api/.venv-test/lib/python3.12/site-packages/httpx/_models.py&amp;quot;, line 763, in raise_for_status\n    raise HTTPStatusError(message, request=request, response=self)\nhttpx.HTTPStatusError: Client error &amp;#x27;429 Too Many Requests&amp;#x27; for url &amp;#x27;https://api.groq.com/openai/v1/chat/completions&amp;#x27;\nFor more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File &amp;quot;/Users/julian/Tresors/Privat/Code/fragment-editor-api/.venv-test/lib/python3.12/site-packages/groq/_base_client.py&amp;quot;, line 961, in _request\n    response.raise_for_status()\n  File &amp;quot;/Users/julian/Tresors/Privat/Code/fragment-editor-api/.venv-test/lib/python3.12/site-packages/httpx/_models.py&amp;quot;, line 763, in raise_for_status\n    raise HTTPStatusError(message, request=request, response=self)\nhttpx.HTTPStatusError: Client error &amp;#x27;429 Too Many Requests&amp;#x27; for url &amp;#x27;https://api.groq.com/openai/v1/chat/completions&amp;#x27;\nFor more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\nDEBUG    groq._base_client:_base_client.py:698 Retrying due to status code 429\nDEBUG    groq._base_client:_base_client.py:1006 0 retries left\nINFO     groq._base_client:_base_client.py:1009 Retrying request to /openai/v1/chat/completions in 2.000000 seconds\nDEBUG    httpcore.http11:_trace.py:45 receive_response_headers.complete return_value=(b&amp;#x27;HTTP/1.1&amp;#x27;, 429, b&amp;#x27;Too Many Requests&amp;#x27;, [(b&amp;#x27;Date&amp;#x27;, b&amp;#x27;Wed, 30 Oct 2024 15:53:44 GMT&amp;#x27;), (b&amp;#x27;Content-Type&amp;#x27;, b&amp;#x27;application/json&amp;#x27;), (b&amp;#x27;Content-Length&amp;#x27;, b&amp;#x27;355&amp;#x27;), (b&amp;#x27;Connection&amp;#x27;, b&amp;#x27;keep-alive&amp;#x27;), (b&amp;#x27;Cache-Control&amp;#x27;, b&amp;#x27;private, max-age=0, no-store, no-cache, must-revalidate&amp;#x27;), (b&amp;#x27;retry-after&amp;#x27;, b&amp;#x27;2&amp;#x27;), (b&amp;#x27;vary&amp;#x27;, b&amp;#x27;Origin&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-requests&amp;#x27;, b&amp;#x27;14400&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-tokens&amp;#x27;, b&amp;#x27;15000&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-requests&amp;#x27;, b&amp;#x27;14367&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-tokens&amp;#x27;, b&amp;#x27;13732&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-requests&amp;#x27;, b&amp;#x27;3m17.203s&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-tokens&amp;#x27;, b&amp;#x27;5.069s&amp;#x27;), (b&amp;#x27;x-request-id&amp;#x27;, b&amp;#x27;req_01jbf241c4fj3an42r6ft43kc1&amp;#x27;), (b&amp;#x27;via&amp;#x27;, b&amp;#x27;1.1 google&amp;#x27;), (b&amp;#x27;alt-svc&amp;#x27;, b&amp;#x27;h3=&amp;quot;:443&amp;quot;; ma=86400&amp;#x27;), (b&amp;#x27;CF-Cache-Status&amp;#x27;, b&amp;#x27;DYNAMIC&amp;#x27;), (b&amp;#x27;Server&amp;#x27;, b&amp;#x27;cloudflare&amp;#x27;), (b&amp;#x27;CF-RAY&amp;#x27;, b&amp;#x27;8dac947289e04168-HAM&amp;#x27;)])\nINFO     httpx:_client.py:1038 HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;HTTP/1.1 429 Too Many Requests&amp;quot;\nDEBUG    httpcore.http11:_trace.py:45 receive_response_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 receive_response_body.complete\nDEBUG    httpcore.http11:_trace.py:45 response_closed.started\nDEBUG    httpcore.http11:_trace.py:45 response_closed.complete\nDEBUG    groq._base_client:_base_client.py:956 HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;429 Too Many Requests&amp;quot;\nDEBUG    groq._base_client:_base_client.py:963 Encountered httpx.HTTPStatusError\nTraceback (most recent call last):\n  File &amp;quot;/Users/julian/Tresors/Privat/Code/fragment-editor-api/.venv-test/lib/python3.12/site-packages/groq/_base_client.py&amp;quot;, line 961, in _request\n    response.raise_for_status()\n  File &amp;quot;/Users/julian/Tresors/Privat/Code/fragment-editor-api/.venv-test/lib/python3.12/site-packages/httpx/_models.py&amp;quot;, line 763, in raise_for_status\n    raise HTTPStatusError(message, request=request, response=self)\nhttpx.HTTPStatusError: Client error &amp;#x27;429 Too Many Requests&amp;#x27; for url &amp;#x27;https://api.groq.com/openai/v1/chat/completions&amp;#x27;\nFor more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File &amp;quot;/Users/julian/Tresors/Privat/Code/fragment-editor-api/.venv-test/lib/python3.12/site-packages/groq/_base_client.py&amp;quot;, line 961, in _request\n    response.raise_for_status()\n  File &amp;quot;/Users/julian/Tresors/Privat/Code/fragment-editor-api/.venv-test/lib/python3.12/site-packages/httpx/_models.py&amp;quot;, line 763, in raise_for_status\n    raise HTTPStatusError(message, request=request, response=self)\nhttpx.HTTPStatusError: Client error &amp;#x27;429 Too Many Requests&amp;#x27; for url &amp;#x27;https://api.groq.com/openai/v1/chat/completions&amp;#x27;\nFor more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\nDEBUG    groq._base_client:_base_client.py:698 Retrying due to status code 429\nDEBUG    groq._base_client:_base_client.py:1006 0 retries left\nINFO     groq._base_client:_base_client.py:1009 Retrying request to /openai/v1/chat/completions in 2.000000 seconds\nDEBUG    groq._base_client:_base_client.py:441 Request options: {&amp;#x27;method&amp;#x27;: &amp;#x27;post&amp;#x27;, &amp;#x27;url&amp;#x27;: &amp;#x27;/openai/v1/chat/completions&amp;#x27;, &amp;#x27;files&amp;#x27;: None, &amp;#x27;json_data&amp;#x27;: {&amp;#x27;messages&amp;#x27;: [{&amp;#x27;role&amp;#x27;: &amp;#x27;system&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate a JSON response following these rules:\\n1. Return exactly ONE compressed version:\\n   {&amp;quot;versions&amp;quot;: [{&amp;quot;text&amp;quot;: &amp;quot;compressed version&amp;quot;}]}\\n2. Target exactly the specified percentage of original length\\n3. Maintain core meaning while removing less essential details\\n4. Ensure complete sentences and proper punctuation\\n5. If task cannot be completed: {&amp;quot;error&amp;quot;: &amp;quot;specific reason&amp;quot;}&amp;#x27;}, {&amp;#x27;role&amp;#x27;: &amp;#x27;user&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate ONE compressed version at 50% length:\\n        Original length: 2 tokens\\n        Original text: Test content&amp;#x27;}], &amp;#x27;model&amp;#x27;: &amp;#x27;llama3-groq-70b-8192-tool-use-preview&amp;#x27;, &amp;#x27;max_tokens&amp;#x27;: 1000, &amp;#x27;temperature&amp;#x27;: 0.7}}\nDEBUG    httpcore.http11:_trace.py:45 send_request_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 send_request_headers.complete\nDEBUG    httpcore.http11:_trace.py:45 send_request_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 send_request_body.complete\nDEBUG    httpcore.http11:_trace.py:45 receive_response_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 receive_response_headers.complete return_value=(b&amp;#x27;HTTP/1.1&amp;#x27;, 200, b&amp;#x27;OK&amp;#x27;, [(b&amp;#x27;Date&amp;#x27;, b&amp;#x27;Wed, 30 Oct 2024 15:53:46 GMT&amp;#x27;), (b&amp;#x27;Content-Type&amp;#x27;, b&amp;#x27;application/json&amp;#x27;), (b&amp;#x27;Transfer-Encoding&amp;#x27;, b&amp;#x27;chunked&amp;#x27;), (b&amp;#x27;Connection&amp;#x27;, b&amp;#x27;keep-alive&amp;#x27;), (b&amp;#x27;Cache-Control&amp;#x27;, b&amp;#x27;private, max-age=0, no-store, no-cache, must-revalidate&amp;#x27;), (b&amp;#x27;vary&amp;#x27;, b&amp;#x27;Origin&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-requests&amp;#x27;, b&amp;#x27;14400&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-tokens&amp;#x27;, b&amp;#x27;15000&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-requests&amp;#x27;, b&amp;#x27;14366&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-tokens&amp;#x27;, b&amp;#x27;14041&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-requests&amp;#x27;, b&amp;#x27;3m21.435s&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-tokens&amp;#x27;, b&amp;#x27;3.834s&amp;#x27;), (b&amp;#x27;x-request-id&amp;#x27;, b&amp;#x27;req_01jbf2433bebpbtfzsv2ccmjca&amp;#x27;), (b&amp;#x27;via&amp;#x27;, b&amp;#x27;1.1 google&amp;#x27;), (b&amp;#x27;alt-svc&amp;#x27;, b&amp;#x27;h3=&amp;quot;:443&amp;quot;; ma=86400&amp;#x27;), (b&amp;#x27;CF-Cache-Status&amp;#x27;, b&amp;#x27;DYNAMIC&amp;#x27;), (b&amp;#x27;Server&amp;#x27;, b&amp;#x27;cloudflare&amp;#x27;), (b&amp;#x27;CF-RAY&amp;#x27;, b&amp;#x27;8dac94801a6fca58-HAM&amp;#x27;), (b&amp;#x27;Content-Encoding&amp;#x27;, b&amp;#x27;gzip&amp;#x27;)])\nINFO     httpx:_client.py:1038 HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;HTTP/1.1 200 OK&amp;quot;\nDEBUG    httpcore.http11:_trace.py:45 receive_response_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 receive_response_body.complete\nDEBUG    httpcore.http11:_trace.py:45 response_closed.started\nDEBUG    httpcore.http11:_trace.py:45 response_closed.complete\nDEBUG    groq._base_client:_base_client.py:956 HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;200 OK&amp;quot;\nDEBUG    groq._base_client:_base_client.py:441 Request options: {&amp;#x27;method&amp;#x27;: &amp;#x27;post&amp;#x27;, &amp;#x27;url&amp;#x27;: &amp;#x27;/openai/v1/chat/completions&amp;#x27;, &amp;#x27;files&amp;#x27;: None, &amp;#x27;json_data&amp;#x27;: {&amp;#x27;messages&amp;#x27;: [{&amp;#x27;role&amp;#x27;: &amp;#x27;system&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate a JSON response following these rules:\\n1. Return exactly ONE compressed version:\\n   {&amp;quot;versions&amp;quot;: [{&amp;quot;text&amp;quot;: &amp;quot;compressed version&amp;quot;}]}\\n2. Target exactly the specified percentage of original length\\n3. Maintain core meaning while removing less essential details\\n4. Ensure complete sentences and proper punctuation\\n5. If task cannot be completed: {&amp;quot;error&amp;quot;: &amp;quot;specific reason&amp;quot;}&amp;#x27;}, {&amp;#x27;role&amp;#x27;: &amp;#x27;user&amp;#x27;, &amp;#x27;content&amp;#x27;: &amp;#x27;Generate ONE compressed version at 50% length:\\n        Original length: 2 tokens\\n        Original text: Test content&amp;#x27;}], &amp;#x27;model&amp;#x27;: &amp;#x27;llama3-groq-70b-8192-tool-use-preview&amp;#x27;, &amp;#x27;max_tokens&amp;#x27;: 1000, &amp;#x27;temperature&amp;#x27;: 0.7}}\nDEBUG    httpcore.http11:_trace.py:45 send_request_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 send_request_headers.complete\nDEBUG    httpcore.http11:_trace.py:45 send_request_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 send_request_body.complete\nDEBUG    httpcore.http11:_trace.py:45 receive_response_headers.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 receive_response_headers.complete return_value=(b&amp;#x27;HTTP/1.1&amp;#x27;, 429, b&amp;#x27;Too Many Requests&amp;#x27;, [(b&amp;#x27;Date&amp;#x27;, b&amp;#x27;Wed, 30 Oct 2024 15:53:46 GMT&amp;#x27;), (b&amp;#x27;Content-Type&amp;#x27;, b&amp;#x27;application/json&amp;#x27;), (b&amp;#x27;Content-Length&amp;#x27;, b&amp;#x27;349&amp;#x27;), (b&amp;#x27;Connection&amp;#x27;, b&amp;#x27;keep-alive&amp;#x27;), (b&amp;#x27;Cache-Control&amp;#x27;, b&amp;#x27;private, max-age=0, no-store, no-cache, must-revalidate&amp;#x27;), (b&amp;#x27;retry-after&amp;#x27;, b&amp;#x27;2&amp;#x27;), (b&amp;#x27;vary&amp;#x27;, b&amp;#x27;Origin&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-requests&amp;#x27;, b&amp;#x27;14400&amp;#x27;), (b&amp;#x27;x-ratelimit-limit-tokens&amp;#x27;, b&amp;#x27;15000&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-requests&amp;#x27;, b&amp;#x27;14366&amp;#x27;), (b&amp;#x27;x-ratelimit-remaining-tokens&amp;#x27;, b&amp;#x27;14152&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-requests&amp;#x27;, b&amp;#x27;3m23.587s&amp;#x27;), (b&amp;#x27;x-ratelimit-reset-tokens&amp;#x27;, b&amp;#x27;3.389s&amp;#x27;), (b&amp;#x27;x-request-id&amp;#x27;, b&amp;#x27;req_01jbf243g9e40vrha3xsxg5qkj&amp;#x27;), (b&amp;#x27;via&amp;#x27;, b&amp;#x27;1.1 google&amp;#x27;), (b&amp;#x27;alt-svc&amp;#x27;, b&amp;#x27;h3=&amp;quot;:443&amp;quot;; ma=86400&amp;#x27;), (b&amp;#x27;CF-Cache-Status&amp;#x27;, b&amp;#x27;DYNAMIC&amp;#x27;), (b&amp;#x27;Server&amp;#x27;, b&amp;#x27;cloudflare&amp;#x27;), (b&amp;#x27;CF-RAY&amp;#x27;, b&amp;#x27;8dac9482bd39ca58-HAM&amp;#x27;)])\nINFO     httpx:_client.py:1038 HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;HTTP/1.1 429 Too Many Requests&amp;quot;\nDEBUG    httpcore.http11:_trace.py:45 receive_response_body.started request=&amp;lt;Request [b&amp;#x27;POST&amp;#x27;]&amp;gt;\nDEBUG    httpcore.http11:_trace.py:45 receive_response_body.complete\nDEBUG    httpcore.http11:_trace.py:45 response_closed.started\nDEBUG    httpcore.http11:_trace.py:45 response_closed.complete\nDEBUG    httpcore.connection:_trace.py:45 close.started\nDEBUG    httpcore.connection:_trace.py:45 close.complete\nDEBUG    httpcore.connection:_trace.py:45 close.started\nDEBUG    httpcore.connection:_trace.py:45 close.complete\nDEBUG    httpcore.connection:_trace.py:45 close.started\nDEBUG    httpcore.connection:_trace.py:45 close.complete\nDEBUG    httpcore.connection:_trace.py:45 close.started\nDEBUG    httpcore.connection:_trace.py:45 close.complete\nDEBUG    httpcore.connection:_trace.py:45 close.started\nDEBUG    httpcore.connection:_trace.py:45 close.complete\nDEBUG    httpcore.connection:_trace.py:45 close.started\nDEBUG    httpcore.connection:_trace.py:45 close.complete\nDEBUG    httpcore.connection:_trace.py:45 close.started\nDEBUG    httpcore.connection:_trace.py:45 close.complete\nDEBUG    groq._base_client:_base_client.py:956 HTTP Request: POST https://api.groq.com/openai/v1/chat/completions &amp;quot;429 Too Many Requests&amp;quot;\nDEBUG    groq._base_client:_base_client.py:963 Encountered httpx.HTTPStatusError\nTraceback (most recent call last):\n  File &amp;quot;/Users/julian/Tresors/Privat/Code/fragment-editor-api/.venv-test/lib/python3.12/site-packages/groq/_base_client.py&amp;quot;, line 961, in _request\n    response.raise_for_status()\n  File &amp;quot;/Users/julian/Tresors/Privat/Code/fragment-editor-api/.venv-test/lib/python3.12/site-packages/httpx/_models.py&amp;quot;, line 763, in raise_for_status\n    raise HTTPStatusError(message, request=request, response=self)\nhttpx.HTTPStatusError: Client error &amp;#x27;429 Too Many Requests&amp;#x27; for url &amp;#x27;https://api.groq.com/openai/v1/chat/completions&amp;#x27;\nFor more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File &amp;quot;/Users/julian/Tresors/Privat/Code/fragment-editor-api/.venv-test/lib/python3.12/site-packages/groq/_base_client.py&amp;quot;, line 961, in _request\n    response.raise_for_status()\n  File &amp;quot;/Users/julian/Tresors/Privat/Code/fragment-editor-api/.venv-test/lib/python3.12/site-packages/httpx/_models.py&amp;quot;, line 763, in raise_for_status\n    raise HTTPStatusError(message, request=request, response=self)\nhttpx.HTTPStatusError: Client error &amp;#x27;429 Too Many Requests&amp;#x27; for url &amp;#x27;https://api.groq.com/openai/v1/chat/completions&amp;#x27;\nFor more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File &amp;quot;/Users/julian/Tresors/Privat/Code/fragment-editor-api/.venv-test/lib/python3.12/site-packages/groq/_base_client.py&amp;quot;, line 961, in _request\n    response.raise_for_status()\n  File &amp;quot;/Users/julian/Tresors/Privat/Code/fragment-editor-api/.venv-test/lib/python3.12/site-packages/httpx/_models.py&amp;quot;, line 763, in raise_for_status\n    raise HTTPStatusError(message, request=request, response=self)\nhttpx.HTTPStatusError: Client error &amp;#x27;429 Too Many Requests&amp;#x27; for url &amp;#x27;https://api.groq.com/openai/v1/chat/completions&amp;#x27;\nFor more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\nDEBUG    groq._base_client:_base_client.py:981 Re-raising status error\n\n&#34;}], &#34;tests/test_compress.py::TestCompressEndpoint::test_single_version_compression&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Failed&#34;, &#34;testId&#34;: &#34;tests/test_compress.py::TestCompressEndpoint::test_single_version_compression&#34;, &#34;duration&#34;: &#34;517 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Failed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_compress.py::TestCompressEndpoint::test_single_version_compression&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;517 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;self = &amp;lt;tests.test_compress.TestCompressEndpoint object at 0x1069d0e30&amp;gt;\nclient = &amp;lt;FlaskClient &amp;lt;Flask &amp;#x27;app&amp;#x27;&amp;gt;&amp;gt;, auth_headers = {&amp;#x27;Authorization&amp;#x27;: &amp;#x27;Bearer test_key&amp;#x27;}\n\n    @pytest.mark.unit\n    def test_single_version_compression(self, client, auth_headers):\n        response = client.post(self.ENDPOINTS[&amp;#x27;compress&amp;#x27;], json={\n            &amp;#x27;content&amp;#x27;: self.SAMPLE_TEXT,\n            &amp;#x27;target_percentage&amp;#x27;: 40\n        }, headers=auth_headers)\n    \n&amp;gt;       assert response.status_code == 200\nE       assert 500 == 200\nE        +  where 500 = &amp;lt;WrapperTestResponse streamed [500 INTERNAL SERVER ERROR]&amp;gt;.status_code\n\ntests/test_compress.py:37: AssertionError\n\n---------------------------- Captured stderr setup -----------------------------\nDEBUG:app:Registering blueprints...\nDEBUG:app:Registered routes:\nDEBUG:app:static: /static/&amp;lt;path:filename&amp;gt; [GET, OPTIONS, HEAD]\nDEBUG:app:generate.create_text: /text/v1/generate/text [OPTIONS, POST]\nDEBUG:app:compress.compress_text: /text/v1/compress/ [OPTIONS, POST]\nDEBUG:app:expand.expand_text: /text/v1/expand/ [OPTIONS, POST]\n\n------------------------------ Captured log setup ------------------------------\nDEBUG    app:__init__.py:106 Registering blueprints...\nDEBUG    app:__init__.py:112 Registered routes:\nDEBUG    app:__init__.py:114 static: /static/&amp;lt;path:filename&amp;gt; [GET, OPTIONS, HEAD]\nDEBUG    app:__init__.py:114 generate.create_text: /text/v1/generate/text [OPTIONS, POST]\nDEBUG    app:__init__.py:114 compress.compress_text: /text/v1/compress/ [OPTIONS, POST]\nDEBUG    app:__init__.py:114 expand.expand_text: /text/v1/expand/ [OPTIONS, POST]\n\n----------------------------- Captured stderr call -----------------------------\nDEBUG:app:Headers: {&amp;#x27;User-Agent&amp;#x27;: &amp;#x27;Werkzeug/3.0.6&amp;#x27;, &amp;#x27;Host&amp;#x27;: &amp;#x27;localhost&amp;#x27;, &amp;#x27;Content-Type&amp;#x27;: &amp;#x27;application/json&amp;#x27;, &amp;#x27;Content-Length&amp;#x27;: &amp;#x27;250&amp;#x27;, &amp;#x27;Authorization&amp;#x27;: &amp;#x27;Bearer test_key&amp;#x27;}\nDEBUG:app:Body: b&amp;#x27;{&amp;quot;content&amp;quot;: &amp;quot;The Text Transformation API offers a robust set of REST endpoints that enable developers to programmatically manipulate and transform text content. The operations include expansion, summarization, and chunking.&amp;quot;, &amp;quot;target_percentage&amp;quot;: 40}&amp;#x27;\nDEBUG:app:Query Params: {}\nDEBUG:app:Route: POST /text/v1/compress/\nERROR:app:An error occurred: &amp;#x27;API_KEY&amp;#x27;\nTraceback (most recent call last):\n  File &amp;quot;/Users/julian/Tresors/Privat/Code/fragment-editor-api/.venv-test/lib/python3.12/site-packages/flask/app.py&amp;quot;, line 870, in full_dispatch_request\n    rv = self.dispatch_request()\n         ^^^^^^^^^^^^^^^^^^^^^^^\n  File &amp;quot;/Users/julian/Tresors/Privat/Code/fragment-editor-api/.venv-test/lib/python3.12/site-packages/flask/app.py&amp;quot;, line 855, in dispatch_request\n    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File &amp;quot;/Users/julian/Tresors/Privat/Code/fragment-editor-api/app/middleware/auth.py&amp;quot;, line 17, in decorated_function\n    if token != current_app.config[&amp;#x27;API_KEY&amp;#x27;]:\n                ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^\nKeyError: &amp;#x27;API_KEY&amp;#x27;\n\n------------------------------ Captured log call -------------------------------\nDEBUG    app:__init__.py:31 Headers: {&amp;#x27;User-Agent&amp;#x27;: &amp;#x27;Werkzeug/3.0.6&amp;#x27;, &amp;#x27;Host&amp;#x27;: &amp;#x27;localhost&amp;#x27;, &amp;#x27;Content-Type&amp;#x27;: &amp;#x27;application/json&amp;#x27;, &amp;#x27;Content-Length&amp;#x27;: &amp;#x27;250&amp;#x27;, &amp;#x27;Authorization&amp;#x27;: &amp;#x27;Bearer test_key&amp;#x27;}\nDEBUG    app:__init__.py:32 Body: b&amp;#x27;{&amp;quot;content&amp;quot;: &amp;quot;The Text Transformation API offers a robust set of REST endpoints that enable developers to programmatically manipulate and transform text content. The operations include expansion, summarization, and chunking.&amp;quot;, &amp;quot;target_percentage&amp;quot;: 40}&amp;#x27;\nDEBUG    app:__init__.py:33 Query Params: {}\nDEBUG    app:__init__.py:34 Route: POST /text/v1/compress/\nERROR    app:__init__.py:77 An error occurred: &amp;#x27;API_KEY&amp;#x27;\nTraceback (most recent call last):\n  File &amp;quot;/Users/julian/Tresors/Privat/Code/fragment-editor-api/.venv-test/lib/python3.12/site-packages/flask/app.py&amp;quot;, line 870, in full_dispatch_request\n    rv = self.dispatch_request()\n         ^^^^^^^^^^^^^^^^^^^^^^^\n  File &amp;quot;/Users/julian/Tresors/Privat/Code/fragment-editor-api/.venv-test/lib/python3.12/site-packages/flask/app.py&amp;quot;, line 855, in dispatch_request\n    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File &amp;quot;/Users/julian/Tresors/Privat/Code/fragment-editor-api/app/middleware/auth.py&amp;quot;, line 17, in decorated_function\n    if token != current_app.config[&amp;#x27;API_KEY&amp;#x27;]:\n                ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^\nKeyError: &amp;#x27;API_KEY&amp;#x27;\n\n&#34;}], &#34;tests/test_compress.py::TestCompressEndpoint::test_fixed_multiple_versions&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Failed&#34;, &#34;testId&#34;: &#34;tests/test_compress.py::TestCompressEndpoint::test_fixed_multiple_versions&#34;, &#34;duration&#34;: &#34;511 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Failed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_compress.py::TestCompressEndpoint::test_fixed_multiple_versions&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;511 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;self = &amp;lt;tests.test_compress.TestCompressEndpoint object at 0x1069d0f20&amp;gt;\nclient = &amp;lt;FlaskClient &amp;lt;Flask &amp;#x27;app&amp;#x27;&amp;gt;&amp;gt;, auth_headers = {&amp;#x27;Authorization&amp;#x27;: &amp;#x27;Bearer test_key&amp;#x27;}\n\n    @pytest.mark.unit\n    def test_fixed_multiple_versions(self, client, auth_headers):\n        response = client.post(self.ENDPOINTS[&amp;#x27;compress&amp;#x27;], json={\n            &amp;#x27;content&amp;#x27;: self.SAMPLE_TEXT,\n            &amp;#x27;target_percentage&amp;#x27;: 50,\n            &amp;#x27;versions&amp;#x27;: 3\n        }, headers=auth_headers)\n    \n&amp;gt;       assert response.status_code == 200\nE       assert 500 == 200\nE        +  where 500 = &amp;lt;WrapperTestResponse streamed [500 INTERNAL SERVER ERROR]&amp;gt;.status_code\n\ntests/test_compress.py:68: AssertionError\n\n---------------------------- Captured stderr setup -----------------------------\nDEBUG:app:Registering blueprints...\nDEBUG:app:Registered routes:\nDEBUG:app:static: /static/&amp;lt;path:filename&amp;gt; [GET, OPTIONS, HEAD]\nDEBUG:app:generate.create_text: /text/v1/generate/text [OPTIONS, POST]\nDEBUG:app:compress.compress_text: /text/v1/compress/ [OPTIONS, POST]\nDEBUG:app:expand.expand_text: /text/v1/expand/ [OPTIONS, POST]\n\n------------------------------ Captured log setup ------------------------------\nDEBUG    app:__init__.py:106 Registering blueprints...\nDEBUG    app:__init__.py:112 Registered routes:\nDEBUG    app:__init__.py:114 static: /static/&amp;lt;path:filename&amp;gt; [GET, OPTIONS, HEAD]\nDEBUG    app:__init__.py:114 generate.create_text: /text/v1/generate/text [OPTIONS, POST]\nDEBUG    app:__init__.py:114 compress.compress_text: /text/v1/compress/ [OPTIONS, POST]\nDEBUG    app:__init__.py:114 expand.expand_text: /text/v1/expand/ [OPTIONS, POST]\n\n----------------------------- Captured stderr call -----------------------------\nDEBUG:app:Headers: {&amp;#x27;User-Agent&amp;#x27;: &amp;#x27;Werkzeug/3.0.6&amp;#x27;, &amp;#x27;Host&amp;#x27;: &amp;#x27;localhost&amp;#x27;, &amp;#x27;Content-Type&amp;#x27;: &amp;#x27;application/json&amp;#x27;, &amp;#x27;Content-Length&amp;#x27;: &amp;#x27;265&amp;#x27;, &amp;#x27;Authorization&amp;#x27;: &amp;#x27;Bearer test_key&amp;#x27;}\nDEBUG:app:Body: b&amp;#x27;{&amp;quot;content&amp;quot;: &amp;quot;The Text Transformation API offers a robust set of REST endpoints that enable developers to programmatically manipulate and transform text content. The operations include expansion, summarization, and chunking.&amp;quot;, &amp;quot;target_percentage&amp;quot;: 50, &amp;quot;versions&amp;quot;: 3}&amp;#x27;\nDEBUG:app:Query Params: {}\nDEBUG:app:Route: POST /text/v1/compress/\nERROR:app:An error occurred: &amp;#x27;API_KEY&amp;#x27;\nTraceback (most recent call last):\n  File &amp;quot;/Users/julian/Tresors/Privat/Code/fragment-editor-api/.venv-test/lib/python3.12/site-packages/flask/app.py&amp;quot;, line 870, in full_dispatch_request\n    rv = self.dispatch_request()\n         ^^^^^^^^^^^^^^^^^^^^^^^\n  File &amp;quot;/Users/julian/Tresors/Privat/Code/fragment-editor-api/.venv-test/lib/python3.12/site-packages/flask/app.py&amp;quot;, line 855, in dispatch_request\n    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File &amp;quot;/Users/julian/Tresors/Privat/Code/fragment-editor-api/app/middleware/auth.py&amp;quot;, line 17, in decorated_function\n    if token != current_app.config[&amp;#x27;API_KEY&amp;#x27;]:\n                ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^\nKeyError: &amp;#x27;API_KEY&amp;#x27;\n\n------------------------------ Captured log call -------------------------------\nDEBUG    app:__init__.py:31 Headers: {&amp;#x27;User-Agent&amp;#x27;: &amp;#x27;Werkzeug/3.0.6&amp;#x27;, &amp;#x27;Host&amp;#x27;: &amp;#x27;localhost&amp;#x27;, &amp;#x27;Content-Type&amp;#x27;: &amp;#x27;application/json&amp;#x27;, &amp;#x27;Content-Length&amp;#x27;: &amp;#x27;265&amp;#x27;, &amp;#x27;Authorization&amp;#x27;: &amp;#x27;Bearer test_key&amp;#x27;}\nDEBUG    app:__init__.py:32 Body: b&amp;#x27;{&amp;quot;content&amp;quot;: &amp;quot;The Text Transformation API offers a robust set of REST endpoints that enable developers to programmatically manipulate and transform text content. The operations include expansion, summarization, and chunking.&amp;quot;, &amp;quot;target_percentage&amp;quot;: 50, &amp;quot;versions&amp;quot;: 3}&amp;#x27;\nDEBUG    app:__init__.py:33 Query Params: {}\nDEBUG    app:__init__.py:34 Route: POST /text/v1/compress/\nERROR    app:__init__.py:77 An error occurred: &amp;#x27;API_KEY&amp;#x27;\nTraceback (most recent call last):\n  File &amp;quot;/Users/julian/Tresors/Privat/Code/fragment-editor-api/.venv-test/lib/python3.12/site-packages/flask/app.py&amp;quot;, line 870, in full_dispatch_request\n    rv = self.dispatch_request()\n         ^^^^^^^^^^^^^^^^^^^^^^^\n  File &amp;quot;/Users/julian/Tresors/Privat/Code/fragment-editor-api/.venv-test/lib/python3.12/site-packages/flask/app.py&amp;quot;, line 855, in dispatch_request\n    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File &amp;quot;/Users/julian/Tresors/Privat/Code/fragment-editor-api/app/middleware/auth.py&amp;quot;, line 17, in decorated_function\n    if token != current_app.config[&amp;#x27;API_KEY&amp;#x27;]:\n                ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^\nKeyError: &amp;#x27;API_KEY&amp;#x27;\n\n&#34;}], &#34;tests/test_compress.py::TestCompressEndpoint::test_staggered_with_steps&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Failed&#34;, &#34;testId&#34;: &#34;tests/test_compress.py::TestCompressEndpoint::test_staggered_with_steps&#34;, &#34;duration&#34;: &#34;509 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Failed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_compress.py::TestCompressEndpoint::test_staggered_with_steps&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;509 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;self = &amp;lt;tests.test_compress.TestCompressEndpoint object at 0x1069d1070&amp;gt;\nclient = &amp;lt;FlaskClient &amp;lt;Flask &amp;#x27;app&amp;#x27;&amp;gt;&amp;gt;, auth_headers = {&amp;#x27;Authorization&amp;#x27;: &amp;#x27;Bearer test_key&amp;#x27;}\n\n    @pytest.mark.unit\n    def test_staggered_with_steps(self, client, auth_headers):\n        response = client.post(self.ENDPOINTS[&amp;#x27;compress&amp;#x27;], json={\n            &amp;#x27;content&amp;#x27;: self.SAMPLE_TEXT,\n            &amp;#x27;target_percentage&amp;#x27;: 40,\n            &amp;#x27;steps_percentage&amp;#x27;: 10\n        }, headers=auth_headers)\n    \n        data = response.json\n&amp;gt;       versions = data[&amp;#x27;versions&amp;#x27;]\nE       KeyError: &amp;#x27;versions&amp;#x27;\n\ntests/test_compress.py:84: KeyError\n\n---------------------------- Captured stderr setup -----------------------------\nDEBUG:app:Registering blueprints...\nDEBUG:app:Registered routes:\nDEBUG:app:static: /static/&amp;lt;path:filename&amp;gt; [GET, OPTIONS, HEAD]\nDEBUG:app:generate.create_text: /text/v1/generate/text [OPTIONS, POST]\nDEBUG:app:compress.compress_text: /text/v1/compress/ [OPTIONS, POST]\nDEBUG:app:expand.expand_text: /text/v1/expand/ [OPTIONS, POST]\n\n------------------------------ Captured log setup ------------------------------\nDEBUG    app:__init__.py:106 Registering blueprints...\nDEBUG    app:__init__.py:112 Registered routes:\nDEBUG    app:__init__.py:114 static: /static/&amp;lt;path:filename&amp;gt; [GET, OPTIONS, HEAD]\nDEBUG    app:__init__.py:114 generate.create_text: /text/v1/generate/text [OPTIONS, POST]\nDEBUG    app:__init__.py:114 compress.compress_text: /text/v1/compress/ [OPTIONS, POST]\nDEBUG    app:__init__.py:114 expand.expand_text: /text/v1/expand/ [OPTIONS, POST]\n\n----------------------------- Captured stderr call -----------------------------\nDEBUG:app:Headers: {&amp;#x27;User-Agent&amp;#x27;: &amp;#x27;Werkzeug/3.0.6&amp;#x27;, &amp;#x27;Host&amp;#x27;: &amp;#x27;localhost&amp;#x27;, &amp;#x27;Content-Type&amp;#x27;: &amp;#x27;application/json&amp;#x27;, &amp;#x27;Content-Length&amp;#x27;: &amp;#x27;274&amp;#x27;, &amp;#x27;Authorization&amp;#x27;: &amp;#x27;Bearer test_key&amp;#x27;}\nDEBUG:app:Body: b&amp;#x27;{&amp;quot;content&amp;quot;: &amp;quot;The Text Transformation API offers a robust set of REST endpoints that enable developers to programmatically manipulate and transform text content. The operations include expansion, summarization, and chunking.&amp;quot;, &amp;quot;steps_percentage&amp;quot;: 10, &amp;quot;target_percentage&amp;quot;: 40}&amp;#x27;\nDEBUG:app:Query Params: {}\nDEBUG:app:Route: POST /text/v1/compress/\nERROR:app:An error occurred: &amp;#x27;API_KEY&amp;#x27;\nTraceback (most recent call last):\n  File &amp;quot;/Users/julian/Tresors/Privat/Code/fragment-editor-api/.venv-test/lib/python3.12/site-packages/flask/app.py&amp;quot;, line 870, in full_dispatch_request\n    rv = self.dispatch_request()\n         ^^^^^^^^^^^^^^^^^^^^^^^\n  File &amp;quot;/Users/julian/Tresors/Privat/Code/fragment-editor-api/.venv-test/lib/python3.12/site-packages/flask/app.py&amp;quot;, line 855, in dispatch_request\n    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File &amp;quot;/Users/julian/Tresors/Privat/Code/fragment-editor-api/app/middleware/auth.py&amp;quot;, line 17, in decorated_function\n    if token != current_app.config[&amp;#x27;API_KEY&amp;#x27;]:\n                ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^\nKeyError: &amp;#x27;API_KEY&amp;#x27;\n\n------------------------------ Captured log call -------------------------------\nDEBUG    app:__init__.py:31 Headers: {&amp;#x27;User-Agent&amp;#x27;: &amp;#x27;Werkzeug/3.0.6&amp;#x27;, &amp;#x27;Host&amp;#x27;: &amp;#x27;localhost&amp;#x27;, &amp;#x27;Content-Type&amp;#x27;: &amp;#x27;application/json&amp;#x27;, &amp;#x27;Content-Length&amp;#x27;: &amp;#x27;274&amp;#x27;, &amp;#x27;Authorization&amp;#x27;: &amp;#x27;Bearer test_key&amp;#x27;}\nDEBUG    app:__init__.py:32 Body: b&amp;#x27;{&amp;quot;content&amp;quot;: &amp;quot;The Text Transformation API offers a robust set of REST endpoints that enable developers to programmatically manipulate and transform text content. The operations include expansion, summarization, and chunking.&amp;quot;, &amp;quot;steps_percentage&amp;quot;: 10, &amp;quot;target_percentage&amp;quot;: 40}&amp;#x27;\nDEBUG    app:__init__.py:33 Query Params: {}\nDEBUG    app:__init__.py:34 Route: POST /text/v1/compress/\nERROR    app:__init__.py:77 An error occurred: &amp;#x27;API_KEY&amp;#x27;\nTraceback (most recent call last):\n  File &amp;quot;/Users/julian/Tresors/Privat/Code/fragment-editor-api/.venv-test/lib/python3.12/site-packages/flask/app.py&amp;quot;, line 870, in full_dispatch_request\n    rv = self.dispatch_request()\n         ^^^^^^^^^^^^^^^^^^^^^^^\n  File &amp;quot;/Users/julian/Tresors/Privat/Code/fragment-editor-api/.venv-test/lib/python3.12/site-packages/flask/app.py&amp;quot;, line 855, in dispatch_request\n    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File &amp;quot;/Users/julian/Tresors/Privat/Code/fragment-editor-api/app/middleware/auth.py&amp;quot;, line 17, in decorated_function\n    if token != current_app.config[&amp;#x27;API_KEY&amp;#x27;]:\n                ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^\nKeyError: &amp;#x27;API_KEY&amp;#x27;\n\n&#34;}], &#34;tests/test_compress.py::TestCompressEndpoint::test_staggered_custom_range&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Failed&#34;, &#34;testId&#34;: &#34;tests/test_compress.py::TestCompressEndpoint::test_staggered_custom_range&#34;, &#34;duration&#34;: &#34;512 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Failed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_compress.py::TestCompressEndpoint::test_staggered_custom_range&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;512 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;self = &amp;lt;tests.test_compress.TestCompressEndpoint object at 0x1069d11c0&amp;gt;\nclient = &amp;lt;FlaskClient &amp;lt;Flask &amp;#x27;app&amp;#x27;&amp;gt;&amp;gt;, auth_headers = {&amp;#x27;Authorization&amp;#x27;: &amp;#x27;Bearer test_key&amp;#x27;}\n\n    @pytest.mark.unit\n    def test_staggered_custom_range(self, client, auth_headers):\n        response = client.post(self.ENDPOINTS[&amp;#x27;compress&amp;#x27;], json={\n            &amp;#x27;content&amp;#x27;: self.SAMPLE_TEXT,\n            &amp;#x27;start_percentage&amp;#x27;: 60,\n            &amp;#x27;target_percentage&amp;#x27;: 40,\n            &amp;#x27;versions&amp;#x27;: 5\n        }, headers=auth_headers)\n    \n        data = response.json\n&amp;gt;       percentages = data[&amp;#x27;metadata&amp;#x27;][&amp;#x27;target_percentages&amp;#x27;]\nE       KeyError: &amp;#x27;metadata&amp;#x27;\n\ntests/test_compress.py:100: KeyError\n\n---------------------------- Captured stderr setup -----------------------------\nDEBUG:app:Registering blueprints...\nDEBUG:app:Registered routes:\nDEBUG:app:static: /static/&amp;lt;path:filename&amp;gt; [GET, OPTIONS, HEAD]\nDEBUG:app:generate.create_text: /text/v1/generate/text [OPTIONS, POST]\nDEBUG:app:compress.compress_text: /text/v1/compress/ [OPTIONS, POST]\nDEBUG:app:expand.expand_text: /text/v1/expand/ [OPTIONS, POST]\n\n------------------------------ Captured log setup ------------------------------\nDEBUG    app:__init__.py:106 Registering blueprints...\nDEBUG    app:__init__.py:112 Registered routes:\nDEBUG    app:__init__.py:114 static: /static/&amp;lt;path:filename&amp;gt; [GET, OPTIONS, HEAD]\nDEBUG    app:__init__.py:114 generate.create_text: /text/v1/generate/text [OPTIONS, POST]\nDEBUG    app:__init__.py:114 compress.compress_text: /text/v1/compress/ [OPTIONS, POST]\nDEBUG    app:__init__.py:114 expand.expand_text: /text/v1/expand/ [OPTIONS, POST]\n\n----------------------------- Captured stderr call -----------------------------\nDEBUG:app:Headers: {&amp;#x27;User-Agent&amp;#x27;: &amp;#x27;Werkzeug/3.0.6&amp;#x27;, &amp;#x27;Host&amp;#x27;: &amp;#x27;localhost&amp;#x27;, &amp;#x27;Content-Type&amp;#x27;: &amp;#x27;application/json&amp;#x27;, &amp;#x27;Content-Length&amp;#x27;: &amp;#x27;289&amp;#x27;, &amp;#x27;Authorization&amp;#x27;: &amp;#x27;Bearer test_key&amp;#x27;}\nDEBUG:app:Body: b&amp;#x27;{&amp;quot;content&amp;quot;: &amp;quot;The Text Transformation API offers a robust set of REST endpoints that enable developers to programmatically manipulate and transform text content. The operations include expansion, summarization, and chunking.&amp;quot;, &amp;quot;start_percentage&amp;quot;: 60, &amp;quot;target_percentage&amp;quot;: 40, &amp;quot;versions&amp;quot;: 5}&amp;#x27;\nDEBUG:app:Query Params: {}\nDEBUG:app:Route: POST /text/v1/compress/\nERROR:app:An error occurred: &amp;#x27;API_KEY&amp;#x27;\nTraceback (most recent call last):\n  File &amp;quot;/Users/julian/Tresors/Privat/Code/fragment-editor-api/.venv-test/lib/python3.12/site-packages/flask/app.py&amp;quot;, line 870, in full_dispatch_request\n    rv = self.dispatch_request()\n         ^^^^^^^^^^^^^^^^^^^^^^^\n  File &amp;quot;/Users/julian/Tresors/Privat/Code/fragment-editor-api/.venv-test/lib/python3.12/site-packages/flask/app.py&amp;quot;, line 855, in dispatch_request\n    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File &amp;quot;/Users/julian/Tresors/Privat/Code/fragment-editor-api/app/middleware/auth.py&amp;quot;, line 17, in decorated_function\n    if token != current_app.config[&amp;#x27;API_KEY&amp;#x27;]:\n                ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^\nKeyError: &amp;#x27;API_KEY&amp;#x27;\n\n------------------------------ Captured log call -------------------------------\nDEBUG    app:__init__.py:31 Headers: {&amp;#x27;User-Agent&amp;#x27;: &amp;#x27;Werkzeug/3.0.6&amp;#x27;, &amp;#x27;Host&amp;#x27;: &amp;#x27;localhost&amp;#x27;, &amp;#x27;Content-Type&amp;#x27;: &amp;#x27;application/json&amp;#x27;, &amp;#x27;Content-Length&amp;#x27;: &amp;#x27;289&amp;#x27;, &amp;#x27;Authorization&amp;#x27;: &amp;#x27;Bearer test_key&amp;#x27;}\nDEBUG    app:__init__.py:32 Body: b&amp;#x27;{&amp;quot;content&amp;quot;: &amp;quot;The Text Transformation API offers a robust set of REST endpoints that enable developers to programmatically manipulate and transform text content. The operations include expansion, summarization, and chunking.&amp;quot;, &amp;quot;start_percentage&amp;quot;: 60, &amp;quot;target_percentage&amp;quot;: 40, &amp;quot;versions&amp;quot;: 5}&amp;#x27;\nDEBUG    app:__init__.py:33 Query Params: {}\nDEBUG    app:__init__.py:34 Route: POST /text/v1/compress/\nERROR    app:__init__.py:77 An error occurred: &amp;#x27;API_KEY&amp;#x27;\nTraceback (most recent call last):\n  File &amp;quot;/Users/julian/Tresors/Privat/Code/fragment-editor-api/.venv-test/lib/python3.12/site-packages/flask/app.py&amp;quot;, line 870, in full_dispatch_request\n    rv = self.dispatch_request()\n         ^^^^^^^^^^^^^^^^^^^^^^^\n  File &amp;quot;/Users/julian/Tresors/Privat/Code/fragment-editor-api/.venv-test/lib/python3.12/site-packages/flask/app.py&amp;quot;, line 855, in dispatch_request\n    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File &amp;quot;/Users/julian/Tresors/Privat/Code/fragment-editor-api/app/middleware/auth.py&amp;quot;, line 17, in decorated_function\n    if token != current_app.config[&amp;#x27;API_KEY&amp;#x27;]:\n                ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^\nKeyError: &amp;#x27;API_KEY&amp;#x27;\n\n&#34;}], &#34;tests/test_compress.py::TestCompressEndpoint::test_array_input&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Failed&#34;, &#34;testId&#34;: &#34;tests/test_compress.py::TestCompressEndpoint::test_array_input&#34;, &#34;duration&#34;: &#34;514 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Failed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_compress.py::TestCompressEndpoint::test_array_input&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;514 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;self = &amp;lt;tests.test_compress.TestCompressEndpoint object at 0x1069d1310&amp;gt;\nclient = &amp;lt;FlaskClient &amp;lt;Flask &amp;#x27;app&amp;#x27;&amp;gt;&amp;gt;, auth_headers = {&amp;#x27;Authorization&amp;#x27;: &amp;#x27;Bearer test_key&amp;#x27;}\n\n    @pytest.mark.unit\n    def test_array_input(self, client, auth_headers):\n        response = client.post(self.ENDPOINTS[&amp;#x27;compress&amp;#x27;], json={\n            &amp;#x27;content&amp;#x27;: [\n                &amp;quot;The Text Transformation API offers REST endpoints&amp;quot;,\n                &amp;quot;These endpoints enable text manipulation&amp;quot;,\n                &amp;quot;Operations include various transformations&amp;quot;\n            ],\n            &amp;#x27;target_percentage&amp;#x27;: 50,\n            &amp;#x27;versions&amp;#x27;: 2\n        }, headers=auth_headers)\n    \n        data = response.json\n&amp;gt;       assert data[&amp;#x27;type&amp;#x27;] == &amp;#x27;fragments&amp;#x27;\nE       KeyError: &amp;#x27;type&amp;#x27;\n\ntests/test_compress.py:116: KeyError\n\n---------------------------- Captured stderr setup -----------------------------\nDEBUG:app:Registering blueprints...\nDEBUG:app:Registered routes:\nDEBUG:app:static: /static/&amp;lt;path:filename&amp;gt; [GET, OPTIONS, HEAD]\nDEBUG:app:generate.create_text: /text/v1/generate/text [OPTIONS, POST]\nDEBUG:app:compress.compress_text: /text/v1/compress/ [OPTIONS, POST]\nDEBUG:app:expand.expand_text: /text/v1/expand/ [OPTIONS, POST]\n\n------------------------------ Captured log setup ------------------------------\nDEBUG    app:__init__.py:106 Registering blueprints...\nDEBUG    app:__init__.py:112 Registered routes:\nDEBUG    app:__init__.py:114 static: /static/&amp;lt;path:filename&amp;gt; [GET, OPTIONS, HEAD]\nDEBUG    app:__init__.py:114 generate.create_text: /text/v1/generate/text [OPTIONS, POST]\nDEBUG    app:__init__.py:114 compress.compress_text: /text/v1/compress/ [OPTIONS, POST]\nDEBUG    app:__init__.py:114 expand.expand_text: /text/v1/expand/ [OPTIONS, POST]\n\n----------------------------- Captured stderr call -----------------------------\nDEBUG:app:Headers: {&amp;#x27;User-Agent&amp;#x27;: &amp;#x27;Werkzeug/3.0.6&amp;#x27;, &amp;#x27;Host&amp;#x27;: &amp;#x27;localhost&amp;#x27;, &amp;#x27;Content-Type&amp;#x27;: &amp;#x27;application/json&amp;#x27;, &amp;#x27;Content-Length&amp;#x27;: &amp;#x27;196&amp;#x27;, &amp;#x27;Authorization&amp;#x27;: &amp;#x27;Bearer test_key&amp;#x27;}\nDEBUG:app:Body: b&amp;#x27;{&amp;quot;content&amp;quot;: [&amp;quot;The Text Transformation API offers REST endpoints&amp;quot;, &amp;quot;These endpoints enable text manipulation&amp;quot;, &amp;quot;Operations include various transformations&amp;quot;], &amp;quot;target_percentage&amp;quot;: 50, &amp;quot;versions&amp;quot;: 2}&amp;#x27;\nDEBUG:app:Query Params: {}\nDEBUG:app:Route: POST /text/v1/compress/\nERROR:app:An error occurred: &amp;#x27;API_KEY&amp;#x27;\nTraceback (most recent call last):\n  File &amp;quot;/Users/julian/Tresors/Privat/Code/fragment-editor-api/.venv-test/lib/python3.12/site-packages/flask/app.py&amp;quot;, line 870, in full_dispatch_request\n    rv = self.dispatch_request()\n         ^^^^^^^^^^^^^^^^^^^^^^^\n  File &amp;quot;/Users/julian/Tresors/Privat/Code/fragment-editor-api/.venv-test/lib/python3.12/site-packages/flask/app.py&amp;quot;, line 855, in dispatch_request\n    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File &amp;quot;/Users/julian/Tresors/Privat/Code/fragment-editor-api/app/middleware/auth.py&amp;quot;, line 17, in decorated_function\n    if token != current_app.config[&amp;#x27;API_KEY&amp;#x27;]:\n                ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^\nKeyError: &amp;#x27;API_KEY&amp;#x27;\n\n------------------------------ Captured log call -------------------------------\nDEBUG    app:__init__.py:31 Headers: {&amp;#x27;User-Agent&amp;#x27;: &amp;#x27;Werkzeug/3.0.6&amp;#x27;, &amp;#x27;Host&amp;#x27;: &amp;#x27;localhost&amp;#x27;, &amp;#x27;Content-Type&amp;#x27;: &amp;#x27;application/json&amp;#x27;, &amp;#x27;Content-Length&amp;#x27;: &amp;#x27;196&amp;#x27;, &amp;#x27;Authorization&amp;#x27;: &amp;#x27;Bearer test_key&amp;#x27;}\nDEBUG    app:__init__.py:32 Body: b&amp;#x27;{&amp;quot;content&amp;quot;: [&amp;quot;The Text Transformation API offers REST endpoints&amp;quot;, &amp;quot;These endpoints enable text manipulation&amp;quot;, &amp;quot;Operations include various transformations&amp;quot;], &amp;quot;target_percentage&amp;quot;: 50, &amp;quot;versions&amp;quot;: 2}&amp;#x27;\nDEBUG    app:__init__.py:33 Query Params: {}\nDEBUG    app:__init__.py:34 Route: POST /text/v1/compress/\nERROR    app:__init__.py:77 An error occurred: &amp;#x27;API_KEY&amp;#x27;\nTraceback (most recent call last):\n  File &amp;quot;/Users/julian/Tresors/Privat/Code/fragment-editor-api/.venv-test/lib/python3.12/site-packages/flask/app.py&amp;quot;, line 870, in full_dispatch_request\n    rv = self.dispatch_request()\n         ^^^^^^^^^^^^^^^^^^^^^^^\n  File &amp;quot;/Users/julian/Tresors/Privat/Code/fragment-editor-api/.venv-test/lib/python3.12/site-packages/flask/app.py&amp;quot;, line 855, in dispatch_request\n    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File &amp;quot;/Users/julian/Tresors/Privat/Code/fragment-editor-api/app/middleware/auth.py&amp;quot;, line 17, in decorated_function\n    if token != current_app.config[&amp;#x27;API_KEY&amp;#x27;]:\n                ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^\nKeyError: &amp;#x27;API_KEY&amp;#x27;\n\n&#34;}], &#34;tests/test_compress.py::TestCompressEndpoint::test_invalid_inputs[invalid_input0]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Failed&#34;, &#34;testId&#34;: &#34;tests/test_compress.py::TestCompressEndpoint::test_invalid_inputs[invalid_input0]&#34;, &#34;duration&#34;: &#34;514 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Failed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_compress.py::TestCompressEndpoint::test_invalid_inputs[invalid_input0]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;514 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;self = &amp;lt;tests.test_compress.TestCompressEndpoint object at 0x1069d1520&amp;gt;\nclient = &amp;lt;FlaskClient &amp;lt;Flask &amp;#x27;app&amp;#x27;&amp;gt;&amp;gt;, auth_headers = {&amp;#x27;Authorization&amp;#x27;: &amp;#x27;Bearer test_key&amp;#x27;}\ninvalid_input = {&amp;#x27;content&amp;#x27;: &amp;#x27;text&amp;#x27;, &amp;#x27;target_percentage&amp;#x27;: 150}\n\n    @pytest.mark.unit\n    @pytest.mark.parametrize(&amp;#x27;invalid_input&amp;#x27;, [\n        {&amp;#x27;content&amp;#x27;: &amp;quot;text&amp;quot;, &amp;#x27;target_percentage&amp;#x27;: 150},  # Invalid percentage\n        {&amp;#x27;content&amp;#x27;: &amp;quot;text&amp;quot;, &amp;#x27;steps_percentage&amp;#x27;: -10},   # Negative steps\n        {&amp;#x27;content&amp;#x27;: &amp;quot;text&amp;quot;, &amp;#x27;versions&amp;#x27;: 10},            # Too many versions\n        {&amp;#x27;content&amp;#x27;: &amp;quot;&amp;quot;, &amp;#x27;target_percentage&amp;#x27;: 50},       # Empty content\n        {&amp;#x27;target_percentage&amp;#x27;: 50},                      # Missing content\n    ])\n    def test_invalid_inputs(self, client, auth_headers, invalid_input):\n        response = client.post(\n            self.ENDPOINTS[&amp;#x27;compress&amp;#x27;], json=invalid_input, headers=auth_headers)\n&amp;gt;       assert response.status_code == 400\nE       assert 500 == 400\nE        +  where 500 = &amp;lt;WrapperTestResponse streamed [500 INTERNAL SERVER ERROR]&amp;gt;.status_code\n\ntests/test_compress.py:139: AssertionError\n\n---------------------------- Captured stderr setup -----------------------------\nDEBUG:app:Registering blueprints...\nDEBUG:app:Registered routes:\nDEBUG:app:static: /static/&amp;lt;path:filename&amp;gt; [GET, OPTIONS, HEAD]\nDEBUG:app:generate.create_text: /text/v1/generate/text [OPTIONS, POST]\nDEBUG:app:compress.compress_text: /text/v1/compress/ [OPTIONS, POST]\nDEBUG:app:expand.expand_text: /text/v1/expand/ [OPTIONS, POST]\n\n------------------------------ Captured log setup ------------------------------\nDEBUG    app:__init__.py:106 Registering blueprints...\nDEBUG    app:__init__.py:112 Registered routes:\nDEBUG    app:__init__.py:114 static: /static/&amp;lt;path:filename&amp;gt; [GET, OPTIONS, HEAD]\nDEBUG    app:__init__.py:114 generate.create_text: /text/v1/generate/text [OPTIONS, POST]\nDEBUG    app:__init__.py:114 compress.compress_text: /text/v1/compress/ [OPTIONS, POST]\nDEBUG    app:__init__.py:114 expand.expand_text: /text/v1/expand/ [OPTIONS, POST]\n\n----------------------------- Captured stderr call -----------------------------\nDEBUG:app:Headers: {&amp;#x27;User-Agent&amp;#x27;: &amp;#x27;Werkzeug/3.0.6&amp;#x27;, &amp;#x27;Host&amp;#x27;: &amp;#x27;localhost&amp;#x27;, &amp;#x27;Content-Type&amp;#x27;: &amp;#x27;application/json&amp;#x27;, &amp;#x27;Content-Length&amp;#x27;: &amp;#x27;45&amp;#x27;, &amp;#x27;Authorization&amp;#x27;: &amp;#x27;Bearer test_key&amp;#x27;}\nDEBUG:app:Body: b&amp;#x27;{&amp;quot;content&amp;quot;: &amp;quot;text&amp;quot;, &amp;quot;target_percentage&amp;quot;: 150}&amp;#x27;\nDEBUG:app:Query Params: {}\nDEBUG:app:Route: POST /text/v1/compress/\nERROR:app:An error occurred: &amp;#x27;API_KEY&amp;#x27;\nTraceback (most recent call last):\n  File &amp;quot;/Users/julian/Tresors/Privat/Code/fragment-editor-api/.venv-test/lib/python3.12/site-packages/flask/app.py&amp;quot;, line 870, in full_dispatch_request\n    rv = self.dispatch_request()\n         ^^^^^^^^^^^^^^^^^^^^^^^\n  File &amp;quot;/Users/julian/Tresors/Privat/Code/fragment-editor-api/.venv-test/lib/python3.12/site-packages/flask/app.py&amp;quot;, line 855, in dispatch_request\n    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File &amp;quot;/Users/julian/Tresors/Privat/Code/fragment-editor-api/app/middleware/auth.py&amp;quot;, line 17, in decorated_function\n    if token != current_app.config[&amp;#x27;API_KEY&amp;#x27;]:\n                ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^\nKeyError: &amp;#x27;API_KEY&amp;#x27;\n\n------------------------------ Captured log call -------------------------------\nDEBUG    app:__init__.py:31 Headers: {&amp;#x27;User-Agent&amp;#x27;: &amp;#x27;Werkzeug/3.0.6&amp;#x27;, &amp;#x27;Host&amp;#x27;: &amp;#x27;localhost&amp;#x27;, &amp;#x27;Content-Type&amp;#x27;: &amp;#x27;application/json&amp;#x27;, &amp;#x27;Content-Length&amp;#x27;: &amp;#x27;45&amp;#x27;, &amp;#x27;Authorization&amp;#x27;: &amp;#x27;Bearer test_key&amp;#x27;}\nDEBUG    app:__init__.py:32 Body: b&amp;#x27;{&amp;quot;content&amp;quot;: &amp;quot;text&amp;quot;, &amp;quot;target_percentage&amp;quot;: 150}&amp;#x27;\nDEBUG    app:__init__.py:33 Query Params: {}\nDEBUG    app:__init__.py:34 Route: POST /text/v1/compress/\nERROR    app:__init__.py:77 An error occurred: &amp;#x27;API_KEY&amp;#x27;\nTraceback (most recent call last):\n  File &amp;quot;/Users/julian/Tresors/Privat/Code/fragment-editor-api/.venv-test/lib/python3.12/site-packages/flask/app.py&amp;quot;, line 870, in full_dispatch_request\n    rv = self.dispatch_request()\n         ^^^^^^^^^^^^^^^^^^^^^^^\n  File &amp;quot;/Users/julian/Tresors/Privat/Code/fragment-editor-api/.venv-test/lib/python3.12/site-packages/flask/app.py&amp;quot;, line 855, in dispatch_request\n    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File &amp;quot;/Users/julian/Tresors/Privat/Code/fragment-editor-api/app/middleware/auth.py&amp;quot;, line 17, in decorated_function\n    if token != current_app.config[&amp;#x27;API_KEY&amp;#x27;]:\n                ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^\nKeyError: &amp;#x27;API_KEY&amp;#x27;\n\n&#34;}], &#34;tests/test_compress.py::TestCompressEndpoint::test_invalid_inputs[invalid_input1]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Failed&#34;, &#34;testId&#34;: &#34;tests/test_compress.py::TestCompressEndpoint::test_invalid_inputs[invalid_input1]&#34;, &#34;duration&#34;: &#34;513 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Failed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_compress.py::TestCompressEndpoint::test_invalid_inputs[invalid_input1]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;513 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;self = &amp;lt;tests.test_compress.TestCompressEndpoint object at 0x1069d16a0&amp;gt;\nclient = &amp;lt;FlaskClient &amp;lt;Flask &amp;#x27;app&amp;#x27;&amp;gt;&amp;gt;, auth_headers = {&amp;#x27;Authorization&amp;#x27;: &amp;#x27;Bearer test_key&amp;#x27;}\ninvalid_input = {&amp;#x27;content&amp;#x27;: &amp;#x27;text&amp;#x27;, &amp;#x27;steps_percentage&amp;#x27;: -10}\n\n    @pytest.mark.unit\n    @pytest.mark.parametrize(&amp;#x27;invalid_input&amp;#x27;, [\n        {&amp;#x27;content&amp;#x27;: &amp;quot;text&amp;quot;, &amp;#x27;target_percentage&amp;#x27;: 150},  # Invalid percentage\n        {&amp;#x27;content&amp;#x27;: &amp;quot;text&amp;quot;, &amp;#x27;steps_percentage&amp;#x27;: -10},   # Negative steps\n        {&amp;#x27;content&amp;#x27;: &amp;quot;text&amp;quot;, &amp;#x27;versions&amp;#x27;: 10},            # Too many versions\n        {&amp;#x27;content&amp;#x27;: &amp;quot;&amp;quot;, &amp;#x27;target_percentage&amp;#x27;: 50},       # Empty content\n        {&amp;#x27;target_percentage&amp;#x27;: 50},                      # Missing content\n    ])\n    def test_invalid_inputs(self, client, auth_headers, invalid_input):\n        response = client.post(\n            self.ENDPOINTS[&amp;#x27;compress&amp;#x27;], json=invalid_input, headers=auth_headers)\n&amp;gt;       assert response.status_code == 400\nE       assert 500 == 400\nE        +  where 500 = &amp;lt;WrapperTestResponse streamed [500 INTERNAL SERVER ERROR]&amp;gt;.status_code\n\ntests/test_compress.py:139: AssertionError\n\n---------------------------- Captured stderr setup -----------------------------\nDEBUG:app:Registering blueprints...\nDEBUG:app:Registered routes:\nDEBUG:app:static: /static/&amp;lt;path:filename&amp;gt; [GET, OPTIONS, HEAD]\nDEBUG:app:generate.create_text: /text/v1/generate/text [OPTIONS, POST]\nDEBUG:app:compress.compress_text: /text/v1/compress/ [OPTIONS, POST]\nDEBUG:app:expand.expand_text: /text/v1/expand/ [OPTIONS, POST]\n\n------------------------------ Captured log setup ------------------------------\nDEBUG    app:__init__.py:106 Registering blueprints...\nDEBUG    app:__init__.py:112 Registered routes:\nDEBUG    app:__init__.py:114 static: /static/&amp;lt;path:filename&amp;gt; [GET, OPTIONS, HEAD]\nDEBUG    app:__init__.py:114 generate.create_text: /text/v1/generate/text [OPTIONS, POST]\nDEBUG    app:__init__.py:114 compress.compress_text: /text/v1/compress/ [OPTIONS, POST]\nDEBUG    app:__init__.py:114 expand.expand_text: /text/v1/expand/ [OPTIONS, POST]\n\n----------------------------- Captured stderr call -----------------------------\nDEBUG:app:Headers: {&amp;#x27;User-Agent&amp;#x27;: &amp;#x27;Werkzeug/3.0.6&amp;#x27;, &amp;#x27;Host&amp;#x27;: &amp;#x27;localhost&amp;#x27;, &amp;#x27;Content-Type&amp;#x27;: &amp;#x27;application/json&amp;#x27;, &amp;#x27;Content-Length&amp;#x27;: &amp;#x27;44&amp;#x27;, &amp;#x27;Authorization&amp;#x27;: &amp;#x27;Bearer test_key&amp;#x27;}\nDEBUG:app:Body: b&amp;#x27;{&amp;quot;content&amp;quot;: &amp;quot;text&amp;quot;, &amp;quot;steps_percentage&amp;quot;: -10}&amp;#x27;\nDEBUG:app:Query Params: {}\nDEBUG:app:Route: POST /text/v1/compress/\nERROR:app:An error occurred: &amp;#x27;API_KEY&amp;#x27;\nTraceback (most recent call last):\n  File &amp;quot;/Users/julian/Tresors/Privat/Code/fragment-editor-api/.venv-test/lib/python3.12/site-packages/flask/app.py&amp;quot;, line 870, in full_dispatch_request\n    rv = self.dispatch_request()\n         ^^^^^^^^^^^^^^^^^^^^^^^\n  File &amp;quot;/Users/julian/Tresors/Privat/Code/fragment-editor-api/.venv-test/lib/python3.12/site-packages/flask/app.py&amp;quot;, line 855, in dispatch_request\n    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File &amp;quot;/Users/julian/Tresors/Privat/Code/fragment-editor-api/app/middleware/auth.py&amp;quot;, line 17, in decorated_function\n    if token != current_app.config[&amp;#x27;API_KEY&amp;#x27;]:\n                ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^\nKeyError: &amp;#x27;API_KEY&amp;#x27;\n\n------------------------------ Captured log call -------------------------------\nDEBUG    app:__init__.py:31 Headers: {&amp;#x27;User-Agent&amp;#x27;: &amp;#x27;Werkzeug/3.0.6&amp;#x27;, &amp;#x27;Host&amp;#x27;: &amp;#x27;localhost&amp;#x27;, &amp;#x27;Content-Type&amp;#x27;: &amp;#x27;application/json&amp;#x27;, &amp;#x27;Content-Length&amp;#x27;: &amp;#x27;44&amp;#x27;, &amp;#x27;Authorization&amp;#x27;: &amp;#x27;Bearer test_key&amp;#x27;}\nDEBUG    app:__init__.py:32 Body: b&amp;#x27;{&amp;quot;content&amp;quot;: &amp;quot;text&amp;quot;, &amp;quot;steps_percentage&amp;quot;: -10}&amp;#x27;\nDEBUG    app:__init__.py:33 Query Params: {}\nDEBUG    app:__init__.py:34 Route: POST /text/v1/compress/\nERROR    app:__init__.py:77 An error occurred: &amp;#x27;API_KEY&amp;#x27;\nTraceback (most recent call last):\n  File &amp;quot;/Users/julian/Tresors/Privat/Code/fragment-editor-api/.venv-test/lib/python3.12/site-packages/flask/app.py&amp;quot;, line 870, in full_dispatch_request\n    rv = self.dispatch_request()\n         ^^^^^^^^^^^^^^^^^^^^^^^\n  File &amp;quot;/Users/julian/Tresors/Privat/Code/fragment-editor-api/.venv-test/lib/python3.12/site-packages/flask/app.py&amp;quot;, line 855, in dispatch_request\n    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File &amp;quot;/Users/julian/Tresors/Privat/Code/fragment-editor-api/app/middleware/auth.py&amp;quot;, line 17, in decorated_function\n    if token != current_app.config[&amp;#x27;API_KEY&amp;#x27;]:\n                ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^\nKeyError: &amp;#x27;API_KEY&amp;#x27;\n\n&#34;}], &#34;tests/test_compress.py::TestCompressEndpoint::test_invalid_inputs[invalid_input2]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Failed&#34;, &#34;testId&#34;: &#34;tests/test_compress.py::TestCompressEndpoint::test_invalid_inputs[invalid_input2]&#34;, &#34;duration&#34;: &#34;516 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Failed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_compress.py::TestCompressEndpoint::test_invalid_inputs[invalid_input2]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;516 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;self = &amp;lt;tests.test_compress.TestCompressEndpoint object at 0x1069d1850&amp;gt;\nclient = &amp;lt;FlaskClient &amp;lt;Flask &amp;#x27;app&amp;#x27;&amp;gt;&amp;gt;, auth_headers = {&amp;#x27;Authorization&amp;#x27;: &amp;#x27;Bearer test_key&amp;#x27;}\ninvalid_input = {&amp;#x27;content&amp;#x27;: &amp;#x27;text&amp;#x27;, &amp;#x27;versions&amp;#x27;: 10}\n\n    @pytest.mark.unit\n    @pytest.mark.parametrize(&amp;#x27;invalid_input&amp;#x27;, [\n        {&amp;#x27;content&amp;#x27;: &amp;quot;text&amp;quot;, &amp;#x27;target_percentage&amp;#x27;: 150},  # Invalid percentage\n        {&amp;#x27;content&amp;#x27;: &amp;quot;text&amp;quot;, &amp;#x27;steps_percentage&amp;#x27;: -10},   # Negative steps\n        {&amp;#x27;content&amp;#x27;: &amp;quot;text&amp;quot;, &amp;#x27;versions&amp;#x27;: 10},            # Too many versions\n        {&amp;#x27;content&amp;#x27;: &amp;quot;&amp;quot;, &amp;#x27;target_percentage&amp;#x27;: 50},       # Empty content\n        {&amp;#x27;target_percentage&amp;#x27;: 50},                      # Missing content\n    ])\n    def test_invalid_inputs(self, client, auth_headers, invalid_input):\n        response = client.post(\n            self.ENDPOINTS[&amp;#x27;compress&amp;#x27;], json=invalid_input, headers=auth_headers)\n&amp;gt;       assert response.status_code == 400\nE       assert 500 == 400\nE        +  where 500 = &amp;lt;WrapperTestResponse streamed [500 INTERNAL SERVER ERROR]&amp;gt;.status_code\n\ntests/test_compress.py:139: AssertionError\n\n---------------------------- Captured stderr setup -----------------------------\nDEBUG:app:Registering blueprints...\nDEBUG:app:Registered routes:\nDEBUG:app:static: /static/&amp;lt;path:filename&amp;gt; [GET, OPTIONS, HEAD]\nDEBUG:app:generate.create_text: /text/v1/generate/text [OPTIONS, POST]\nDEBUG:app:compress.compress_text: /text/v1/compress/ [OPTIONS, POST]\nDEBUG:app:expand.expand_text: /text/v1/expand/ [OPTIONS, POST]\n\n------------------------------ Captured log setup ------------------------------\nDEBUG    app:__init__.py:106 Registering blueprints...\nDEBUG    app:__init__.py:112 Registered routes:\nDEBUG    app:__init__.py:114 static: /static/&amp;lt;path:filename&amp;gt; [GET, OPTIONS, HEAD]\nDEBUG    app:__init__.py:114 generate.create_text: /text/v1/generate/text [OPTIONS, POST]\nDEBUG    app:__init__.py:114 compress.compress_text: /text/v1/compress/ [OPTIONS, POST]\nDEBUG    app:__init__.py:114 expand.expand_text: /text/v1/expand/ [OPTIONS, POST]\n\n----------------------------- Captured stderr call -----------------------------\nDEBUG:app:Headers: {&amp;#x27;User-Agent&amp;#x27;: &amp;#x27;Werkzeug/3.0.6&amp;#x27;, &amp;#x27;Host&amp;#x27;: &amp;#x27;localhost&amp;#x27;, &amp;#x27;Content-Type&amp;#x27;: &amp;#x27;application/json&amp;#x27;, &amp;#x27;Content-Length&amp;#x27;: &amp;#x27;35&amp;#x27;, &amp;#x27;Authorization&amp;#x27;: &amp;#x27;Bearer test_key&amp;#x27;}\nDEBUG:app:Body: b&amp;#x27;{&amp;quot;content&amp;quot;: &amp;quot;text&amp;quot;, &amp;quot;versions&amp;quot;: 10}&amp;#x27;\nDEBUG:app:Query Params: {}\nDEBUG:app:Route: POST /text/v1/compress/\nERROR:app:An error occurred: &amp;#x27;API_KEY&amp;#x27;\nTraceback (most recent call last):\n  File &amp;quot;/Users/julian/Tresors/Privat/Code/fragment-editor-api/.venv-test/lib/python3.12/site-packages/flask/app.py&amp;quot;, line 870, in full_dispatch_request\n    rv = self.dispatch_request()\n         ^^^^^^^^^^^^^^^^^^^^^^^\n  File &amp;quot;/Users/julian/Tresors/Privat/Code/fragment-editor-api/.venv-test/lib/python3.12/site-packages/flask/app.py&amp;quot;, line 855, in dispatch_request\n    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File &amp;quot;/Users/julian/Tresors/Privat/Code/fragment-editor-api/app/middleware/auth.py&amp;quot;, line 17, in decorated_function\n    if token != current_app.config[&amp;#x27;API_KEY&amp;#x27;]:\n                ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^\nKeyError: &amp;#x27;API_KEY&amp;#x27;\n\n------------------------------ Captured log call -------------------------------\nDEBUG    app:__init__.py:31 Headers: {&amp;#x27;User-Agent&amp;#x27;: &amp;#x27;Werkzeug/3.0.6&amp;#x27;, &amp;#x27;Host&amp;#x27;: &amp;#x27;localhost&amp;#x27;, &amp;#x27;Content-Type&amp;#x27;: &amp;#x27;application/json&amp;#x27;, &amp;#x27;Content-Length&amp;#x27;: &amp;#x27;35&amp;#x27;, &amp;#x27;Authorization&amp;#x27;: &amp;#x27;Bearer test_key&amp;#x27;}\nDEBUG    app:__init__.py:32 Body: b&amp;#x27;{&amp;quot;content&amp;quot;: &amp;quot;text&amp;quot;, &amp;quot;versions&amp;quot;: 10}&amp;#x27;\nDEBUG    app:__init__.py:33 Query Params: {}\nDEBUG    app:__init__.py:34 Route: POST /text/v1/compress/\nERROR    app:__init__.py:77 An error occurred: &amp;#x27;API_KEY&amp;#x27;\nTraceback (most recent call last):\n  File &amp;quot;/Users/julian/Tresors/Privat/Code/fragment-editor-api/.venv-test/lib/python3.12/site-packages/flask/app.py&amp;quot;, line 870, in full_dispatch_request\n    rv = self.dispatch_request()\n         ^^^^^^^^^^^^^^^^^^^^^^^\n  File &amp;quot;/Users/julian/Tresors/Privat/Code/fragment-editor-api/.venv-test/lib/python3.12/site-packages/flask/app.py&amp;quot;, line 855, in dispatch_request\n    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File &amp;quot;/Users/julian/Tresors/Privat/Code/fragment-editor-api/app/middleware/auth.py&amp;quot;, line 17, in decorated_function\n    if token != current_app.config[&amp;#x27;API_KEY&amp;#x27;]:\n                ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^\nKeyError: &amp;#x27;API_KEY&amp;#x27;\n\n&#34;}], &#34;tests/test_compress.py::TestCompressEndpoint::test_invalid_inputs[invalid_input3]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Failed&#34;, &#34;testId&#34;: &#34;tests/test_compress.py::TestCompressEndpoint::test_invalid_inputs[invalid_input3]&#34;, &#34;duration&#34;: &#34;515 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Failed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_compress.py::TestCompressEndpoint::test_invalid_inputs[invalid_input3]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;515 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;self = &amp;lt;tests.test_compress.TestCompressEndpoint object at 0x1069d18e0&amp;gt;\nclient = &amp;lt;FlaskClient &amp;lt;Flask &amp;#x27;app&amp;#x27;&amp;gt;&amp;gt;, auth_headers = {&amp;#x27;Authorization&amp;#x27;: &amp;#x27;Bearer test_key&amp;#x27;}\ninvalid_input = {&amp;#x27;content&amp;#x27;: &amp;#x27;&amp;#x27;, &amp;#x27;target_percentage&amp;#x27;: 50}\n\n    @pytest.mark.unit\n    @pytest.mark.parametrize(&amp;#x27;invalid_input&amp;#x27;, [\n        {&amp;#x27;content&amp;#x27;: &amp;quot;text&amp;quot;, &amp;#x27;target_percentage&amp;#x27;: 150},  # Invalid percentage\n        {&amp;#x27;content&amp;#x27;: &amp;quot;text&amp;quot;, &amp;#x27;steps_percentage&amp;#x27;: -10},   # Negative steps\n        {&amp;#x27;content&amp;#x27;: &amp;quot;text&amp;quot;, &amp;#x27;versions&amp;#x27;: 10},            # Too many versions\n        {&amp;#x27;content&amp;#x27;: &amp;quot;&amp;quot;, &amp;#x27;target_percentage&amp;#x27;: 50},       # Empty content\n        {&amp;#x27;target_percentage&amp;#x27;: 50},                      # Missing content\n    ])\n    def test_invalid_inputs(self, client, auth_headers, invalid_input):\n        response = client.post(\n            self.ENDPOINTS[&amp;#x27;compress&amp;#x27;], json=invalid_input, headers=auth_headers)\n&amp;gt;       assert response.status_code == 400\nE       assert 500 == 400\nE        +  where 500 = &amp;lt;WrapperTestResponse streamed [500 INTERNAL SERVER ERROR]&amp;gt;.status_code\n\ntests/test_compress.py:139: AssertionError\n\n---------------------------- Captured stderr setup -----------------------------\nDEBUG:app:Registering blueprints...\nDEBUG:app:Registered routes:\nDEBUG:app:static: /static/&amp;lt;path:filename&amp;gt; [GET, OPTIONS, HEAD]\nDEBUG:app:generate.create_text: /text/v1/generate/text [OPTIONS, POST]\nDEBUG:app:compress.compress_text: /text/v1/compress/ [OPTIONS, POST]\nDEBUG:app:expand.expand_text: /text/v1/expand/ [OPTIONS, POST]\n\n------------------------------ Captured log setup ------------------------------\nDEBUG    app:__init__.py:106 Registering blueprints...\nDEBUG    app:__init__.py:112 Registered routes:\nDEBUG    app:__init__.py:114 static: /static/&amp;lt;path:filename&amp;gt; [GET, OPTIONS, HEAD]\nDEBUG    app:__init__.py:114 generate.create_text: /text/v1/generate/text [OPTIONS, POST]\nDEBUG    app:__init__.py:114 compress.compress_text: /text/v1/compress/ [OPTIONS, POST]\nDEBUG    app:__init__.py:114 expand.expand_text: /text/v1/expand/ [OPTIONS, POST]\n\n----------------------------- Captured stderr call -----------------------------\nDEBUG:app:Headers: {&amp;#x27;User-Agent&amp;#x27;: &amp;#x27;Werkzeug/3.0.6&amp;#x27;, &amp;#x27;Host&amp;#x27;: &amp;#x27;localhost&amp;#x27;, &amp;#x27;Content-Type&amp;#x27;: &amp;#x27;application/json&amp;#x27;, &amp;#x27;Content-Length&amp;#x27;: &amp;#x27;40&amp;#x27;, &amp;#x27;Authorization&amp;#x27;: &amp;#x27;Bearer test_key&amp;#x27;}\nDEBUG:app:Body: b&amp;#x27;{&amp;quot;content&amp;quot;: &amp;quot;&amp;quot;, &amp;quot;target_percentage&amp;quot;: 50}&amp;#x27;\nDEBUG:app:Query Params: {}\nDEBUG:app:Route: POST /text/v1/compress/\nERROR:app:An error occurred: &amp;#x27;API_KEY&amp;#x27;\nTraceback (most recent call last):\n  File &amp;quot;/Users/julian/Tresors/Privat/Code/fragment-editor-api/.venv-test/lib/python3.12/site-packages/flask/app.py&amp;quot;, line 870, in full_dispatch_request\n    rv = self.dispatch_request()\n         ^^^^^^^^^^^^^^^^^^^^^^^\n  File &amp;quot;/Users/julian/Tresors/Privat/Code/fragment-editor-api/.venv-test/lib/python3.12/site-packages/flask/app.py&amp;quot;, line 855, in dispatch_request\n    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File &amp;quot;/Users/julian/Tresors/Privat/Code/fragment-editor-api/app/middleware/auth.py&amp;quot;, line 17, in decorated_function\n    if token != current_app.config[&amp;#x27;API_KEY&amp;#x27;]:\n                ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^\nKeyError: &amp;#x27;API_KEY&amp;#x27;\n\n------------------------------ Captured log call -------------------------------\nDEBUG    app:__init__.py:31 Headers: {&amp;#x27;User-Agent&amp;#x27;: &amp;#x27;Werkzeug/3.0.6&amp;#x27;, &amp;#x27;Host&amp;#x27;: &amp;#x27;localhost&amp;#x27;, &amp;#x27;Content-Type&amp;#x27;: &amp;#x27;application/json&amp;#x27;, &amp;#x27;Content-Length&amp;#x27;: &amp;#x27;40&amp;#x27;, &amp;#x27;Authorization&amp;#x27;: &amp;#x27;Bearer test_key&amp;#x27;}\nDEBUG    app:__init__.py:32 Body: b&amp;#x27;{&amp;quot;content&amp;quot;: &amp;quot;&amp;quot;, &amp;quot;target_percentage&amp;quot;: 50}&amp;#x27;\nDEBUG    app:__init__.py:33 Query Params: {}\nDEBUG    app:__init__.py:34 Route: POST /text/v1/compress/\nERROR    app:__init__.py:77 An error occurred: &amp;#x27;API_KEY&amp;#x27;\nTraceback (most recent call last):\n  File &amp;quot;/Users/julian/Tresors/Privat/Code/fragment-editor-api/.venv-test/lib/python3.12/site-packages/flask/app.py&amp;quot;, line 870, in full_dispatch_request\n    rv = self.dispatch_request()\n         ^^^^^^^^^^^^^^^^^^^^^^^\n  File &amp;quot;/Users/julian/Tresors/Privat/Code/fragment-editor-api/.venv-test/lib/python3.12/site-packages/flask/app.py&amp;quot;, line 855, in dispatch_request\n    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File &amp;quot;/Users/julian/Tresors/Privat/Code/fragment-editor-api/app/middleware/auth.py&amp;quot;, line 17, in decorated_function\n    if token != current_app.config[&amp;#x27;API_KEY&amp;#x27;]:\n                ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^\nKeyError: &amp;#x27;API_KEY&amp;#x27;\n\n&#34;}], &#34;tests/test_compress.py::TestCompressEndpoint::test_invalid_inputs[invalid_input4]&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Failed&#34;, &#34;testId&#34;: &#34;tests/test_compress.py::TestCompressEndpoint::test_invalid_inputs[invalid_input4]&#34;, &#34;duration&#34;: &#34;512 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Failed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_compress.py::TestCompressEndpoint::test_invalid_inputs[invalid_input4]&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;512 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;self = &amp;lt;tests.test_compress.TestCompressEndpoint object at 0x1069d1970&amp;gt;\nclient = &amp;lt;FlaskClient &amp;lt;Flask &amp;#x27;app&amp;#x27;&amp;gt;&amp;gt;, auth_headers = {&amp;#x27;Authorization&amp;#x27;: &amp;#x27;Bearer test_key&amp;#x27;}\ninvalid_input = {&amp;#x27;target_percentage&amp;#x27;: 50}\n\n    @pytest.mark.unit\n    @pytest.mark.parametrize(&amp;#x27;invalid_input&amp;#x27;, [\n        {&amp;#x27;content&amp;#x27;: &amp;quot;text&amp;quot;, &amp;#x27;target_percentage&amp;#x27;: 150},  # Invalid percentage\n        {&amp;#x27;content&amp;#x27;: &amp;quot;text&amp;quot;, &amp;#x27;steps_percentage&amp;#x27;: -10},   # Negative steps\n        {&amp;#x27;content&amp;#x27;: &amp;quot;text&amp;quot;, &amp;#x27;versions&amp;#x27;: 10},            # Too many versions\n        {&amp;#x27;content&amp;#x27;: &amp;quot;&amp;quot;, &amp;#x27;target_percentage&amp;#x27;: 50},       # Empty content\n        {&amp;#x27;target_percentage&amp;#x27;: 50},                      # Missing content\n    ])\n    def test_invalid_inputs(self, client, auth_headers, invalid_input):\n        response = client.post(\n            self.ENDPOINTS[&amp;#x27;compress&amp;#x27;], json=invalid_input, headers=auth_headers)\n&amp;gt;       assert response.status_code == 400\nE       assert 500 == 400\nE        +  where 500 = &amp;lt;WrapperTestResponse streamed [500 INTERNAL SERVER ERROR]&amp;gt;.status_code\n\ntests/test_compress.py:139: AssertionError\n\n---------------------------- Captured stderr setup -----------------------------\nDEBUG:app:Registering blueprints...\nDEBUG:app:Registered routes:\nDEBUG:app:static: /static/&amp;lt;path:filename&amp;gt; [GET, OPTIONS, HEAD]\nDEBUG:app:generate.create_text: /text/v1/generate/text [OPTIONS, POST]\nDEBUG:app:compress.compress_text: /text/v1/compress/ [OPTIONS, POST]\nDEBUG:app:expand.expand_text: /text/v1/expand/ [OPTIONS, POST]\n\n------------------------------ Captured log setup ------------------------------\nDEBUG    app:__init__.py:106 Registering blueprints...\nDEBUG    app:__init__.py:112 Registered routes:\nDEBUG    app:__init__.py:114 static: /static/&amp;lt;path:filename&amp;gt; [GET, OPTIONS, HEAD]\nDEBUG    app:__init__.py:114 generate.create_text: /text/v1/generate/text [OPTIONS, POST]\nDEBUG    app:__init__.py:114 compress.compress_text: /text/v1/compress/ [OPTIONS, POST]\nDEBUG    app:__init__.py:114 expand.expand_text: /text/v1/expand/ [OPTIONS, POST]\n\n----------------------------- Captured stderr call -----------------------------\nDEBUG:app:Headers: {&amp;#x27;User-Agent&amp;#x27;: &amp;#x27;Werkzeug/3.0.6&amp;#x27;, &amp;#x27;Host&amp;#x27;: &amp;#x27;localhost&amp;#x27;, &amp;#x27;Content-Type&amp;#x27;: &amp;#x27;application/json&amp;#x27;, &amp;#x27;Content-Length&amp;#x27;: &amp;#x27;25&amp;#x27;, &amp;#x27;Authorization&amp;#x27;: &amp;#x27;Bearer test_key&amp;#x27;}\nDEBUG:app:Body: b&amp;#x27;{&amp;quot;target_percentage&amp;quot;: 50}&amp;#x27;\nDEBUG:app:Query Params: {}\nDEBUG:app:Route: POST /text/v1/compress/\nERROR:app:An error occurred: &amp;#x27;API_KEY&amp;#x27;\nTraceback (most recent call last):\n  File &amp;quot;/Users/julian/Tresors/Privat/Code/fragment-editor-api/.venv-test/lib/python3.12/site-packages/flask/app.py&amp;quot;, line 870, in full_dispatch_request\n    rv = self.dispatch_request()\n         ^^^^^^^^^^^^^^^^^^^^^^^\n  File &amp;quot;/Users/julian/Tresors/Privat/Code/fragment-editor-api/.venv-test/lib/python3.12/site-packages/flask/app.py&amp;quot;, line 855, in dispatch_request\n    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File &amp;quot;/Users/julian/Tresors/Privat/Code/fragment-editor-api/app/middleware/auth.py&amp;quot;, line 17, in decorated_function\n    if token != current_app.config[&amp;#x27;API_KEY&amp;#x27;]:\n                ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^\nKeyError: &amp;#x27;API_KEY&amp;#x27;\n\n------------------------------ Captured log call -------------------------------\nDEBUG    app:__init__.py:31 Headers: {&amp;#x27;User-Agent&amp;#x27;: &amp;#x27;Werkzeug/3.0.6&amp;#x27;, &amp;#x27;Host&amp;#x27;: &amp;#x27;localhost&amp;#x27;, &amp;#x27;Content-Type&amp;#x27;: &amp;#x27;application/json&amp;#x27;, &amp;#x27;Content-Length&amp;#x27;: &amp;#x27;25&amp;#x27;, &amp;#x27;Authorization&amp;#x27;: &amp;#x27;Bearer test_key&amp;#x27;}\nDEBUG    app:__init__.py:32 Body: b&amp;#x27;{&amp;quot;target_percentage&amp;quot;: 50}&amp;#x27;\nDEBUG    app:__init__.py:33 Query Params: {}\nDEBUG    app:__init__.py:34 Route: POST /text/v1/compress/\nERROR    app:__init__.py:77 An error occurred: &amp;#x27;API_KEY&amp;#x27;\nTraceback (most recent call last):\n  File &amp;quot;/Users/julian/Tresors/Privat/Code/fragment-editor-api/.venv-test/lib/python3.12/site-packages/flask/app.py&amp;quot;, line 870, in full_dispatch_request\n    rv = self.dispatch_request()\n         ^^^^^^^^^^^^^^^^^^^^^^^\n  File &amp;quot;/Users/julian/Tresors/Privat/Code/fragment-editor-api/.venv-test/lib/python3.12/site-packages/flask/app.py&amp;quot;, line 855, in dispatch_request\n    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File &amp;quot;/Users/julian/Tresors/Privat/Code/fragment-editor-api/app/middleware/auth.py&amp;quot;, line 17, in decorated_function\n    if token != current_app.config[&amp;#x27;API_KEY&amp;#x27;]:\n                ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^\nKeyError: &amp;#x27;API_KEY&amp;#x27;\n\n&#34;}], &#34;tests/test_compress.py::TestCompressEndpoint::test_length_validation&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Failed&#34;, &#34;testId&#34;: &#34;tests/test_compress.py::TestCompressEndpoint::test_length_validation&#34;, &#34;duration&#34;: &#34;513 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Failed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_compress.py::TestCompressEndpoint::test_length_validation&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;513 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;self = &amp;lt;tests.test_compress.TestCompressEndpoint object at 0x1069d15e0&amp;gt;\nclient = &amp;lt;FlaskClient &amp;lt;Flask &amp;#x27;app&amp;#x27;&amp;gt;&amp;gt;, auth_headers = {&amp;#x27;Authorization&amp;#x27;: &amp;#x27;Bearer test_key&amp;#x27;}\n\n    @pytest.mark.unit\n    def test_length_validation(self, client, auth_headers):\n        &amp;quot;&amp;quot;&amp;quot;Test if compressed versions roughly match target percentages&amp;quot;&amp;quot;&amp;quot;\n        response = client.post(self.ENDPOINTS[&amp;#x27;compress&amp;#x27;], json={\n            &amp;#x27;content&amp;#x27;: self.SAMPLE_TEXT,\n            &amp;#x27;target_percentage&amp;#x27;: 50,\n            &amp;#x27;versions&amp;#x27;: 1\n        }, headers=auth_headers)\n    \n        data = response.json\n        original_length = len(self.SAMPLE_TEXT)\n&amp;gt;       compressed_length = len(data[&amp;#x27;versions&amp;#x27;][0][&amp;#x27;text&amp;#x27;])\nE       KeyError: &amp;#x27;versions&amp;#x27;\n\ntests/test_compress.py:153: KeyError\n\n---------------------------- Captured stderr setup -----------------------------\nDEBUG:app:Registering blueprints...\nDEBUG:app:Registered routes:\nDEBUG:app:static: /static/&amp;lt;path:filename&amp;gt; [GET, OPTIONS, HEAD]\nDEBUG:app:generate.create_text: /text/v1/generate/text [OPTIONS, POST]\nDEBUG:app:compress.compress_text: /text/v1/compress/ [OPTIONS, POST]\nDEBUG:app:expand.expand_text: /text/v1/expand/ [OPTIONS, POST]\n\n------------------------------ Captured log setup ------------------------------\nDEBUG    app:__init__.py:106 Registering blueprints...\nDEBUG    app:__init__.py:112 Registered routes:\nDEBUG    app:__init__.py:114 static: /static/&amp;lt;path:filename&amp;gt; [GET, OPTIONS, HEAD]\nDEBUG    app:__init__.py:114 generate.create_text: /text/v1/generate/text [OPTIONS, POST]\nDEBUG    app:__init__.py:114 compress.compress_text: /text/v1/compress/ [OPTIONS, POST]\nDEBUG    app:__init__.py:114 expand.expand_text: /text/v1/expand/ [OPTIONS, POST]\n\n----------------------------- Captured stderr call -----------------------------\nDEBUG:app:Headers: {&amp;#x27;User-Agent&amp;#x27;: &amp;#x27;Werkzeug/3.0.6&amp;#x27;, &amp;#x27;Host&amp;#x27;: &amp;#x27;localhost&amp;#x27;, &amp;#x27;Content-Type&amp;#x27;: &amp;#x27;application/json&amp;#x27;, &amp;#x27;Content-Length&amp;#x27;: &amp;#x27;265&amp;#x27;, &amp;#x27;Authorization&amp;#x27;: &amp;#x27;Bearer test_key&amp;#x27;}\nDEBUG:app:Body: b&amp;#x27;{&amp;quot;content&amp;quot;: &amp;quot;The Text Transformation API offers a robust set of REST endpoints that enable developers to programmatically manipulate and transform text content. The operations include expansion, summarization, and chunking.&amp;quot;, &amp;quot;target_percentage&amp;quot;: 50, &amp;quot;versions&amp;quot;: 1}&amp;#x27;\nDEBUG:app:Query Params: {}\nDEBUG:app:Route: POST /text/v1/compress/\nERROR:app:An error occurred: &amp;#x27;API_KEY&amp;#x27;\nTraceback (most recent call last):\n  File &amp;quot;/Users/julian/Tresors/Privat/Code/fragment-editor-api/.venv-test/lib/python3.12/site-packages/flask/app.py&amp;quot;, line 870, in full_dispatch_request\n    rv = self.dispatch_request()\n         ^^^^^^^^^^^^^^^^^^^^^^^\n  File &amp;quot;/Users/julian/Tresors/Privat/Code/fragment-editor-api/.venv-test/lib/python3.12/site-packages/flask/app.py&amp;quot;, line 855, in dispatch_request\n    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File &amp;quot;/Users/julian/Tresors/Privat/Code/fragment-editor-api/app/middleware/auth.py&amp;quot;, line 17, in decorated_function\n    if token != current_app.config[&amp;#x27;API_KEY&amp;#x27;]:\n                ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^\nKeyError: &amp;#x27;API_KEY&amp;#x27;\n\n------------------------------ Captured log call -------------------------------\nDEBUG    app:__init__.py:31 Headers: {&amp;#x27;User-Agent&amp;#x27;: &amp;#x27;Werkzeug/3.0.6&amp;#x27;, &amp;#x27;Host&amp;#x27;: &amp;#x27;localhost&amp;#x27;, &amp;#x27;Content-Type&amp;#x27;: &amp;#x27;application/json&amp;#x27;, &amp;#x27;Content-Length&amp;#x27;: &amp;#x27;265&amp;#x27;, &amp;#x27;Authorization&amp;#x27;: &amp;#x27;Bearer test_key&amp;#x27;}\nDEBUG    app:__init__.py:32 Body: b&amp;#x27;{&amp;quot;content&amp;quot;: &amp;quot;The Text Transformation API offers a robust set of REST endpoints that enable developers to programmatically manipulate and transform text content. The operations include expansion, summarization, and chunking.&amp;quot;, &amp;quot;target_percentage&amp;quot;: 50, &amp;quot;versions&amp;quot;: 1}&amp;#x27;\nDEBUG    app:__init__.py:33 Query Params: {}\nDEBUG    app:__init__.py:34 Route: POST /text/v1/compress/\nERROR    app:__init__.py:77 An error occurred: &amp;#x27;API_KEY&amp;#x27;\nTraceback (most recent call last):\n  File &amp;quot;/Users/julian/Tresors/Privat/Code/fragment-editor-api/.venv-test/lib/python3.12/site-packages/flask/app.py&amp;quot;, line 870, in full_dispatch_request\n    rv = self.dispatch_request()\n         ^^^^^^^^^^^^^^^^^^^^^^^\n  File &amp;quot;/Users/julian/Tresors/Privat/Code/fragment-editor-api/.venv-test/lib/python3.12/site-packages/flask/app.py&amp;quot;, line 855, in dispatch_request\n    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File &amp;quot;/Users/julian/Tresors/Privat/Code/fragment-editor-api/app/middleware/auth.py&amp;quot;, line 17, in decorated_function\n    if token != current_app.config[&amp;#x27;API_KEY&amp;#x27;]:\n                ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^\nKeyError: &amp;#x27;API_KEY&amp;#x27;\n\n&#34;}]}, &#34;renderCollapsed&#34;: [&#34;passed&#34;], &#34;initialSort&#34;: &#34;result&#34;, &#34;title&#34;: &#34;report.html&#34;}"></div>
    <script>
      (function(){function r(e,n,t){function o(i,f){if(!n[i]){if(!e[i]){var c="function"==typeof require&&require;if(!f&&c)return c(i,!0);if(u)return u(i,!0);var a=new Error("Cannot find module '"+i+"'");throw a.code="MODULE_NOT_FOUND",a}var p=n[i]={exports:{}};e[i][0].call(p.exports,function(r){var n=e[i][1][r];return o(n||r)},p,p.exports,r,e,n,t)}return n[i].exports}for(var u="function"==typeof require&&require,i=0;i<t.length;i++)o(t[i]);return o}return r})()({1:[function(require,module,exports){
const { getCollapsedCategory, setCollapsedIds } = require('./storage.js')

class DataManager {
    setManager(data) {
        const collapsedCategories = [...getCollapsedCategory(data.renderCollapsed)]
        const collapsedIds = []
        const tests = Object.values(data.tests).flat().map((test, index) => {
            const collapsed = collapsedCategories.includes(test.result.toLowerCase())
            const id = `test_${index}`
            if (collapsed) {
                collapsedIds.push(id)
            }
            return {
                ...test,
                id,
                collapsed,
            }
        })
        const dataBlob = { ...data, tests }
        this.data = { ...dataBlob }
        this.renderData = { ...dataBlob }
        setCollapsedIds(collapsedIds)
    }

    get allData() {
        return { ...this.data }
    }

    resetRender() {
        this.renderData = { ...this.data }
    }

    setRender(data) {
        this.renderData.tests = [...data]
    }

    toggleCollapsedItem(id) {
        this.renderData.tests = this.renderData.tests.map((test) =>
            test.id === id ? { ...test, collapsed: !test.collapsed } : test,
        )
    }

    set allCollapsed(collapsed) {
        this.renderData = { ...this.renderData, tests: [...this.renderData.tests.map((test) => (
            { ...test, collapsed }
        ))] }
    }

    get testSubset() {
        return [...this.renderData.tests]
    }

    get environment() {
        return this.renderData.environment
    }

    get initialSort() {
        return this.data.initialSort
    }
}

module.exports = {
    manager: new DataManager(),
}

},{"./storage.js":8}],2:[function(require,module,exports){
const mediaViewer = require('./mediaviewer.js')
const templateEnvRow = document.getElementById('template_environment_row')
const templateResult = document.getElementById('template_results-table__tbody')

function htmlToElements(html) {
    const temp = document.createElement('template')
    temp.innerHTML = html
    return temp.content.childNodes
}

const find = (selector, elem) => {
    if (!elem) {
        elem = document
    }
    return elem.querySelector(selector)
}

const findAll = (selector, elem) => {
    if (!elem) {
        elem = document
    }
    return [...elem.querySelectorAll(selector)]
}

const dom = {
    getStaticRow: (key, value) => {
        const envRow = templateEnvRow.content.cloneNode(true)
        const isObj = typeof value === 'object' && value !== null
        const values = isObj ? Object.keys(value).map((k) => `${k}: ${value[k]}`) : null

        const valuesElement = htmlToElements(
            values ? `<ul>${values.map((val) => `<li>${val}</li>`).join('')}<ul>` : `<div>${value}</div>`)[0]
        const td = findAll('td', envRow)
        td[0].textContent = key
        td[1].appendChild(valuesElement)

        return envRow
    },
    getResultTBody: ({ testId, id, log, extras, resultsTableRow, tableHtml, result, collapsed }) => {
        const resultBody = templateResult.content.cloneNode(true)
        resultBody.querySelector('tbody').classList.add(result.toLowerCase())
        resultBody.querySelector('tbody').id = testId
        resultBody.querySelector('.collapsible').dataset.id = id

        resultsTableRow.forEach((html) => {
            const t = document.createElement('template')
            t.innerHTML = html
            resultBody.querySelector('.collapsible').appendChild(t.content)
        })

        if (log) {
            // Wrap lines starting with "E" with span.error to color those lines red
            const wrappedLog = log.replace(/^E.*$/gm, (match) => `<span class="error">${match}</span>`)
            resultBody.querySelector('.log').innerHTML = wrappedLog
        } else {
            resultBody.querySelector('.log').remove()
        }

        if (collapsed) {
            resultBody.querySelector('.collapsible > td')?.classList.add('collapsed')
            resultBody.querySelector('.extras-row').classList.add('hidden')
        } else {
            resultBody.querySelector('.collapsible > td')?.classList.remove('collapsed')
        }

        const media = []
        extras?.forEach(({ name, format_type, content }) => {
            if (['image', 'video'].includes(format_type)) {
                media.push({ path: content, name, format_type })
            }

            if (format_type === 'html') {
                resultBody.querySelector('.extraHTML').insertAdjacentHTML('beforeend', `<div>${content}</div>`)
            }
        })
        mediaViewer.setup(resultBody, media)

        // Add custom html from the pytest_html_results_table_html hook
        tableHtml?.forEach((item) => {
            resultBody.querySelector('td[class="extra"]').insertAdjacentHTML('beforeend', item)
        })

        return resultBody
    },
}

module.exports = {
    dom,
    htmlToElements,
    find,
    findAll,
}

},{"./mediaviewer.js":6}],3:[function(require,module,exports){
const { manager } = require('./datamanager.js')
const { doSort } = require('./sort.js')
const storageModule = require('./storage.js')

const getFilteredSubSet = (filter) =>
    manager.allData.tests.filter(({ result }) => filter.includes(result.toLowerCase()))

const doInitFilter = () => {
    const currentFilter = storageModule.getVisible()
    const filteredSubset = getFilteredSubSet(currentFilter)
    manager.setRender(filteredSubset)
}

const doFilter = (type, show) => {
    if (show) {
        storageModule.showCategory(type)
    } else {
        storageModule.hideCategory(type)
    }

    const currentFilter = storageModule.getVisible()
    const filteredSubset = getFilteredSubSet(currentFilter)
    manager.setRender(filteredSubset)

    const sortColumn = storageModule.getSort()
    doSort(sortColumn, true)
}

module.exports = {
    doFilter,
    doInitFilter,
}

},{"./datamanager.js":1,"./sort.js":7,"./storage.js":8}],4:[function(require,module,exports){
const { redraw, bindEvents, renderStatic } = require('./main.js')
const { doInitFilter } = require('./filter.js')
const { doInitSort } = require('./sort.js')
const { manager } = require('./datamanager.js')
const data = JSON.parse(document.getElementById('data-container').dataset.jsonblob)

function init() {
    manager.setManager(data)
    doInitFilter()
    doInitSort()
    renderStatic()
    redraw()
    bindEvents()
}

init()

},{"./datamanager.js":1,"./filter.js":3,"./main.js":5,"./sort.js":7}],5:[function(require,module,exports){
const { dom, find, findAll } = require('./dom.js')
const { manager } = require('./datamanager.js')
const { doSort } = require('./sort.js')
const { doFilter } = require('./filter.js')
const {
    getVisible,
    getCollapsedIds,
    setCollapsedIds,
    getSort,
    getSortDirection,
    possibleFilters,
} = require('./storage.js')

const removeChildren = (node) => {
    while (node.firstChild) {
        node.removeChild(node.firstChild)
    }
}

const renderStatic = () => {
    const renderEnvironmentTable = () => {
        const environment = manager.environment
        const rows = Object.keys(environment).map((key) => dom.getStaticRow(key, environment[key]))
        const table = document.getElementById('environment')
        removeChildren(table)
        rows.forEach((row) => table.appendChild(row))
    }
    renderEnvironmentTable()
}

const addItemToggleListener = (elem) => {
    elem.addEventListener('click', ({ target }) => {
        const id = target.parentElement.dataset.id
        manager.toggleCollapsedItem(id)

        const collapsedIds = getCollapsedIds()
        if (collapsedIds.includes(id)) {
            const updated = collapsedIds.filter((item) => item !== id)
            setCollapsedIds(updated)
        } else {
            collapsedIds.push(id)
            setCollapsedIds(collapsedIds)
        }
        redraw()
    })
}

const renderContent = (tests) => {
    const sortAttr = getSort(manager.initialSort)
    const sortAsc = JSON.parse(getSortDirection())
    const rows = tests.map(dom.getResultTBody)
    const table = document.getElementById('results-table')
    const tableHeader = document.getElementById('results-table-head')

    const newTable = document.createElement('table')
    newTable.id = 'results-table'

    // remove all sorting classes and set the relevant
    findAll('.sortable', tableHeader).forEach((elem) => elem.classList.remove('asc', 'desc'))
    tableHeader.querySelector(`.sortable[data-column-type="${sortAttr}"]`)?.classList.add(sortAsc ? 'desc' : 'asc')
    newTable.appendChild(tableHeader)

    if (!rows.length) {
        const emptyTable = document.getElementById('template_results-table__body--empty').content.cloneNode(true)
        newTable.appendChild(emptyTable)
    } else {
        rows.forEach((row) => {
            if (!!row) {
                findAll('.collapsible td:not(.col-links', row).forEach(addItemToggleListener)
                find('.logexpander', row).addEventListener('click',
                    (evt) => evt.target.parentNode.classList.toggle('expanded'),
                )
                newTable.appendChild(row)
            }
        })
    }

    table.replaceWith(newTable)
}

const renderDerived = () => {
    const currentFilter = getVisible()
    possibleFilters.forEach((result) => {
        const input = document.querySelector(`input[data-test-result="${result}"]`)
        input.checked = currentFilter.includes(result)
    })
}

const bindEvents = () => {
    const filterColumn = (evt) => {
        const { target: element } = evt
        const { testResult } = element.dataset

        doFilter(testResult, element.checked)
        const collapsedIds = getCollapsedIds()
        const updated = manager.renderData.tests.map((test) => {
            return {
                ...test,
                collapsed: collapsedIds.includes(test.id),
            }
        })
        manager.setRender(updated)
        redraw()
    }

    const header = document.getElementById('environment-header')
    header.addEventListener('click', () => {
        const table = document.getElementById('environment')
        table.classList.toggle('hidden')
        header.classList.toggle('collapsed')
    })

    findAll('input[name="filter_checkbox"]').forEach((elem) => {
        elem.addEventListener('click', filterColumn)
    })

    findAll('.sortable').forEach((elem) => {
        elem.addEventListener('click', (evt) => {
            const { target: element } = evt
            const { columnType } = element.dataset
            doSort(columnType)
            redraw()
        })
    })

    document.getElementById('show_all_details').addEventListener('click', () => {
        manager.allCollapsed = false
        setCollapsedIds([])
        redraw()
    })
    document.getElementById('hide_all_details').addEventListener('click', () => {
        manager.allCollapsed = true
        const allIds = manager.renderData.tests.map((test) => test.id)
        setCollapsedIds(allIds)
        redraw()
    })
}

const redraw = () => {
    const { testSubset } = manager

    renderContent(testSubset)
    renderDerived()
}

module.exports = {
    redraw,
    bindEvents,
    renderStatic,
}

},{"./datamanager.js":1,"./dom.js":2,"./filter.js":3,"./sort.js":7,"./storage.js":8}],6:[function(require,module,exports){
class MediaViewer {
    constructor(assets) {
        this.assets = assets
        this.index = 0
    }

    nextActive() {
        this.index = this.index === this.assets.length - 1 ? 0 : this.index + 1
        return [this.activeFile, this.index]
    }

    prevActive() {
        this.index = this.index === 0 ? this.assets.length - 1 : this.index -1
        return [this.activeFile, this.index]
    }

    get currentIndex() {
        return this.index
    }

    get activeFile() {
        return this.assets[this.index]
    }
}


const setup = (resultBody, assets) => {
    if (!assets.length) {
        resultBody.querySelector('.media').classList.add('hidden')
        return
    }

    const mediaViewer = new MediaViewer(assets)
    const container = resultBody.querySelector('.media-container')
    const leftArrow = resultBody.querySelector('.media-container__nav--left')
    const rightArrow = resultBody.querySelector('.media-container__nav--right')
    const mediaName = resultBody.querySelector('.media__name')
    const counter = resultBody.querySelector('.media__counter')
    const imageEl = resultBody.querySelector('img')
    const sourceEl = resultBody.querySelector('source')
    const videoEl = resultBody.querySelector('video')

    const setImg = (media, index) => {
        if (media?.format_type === 'image') {
            imageEl.src = media.path

            imageEl.classList.remove('hidden')
            videoEl.classList.add('hidden')
        } else if (media?.format_type === 'video') {
            sourceEl.src = media.path

            videoEl.classList.remove('hidden')
            imageEl.classList.add('hidden')
        }

        mediaName.innerText = media?.name
        counter.innerText = `${index + 1} / ${assets.length}`
    }
    setImg(mediaViewer.activeFile, mediaViewer.currentIndex)

    const moveLeft = () => {
        const [media, index] = mediaViewer.prevActive()
        setImg(media, index)
    }
    const doRight = () => {
        const [media, index] = mediaViewer.nextActive()
        setImg(media, index)
    }
    const openImg = () => {
        window.open(mediaViewer.activeFile.path, '_blank')
    }
    if (assets.length === 1) {
        container.classList.add('media-container--fullscreen')
    } else {
        leftArrow.addEventListener('click', moveLeft)
        rightArrow.addEventListener('click', doRight)
    }
    imageEl.addEventListener('click', openImg)
}

module.exports = {
    setup,
}

},{}],7:[function(require,module,exports){
const { manager } = require('./datamanager.js')
const storageModule = require('./storage.js')

const genericSort = (list, key, ascending, customOrder) => {
    let sorted
    if (customOrder) {
        sorted = list.sort((a, b) => {
            const aValue = a.result.toLowerCase()
            const bValue = b.result.toLowerCase()

            const aIndex = customOrder.findIndex((item) => item.toLowerCase() === aValue)
            const bIndex = customOrder.findIndex((item) => item.toLowerCase() === bValue)

            // Compare the indices to determine the sort order
            return aIndex - bIndex
        })
    } else {
        sorted = list.sort((a, b) => a[key] === b[key] ? 0 : a[key] > b[key] ? 1 : -1)
    }

    if (ascending) {
        sorted.reverse()
    }
    return sorted
}

const durationSort = (list, ascending) => {
    const parseDuration = (duration) => {
        if (duration.includes(':')) {
            // If it's in the format "HH:mm:ss"
            const [hours, minutes, seconds] = duration.split(':').map(Number)
            return (hours * 3600 + minutes * 60 + seconds) * 1000
        } else {
            // If it's in the format "nnn ms"
            return parseInt(duration)
        }
    }
    const sorted = list.sort((a, b) => parseDuration(a['duration']) - parseDuration(b['duration']))
    if (ascending) {
        sorted.reverse()
    }
    return sorted
}

const doInitSort = () => {
    const type = storageModule.getSort(manager.initialSort)
    const ascending = storageModule.getSortDirection()
    const list = manager.testSubset
    const initialOrder = ['Error', 'Failed', 'Rerun', 'XFailed', 'XPassed', 'Skipped', 'Passed']

    storageModule.setSort(type)
    storageModule.setSortDirection(ascending)

    if (type?.toLowerCase() === 'original') {
        manager.setRender(list)
    } else {
        let sortedList
        switch (type) {
        case 'duration':
            sortedList = durationSort(list, ascending)
            break
        case 'result':
            sortedList = genericSort(list, type, ascending, initialOrder)
            break
        default:
            sortedList = genericSort(list, type, ascending)
            break
        }
        manager.setRender(sortedList)
    }
}

const doSort = (type, skipDirection) => {
    const newSortType = storageModule.getSort(manager.initialSort) !== type
    const currentAsc = storageModule.getSortDirection()
    let ascending
    if (skipDirection) {
        ascending = currentAsc
    } else {
        ascending = newSortType ? false : !currentAsc
    }
    storageModule.setSort(type)
    storageModule.setSortDirection(ascending)

    const list = manager.testSubset
    const sortedList = type === 'duration' ? durationSort(list, ascending) : genericSort(list, type, ascending)
    manager.setRender(sortedList)
}

module.exports = {
    doInitSort,
    doSort,
}

},{"./datamanager.js":1,"./storage.js":8}],8:[function(require,module,exports){
const possibleFilters = [
    'passed',
    'skipped',
    'failed',
    'error',
    'xfailed',
    'xpassed',
    'rerun',
]

const getVisible = () => {
    const url = new URL(window.location.href)
    const settings = new URLSearchParams(url.search).get('visible')
    const lower = (item) => {
        const lowerItem = item.toLowerCase()
        if (possibleFilters.includes(lowerItem)) {
            return lowerItem
        }
        return null
    }
    return settings === null ?
        possibleFilters :
        [...new Set(settings?.split(',').map(lower).filter((item) => item))]
}

const hideCategory = (categoryToHide) => {
    const url = new URL(window.location.href)
    const visibleParams = new URLSearchParams(url.search).get('visible')
    const currentVisible = visibleParams ? visibleParams.split(',') : [...possibleFilters]
    const settings = [...new Set(currentVisible)].filter((f) => f !== categoryToHide).join(',')

    url.searchParams.set('visible', settings)
    window.history.pushState({}, null, unescape(url.href))
}

const showCategory = (categoryToShow) => {
    if (typeof window === 'undefined') {
        return
    }
    const url = new URL(window.location.href)
    const currentVisible = new URLSearchParams(url.search).get('visible')?.split(',').filter(Boolean) ||
        [...possibleFilters]
    const settings = [...new Set([categoryToShow, ...currentVisible])]
    const noFilter = possibleFilters.length === settings.length || !settings.length

    noFilter ? url.searchParams.delete('visible') : url.searchParams.set('visible', settings.join(','))
    window.history.pushState({}, null, unescape(url.href))
}

const getSort = (initialSort) => {
    const url = new URL(window.location.href)
    let sort = new URLSearchParams(url.search).get('sort')
    if (!sort) {
        sort = initialSort || 'result'
    }
    return sort
}

const setSort = (type) => {
    const url = new URL(window.location.href)
    url.searchParams.set('sort', type)
    window.history.pushState({}, null, unescape(url.href))
}

const getCollapsedCategory = (renderCollapsed) => {
    let categories
    if (typeof window !== 'undefined') {
        const url = new URL(window.location.href)
        const collapsedItems = new URLSearchParams(url.search).get('collapsed')
        switch (true) {
        case !renderCollapsed && collapsedItems === null:
            categories = ['passed']
            break
        case collapsedItems?.length === 0 || /^["']{2}$/.test(collapsedItems):
            categories = []
            break
        case /^all$/.test(collapsedItems) || collapsedItems === null && /^all$/.test(renderCollapsed):
            categories = [...possibleFilters]
            break
        default:
            categories = collapsedItems?.split(',').map((item) => item.toLowerCase()) || renderCollapsed
            break
        }
    } else {
        categories = []
    }
    return categories
}

const getSortDirection = () => JSON.parse(sessionStorage.getItem('sortAsc')) || false
const setSortDirection = (ascending) => sessionStorage.setItem('sortAsc', ascending)

const getCollapsedIds = () => JSON.parse(sessionStorage.getItem('collapsedIds')) || []
const setCollapsedIds = (list) => sessionStorage.setItem('collapsedIds', JSON.stringify(list))

module.exports = {
    getVisible,
    hideCategory,
    showCategory,
    getCollapsedIds,
    setCollapsedIds,
    getSort,
    setSort,
    getSortDirection,
    setSortDirection,
    getCollapsedCategory,
    possibleFilters,
}

},{}]},{},[4]);
    </script>
  </footer>
</html>